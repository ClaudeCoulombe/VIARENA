{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca2b1d2d",
   "metadata": {},
   "source": [
    "<a style=\"float:left;\" href=\"https://colab.research.google.com/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-Detection_Objets/Detection_Objets-colab.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<br/>\n",
    "### Rappel - Fonctionnement d'un carnet web iPython\n",
    "\n",
    "* Pour exécuter le code contenu dans une cellule d'un carnet iPython, cliquez dans la cellule et faites (⇧↵, shift-enter) \n",
    "* Le code d'un carnet iPython s'exécute séquentiellement de haut en bas de la page. Souvent, l'importation d'une bibliothèque Python ou l'initialisation d'une variable est préalable à l'exécution d'une cellule située plus bas. Il est donc recommandé d'exécuter les cellules en séquence. Enfin, méfiez-vous des retours en arrière qui peuvent réinitialiser certaines variables.\n",
    "* Pour obtenir de l'information sur une fonction, utilisez la commande Python `help(`\"nom de la fonction\"`)`\n",
    "\n",
    "SVP, déployez toutes les cellules en sélectionnant l'item « Développer les rubriques » de l'onglet « Affichage »."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7dd840",
   "metadata": {},
   "source": [
    "# Détection d'objets\n",
    "\n",
    "Bien que manquant de temps et d'espace pour traiter sérieusement de la tâche de détection d'objets, voici un petit labo Colab pour vous mettre en appétit sur le sujet plein d'applications.\n",
    "\n",
    "Rappelons que la détection consiste à identifier les différents objets dans une image en les encadrant dans un rectangle.\n",
    "\n",
    "La détection d'objets est utilisée pour identifier, isoler et même compter des objets dans une image, cela inclut le comptage du bétail dans un enclos, l'estimation du nombre d'arbres dans une forêt, ou le comptage du nombre de poissons dans une passe migratoire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43122d47",
   "metadata": {},
   "source": [
    "## Modèle créé à l'aide de l'IPA de détection d'objets TensorFlow\n",
    "\n",
    "<p>Utilisation de l'<a href=\"https://github.com/tensorflow/models/tree/master/research/object_detection\" target='_blank'>IPA</a> (<i>API</i>) de détection d'objets TensorFlow. L'IPA de détection d'objets TensorFlow utilise l'algorithme (<i>Faster R-CNN</i>) avec un extracteur d'attributs visuels basé sur l'architecture de réseau convolutif profond <a href=\"https://paperswithcode.com/method/inception-resnet-v2\" target='_blank'>Inception Resnet v2</a>. Le modèle est entraîné par apprentissage par transfert à partir d'un modèle préentraîné sur Imagenet puis peaufiné sur l'ensemble de données <a href=\"https://cocodataset.org/#home\" target='_blank'>COCO</a> 2017 avec des lots de 64 images en couleur de 640 par 640 pixels.</p>\n",
    "\n",
    "### L'algorithme <code>Faster R-CNN</code>\n",
    "\n",
    "Voici une tentative d'explication des étapes principales de l'algorithme <code>Faster R-CNN</code>:\n",
    "\n",
    "<ul>\n",
    "    <ol>\n",
    "        <li>Un réseau convolutif profond, d'architecture <a href=\"https://paperswithcode.com/method/inception-resnet-v2\" target='_blank'>Inception Resnet v2</a>, extrait une représentation des attributs visuels de l’image d'entrée;</li> \n",
    "        <li>Cette représentation passe à un réseau de proposition de régions (en anglais, <i>region proposal network</i> ou <i>RPN</i>), qui génère des propositions de régions qui sont des rectangles qui délimitent les objets pertinents de l’image. Pour cela, le réseau de proposition de régions utilise des rectangles de taille fixe placés uniformément sur l’image originale afin de détecter les objets;</li>\n",
    "        <li>Les régions candidates sont ensuite filtrées par un algorithme dit de suppression des non-maxima (en anglais, <i>non-maximum suppression</i>), appelé aussi <a href=\"https://fr.wikipedia.org/wiki/Filtre_de_Canny\" target='_blank'>filtre de Canny</a>, qui ne conserve que les régions les plus intéressantes;</li> \n",
    "        <li>La représentation des attributs visuels de l’image d'entrée 1) et les rectangles de délimitation des objets pertinents 3) sont combinées pour générer une nouvelle représentation par sous-échantillonnage (<i>pooling</i>) des régions d'intérêt (en anglais, <i>regions of interest</i> ou <i>RoI</i>);</li>\n",
    "        <li>Finalement, la représentation des régions d'intérêt passe dans un perceptron multicouche pour la prédiction des coordonnées (par régression) des rectangles contenant des objets et (par classification softmax) les classes d'objets.</li> \n",
    "    </ol>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa1e08",
   "metadata": {},
   "source": [
    "### Inspiration et droits d'auteur\n",
    "\n",
    "Ce laboratoire est une adaptation et modification directe du tutoriel <a href=\"https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1\" target='_blank'>TensorFlow Hub Object Detection</a> - site Google / TensorFlow Hub\n",
    "\n",
    "##### Copyright (c) 2020, The TensorFlow Hub Authors.\n",
    "##### Copyright (c) 2022, Claude COULOMBE, modifications et adaptation française\n",
    "\n",
    "Le contenu de cette page est sous licence <a href=\"https://creativecommons.org/licenses/by/3.0/deed.fr\" target='_blank'>Creative Commons Attribution 3.0 (CC BY 3.0)</a>,<br/>et les exemples de code sont sous <a href=\"https://www.apache.org/licenses/LICENSE-2.0\" target='_blank'>licence Apache 2.0</a>.\n",
    "\n",
    "#### Données\n",
    "\n",
    "Les données sur les images du jeux de données <a href=\"https://cocodataset.org/#home\" target='_blank'>COCO</a> (<i>Common Objects in Context</i>) de Microsoft, une banque en données ouvertes sous licence <a href=\"https://creativecommons.org/licenses/by/4.0/deed.fr\" target='_blank'>Creative Commons Attribution 4.0 (CC BY 4.0)</a> de 330 000 photos de 80 objets communs dans leur contexte.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4234c744",
   "metadata": {},
   "source": [
    "## Fixer le hasard pour la reproductibilité\n",
    "\n",
    "La mise au point de réseaux de neurones implique certains processus aléatoires. Afin de pouvoir reproduire et comparer vos résultats d'expérience, vous fixez temporairement l'état aléatoire grâce à un germe aléatoire unique.\n",
    "\n",
    "Pendant la mise au point, vous fixez temporairement l'état aléatoire pour la reproductibilité mais vous répétez l'expérience avec différents germes ou états aléatoires et prenez la moyenne des résultats.\n",
    "<br/>\n",
    "**Note** : Pour un système en production, vous ravivez simplement l'état  purement aléatoire avec l'instruction `GERME_ALEATOIRE = None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "008660d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow>=2.5 in /usr/local/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (1.20.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (1.44.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (2.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (0.5.3)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (2.8.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (13.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (0.24.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (1.1.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (3.19.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (4.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (1.15.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (2.8.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (3.6.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (61.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.5) (1.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.5) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5) (2.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5) (2.0.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.5) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.5) (4.11.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.5) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.5) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.5) (2.0.11)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.5) (1.26.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.5) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.5) (3.2.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# This Colab requires TF 2.5.\n",
    "# !pip3 install -U \"tensorflow>=2.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dde8782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version TensorFlow: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Version TensorFlow:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6d1cafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version \n",
      "Germe aléatoire fixé\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Définir un germe aléatoire\n",
    "GERME_ALEATOIRE = 42\n",
    "\n",
    "# Définir un état aléatoire pour Python\n",
    "os.environ['PYTHONHASHSEED'] = str(GERME_ALEATOIRE)\n",
    "\n",
    "# Définir un état aléatoire pour Python random\n",
    "import random\n",
    "random.seed(GERME_ALEATOIRE)\n",
    "\n",
    "# Définir un état aléatoire pour NumPy\n",
    "import numpy as np\n",
    "np.random.seed(GERME_ALEATOIRE)\n",
    "\n",
    "# Définir un état aléatoire pour TensorFlow\n",
    "\n",
    "tf.random.set_seed(GERME_ALEATOIRE)\n",
    "\n",
    "# Note: Retrait du comportement déterministe\n",
    "# à cause de keras.layers.RandomContrast(...)\n",
    "# dont il n'existe pas de version déterministe\n",
    "# os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "# os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "print(\"Version \")\n",
    "print(\"Germe aléatoire fixé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e651846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliothèques importées\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "print(\"Bibliothèques importées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff4ea3",
   "metadata": {},
   "source": [
    "## Utilitaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ef4b3",
   "metadata": {},
   "source": [
    "Exécutez le code de la cellule suivante pour créer des utilitairesé\n",
    "\n",
    "* Méthode pour charger une image\n",
    "* Liste de tous les modèles de TensorFlow Hub\n",
    "* Liste des tuples avec Human Keypoints pour le jeu de données COCO 2017. Ceci est nécessaire pour les modèles avec des points clés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a67ec9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilitaires chargés\n"
     ]
    }
   ],
   "source": [
    "# @title Run this!!\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "    Args:\n",
    "        path: the file path to the image\n",
    "    Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    image = None\n",
    "    if(path.startswith('http')):\n",
    "        response = urlopen(path)\n",
    "        image_data = response.read()\n",
    "        image_data = BytesIO(image_data)\n",
    "        image = Image.open(image_data)\n",
    "    else:\n",
    "        image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((1, im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "ALL_MODELS = {\n",
    "    'CenterNet HourGlass104 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1',\n",
    "    'CenterNet HourGlass104 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1',\n",
    "    'CenterNet HourGlass104 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1',\n",
    "    'CenterNet HourGlass104 Keypoints 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024_kpts/1',\n",
    "    'CenterNet Resnet50 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1',\n",
    "    'CenterNet Resnet50 V1 FPN Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512_kpts/1',\n",
    "    'CenterNet Resnet101 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1',\n",
    "    'CenterNet Resnet50 V2 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1',\n",
    "    'CenterNet Resnet50 V2 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1',\n",
    "    'EfficientDet D0 512x512' : 'https://tfhub.dev/tensorflow/efficientdet/d0/1',\n",
    "    'EfficientDet D1 640x640' : 'https://tfhub.dev/tensorflow/efficientdet/d1/1',\n",
    "    'EfficientDet D2 768x768' : 'https://tfhub.dev/tensorflow/efficientdet/d2/1',\n",
    "    'EfficientDet D3 896x896' : 'https://tfhub.dev/tensorflow/efficientdet/d3/1',\n",
    "    'EfficientDet D4 1024x1024' : 'https://tfhub.dev/tensorflow/efficientdet/d4/1',\n",
    "    'EfficientDet D5 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d5/1',\n",
    "    'EfficientDet D6 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d6/1',\n",
    "    'EfficientDet D7 1536x1536' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n",
    "    'SSD MobileNet v2 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',\n",
    "    'SSD MobileNet V1 FPN 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1',\n",
    "    'SSD MobileNet V2 FPNLite 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1',\n",
    "    'SSD MobileNet V2 FPNLite 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1',\n",
    "    'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1',\n",
    "    'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_1024x1024/1',\n",
    "    'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_640x640/1',\n",
    "    'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_1024x1024/1',\n",
    "    'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1',\n",
    "    'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1',\n",
    "    'Faster R-CNN ResNet50 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1',\n",
    "    'Faster R-CNN ResNet50 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1',\n",
    "    'Faster R-CNN ResNet50 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_800x1333/1',\n",
    "    'Faster R-CNN ResNet101 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1',\n",
    "    'Faster R-CNN ResNet101 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1',\n",
    "    'Faster R-CNN ResNet101 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_800x1333/1',\n",
    "    'Faster R-CNN ResNet152 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1',\n",
    "    'Faster R-CNN ResNet152 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1',\n",
    "    'Faster R-CNN ResNet152 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1',\n",
    "    'Faster R-CNN Inception ResNet V2 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1',\n",
    "    'Faster R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n",
    "    'Mask R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'\n",
    "}\n",
    "\n",
    "IMAGES_FOR_TEST = {\n",
    "  'Beach' : 'models/research/object_detection/test_images/image2.jpg',\n",
    "  'Dogs' : 'models/research/object_detection/test_images/image1.jpg',\n",
    "  # By Heiko Gorski, Source: https://commons.wikimedia.org/wiki/File:Naxos_Taverna.jpg\n",
    "  'Naxos Taverna' : 'https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg',\n",
    "  # Source: https://commons.wikimedia.org/wiki/File:The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg\n",
    "  'Beatles' : 'https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg',\n",
    "  # By Américo Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg\n",
    "  'Phones' : 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg',\n",
    "  # Source: https://commons.wikimedia.org/wiki/File:The_smaller_British_birds_(8053836633).jpg\n",
    "  'Birds' : 'https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg',\n",
    "}\n",
    "\n",
    "COCO17_HUMAN_POSE_KEYPOINTS = [  (0, 1),\n",
    "                                 (0, 2),\n",
    "                                 (1, 3),\n",
    "                                 (2, 4),\n",
    "                                 (0, 5),\n",
    "                                 (0, 6),\n",
    "                                 (5, 7),\n",
    "                                 (7, 9),\n",
    "                                 (6, 8),\n",
    "                                 (8, 10),\n",
    "                                 (5, 6),\n",
    "                                 (5, 11),\n",
    "                                 (6, 12),\n",
    "                                 (11, 12),\n",
    "                                 (11, 13),\n",
    "                                 (13, 15),\n",
    "                                 (12, 14),\n",
    "                                 (14, 16)\n",
    "                              ]\n",
    "\n",
    "print(\"Utilitaires chargés\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf0b665",
   "metadata": {},
   "source": [
    "## Outils de visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb647af",
   "metadata": {},
   "source": [
    "Pour visualiser les images avec les rectangles, les points clés et la segmentation détectés appropriés, nous utiliserons l'API de détection d'objets TensorFlow. Pour l'installer, nous allons cloner le dépôt GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a55790c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 3314, done.\u001b[K\n",
      "remote: Counting objects: 100% (3314/3314), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2737/2737), done.\u001b[K\n",
      "remote: Total 3314 (delta 879), reused 1393 (delta 528), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (3314/3314), 34.29 MiB | 10.29 MiB/s, done.\n",
      "Resolving deltas: 100% (879/879), done.\n",
      "Updating files: 100% (3016/3016), done.\n"
     ]
    }
   ],
   "source": [
    "# Clone the tensorflow models repository\n",
    "!git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de310463",
   "metadata": {},
   "source": [
    "### Intalling the Object Detection API\n",
    "\n",
    "sudo apt install -y protobuf-compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "579d6183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apt: invalid flag: install\n",
      "Usage: apt <apt and javac options> <source files>\n",
      "where apt options include:\n",
      "  -classpath <path>          Specify where to find user class files and annotation processor factories\n",
      "  -cp <path>                 Specify where to find user class files and annotation processor factories\n",
      "  -d <path>                  Specify where to place processor and javac generated class files\n",
      "  -s <path>                  Specify where to place processor generated source files\n",
      "  -source <release>          Provide source compatibility with specified release\n",
      "  -version                   Version information\n",
      "  -help                      Print a synopsis of standard options; use javac -help for more options\n",
      "  -X                         Print a synopsis of nonstandard options\n",
      "  -J<flag>                   Pass <flag> directly to the runtime system\n",
      "  -A[key[=value]]            Options to pass to annotation processors\n",
      "  -nocompile                 Do not compile source files to class files\n",
      "  -print                     Print out textual representation of specified types\n",
      "  -factorypath <path>        Specify where to find annotation processor factories\n",
      "  -factory <class>           Name of AnnotationProcessorFactory to use; bypasses default discovery process\n",
      "See javac -help for information on javac options.\n",
      "\n",
      "\n",
      "warning: The apt tool and its associated API are planned to be\n",
      "removed in the next major JDK release.  These features have been\n",
      "superseded by javac and the standardized annotation processing API,\n",
      "javax.annotation.processing and javax.lang.model.  Users are\n",
      "recommended to migrate to the annotation processing features of\n",
      "javac; see the javac man page for more information.\n",
      "/System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python: No module named pip\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'apt install -y protobuf-compiler\\ncd models/research/\\nprotoc object_detection/protos/*.proto --python_out=.\\ncp object_detection/packages/tf2/setup.py .\\npython -m pip install .\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapt install -y protobuf-compiler\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mcd models/research/\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprotoc object_detection/protos/*.proto --python_out=.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mcp object_detection/packages/tf2/setup.py .\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mpython -m pip install .\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/jupyterlab/3.3.2/libexec/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2338\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2337\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2338\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/Cellar/jupyterlab/3.3.2/libexec/lib/python3.9/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/jupyterlab/3.3.2/libexec/lib/python3.9/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'apt install -y protobuf-compiler\\ncd models/research/\\nprotoc object_detection/protos/*.proto --python_out=.\\ncp object_detection/packages/tf2/setup.py .\\npython -m pip install .\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "apt install -y protobuf-compiler\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f0534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
