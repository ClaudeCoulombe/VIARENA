{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF6G0T3AAugy"
      },
      "source": [
        "<a style=\"float:left;\" href=\"https://colab.research.google.com/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-Couverture_Terrestre/ImagesSatellitaires-AnalyseCouvertureTerrestre.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<br/>\n",
        "### Rappel - Fonctionnement d'un carnet web iPython\n",
        "\n",
        "* Pour exécuter le code contenu dans une cellule d'un carnet iPython, cliquez dans la cellule et faites (⇧↵, shift-enter);\n",
        "* Le code d'un carnet iPython s'exécute séquentiellement de haut en bas de la page. Souvent, l'importation d'une bibliothèque Python ou l'initialisation d'une variable est préalable à l'exécution d'une cellule située plus bas. Il est donc recommandé d'exécuter les cellules en séquence. Enfin, méfiez-vous des retours en arrière qui peuvent réinitialiser certaines variables;\n",
        "* Pour obtenir de l'information sur une fonction, utilisez la commande Python `help(`\"nom de la fonction\"`)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPGs4XnJ70g3"
      },
      "source": [
        "# Images satellitaires - Analyse de la couverture terrestre\n",
        "\n",
        "## Utilisation d'un réseau convolutif\n",
        "\n",
        "Ce carnet IPython pour Google Colab est une traduction et une adaptation du tutoriel « <a href=\"https://github.com/patrickcgray/open-geo-tutorial/blob/master/notebooks/chapter_6_neural_networks.ipynb\" target='_blank'>Chapter 6: Using Neural Networks for Classification and Land Cover Mapping</a> » de <a href=\"https://github.com/patrickcgray\" target='_blank'><b>Patrick Gray</b></a> par <a href=\"https:/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-Couverture_Terrestre/ImagesSatellitaires-AnalyseCouvertureTerrestre.ipynb\" target='_blank'>Claude Coulombe</a>. \n",
        "\n",
        "## Introduction\n",
        "\n",
        "L'apprentissage profond est à la fois surexposé sur le plan médiatique et sous-utilisé en pratique (https://doi.org/10.1038/nature14539). Peu importe,  l'apprentissage profond constitue un puissant coffre à outils pour analyser d'énormes quantités de données. De nouvelles applications passionnantes se développent rapidement en <a href=\"https://doi.org/10.1109/MGRS.2017.2762307\" target='_blank'>télédétection</a> dans des domaines tels que la <a href=\"https://doi.org/10.1109/TGRS.2018.2872509\" target='_blank'>détection d'anomalies</a>, la <a href=\"https://doi.org/10.1109/TGRS.2016.2612821\" target='_blank'>classification des images</a> et la <a href=\"https://doi.org/10.3390/rs11070768\" target='_blank'>régression des variables biophysiques</a>. \n",
        "\n",
        "Vous expérimenterez ici un exemple simple de classification de la couverture terrestre à partir d'images satellitaires de <i>Landsat 8</i> du <i>National Landcover Dataset</i> américain comme données d'entraînement et d'un réseau convolutif profond.\n",
        "\n",
        "Lancé par la <i>NASA</i> au début des années 1970, <i>Landsat</i> est un programme d’observation de la terre basé sur une constellation de 8 satellites.  <i>Landsat</i> est destiné à des applications civiles (agriculture, utilisation des sols, foresterie, urbanisme, etc.)\n",
        "\n",
        "## Plan\n",
        "\n",
        "*   Installation de bibiothèques Python requises;\n",
        "*   Téléchargement des données depuis GitHub;\n",
        "*   Création de fonctions utilitaires;\n",
        "*   Exploration des données;\n",
        "*   Création d'une base de référence\n",
        "    * pour la classification avec l'algorithme des K-plus-proches-voisins (<i>K nearest neighbors</i>)\n",
        "    * l'algorithme de la forêt aléatoire (<i>random forest</i>);\n",
        "*   Création et entraînement d'un réseau convolutif;\n",
        "*   Évaluation et comparaison du modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vjy1eHXAuhB"
      },
      "source": [
        "## Installation de bibliothèques Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0ClI2eJVDPx"
      },
      "outputs": [],
      "source": [
        "# Installation de bibliothèques Python\n",
        "! pip3 install geopandas rasterio matplotlib descartes scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNbyQv8KAuhG"
      },
      "source": [
        "## Fixer le hasard pour la reproductibilité\n",
        "\n",
        "La mise au point de réseaux de neurones implique certains processus aléatoires. Afin de pouvoir reproduire et comparer vos résultats d'expérience, vous fixez temporairement l'état aléatoire grâce à un germe aléatoire unique.\n",
        "\n",
        "Pendant la mise au point, vous fixez temporairement l'état aléatoire pour la reproductibilité mais vous répétez l'expérience avec différents germes ou états aléatoires et prenez la moyenne des résultats.\n",
        "<br/>\n",
        "##### **Note**: Pour un système en production, vous ravivez simplement l'état  purement aléatoire avec l'instruction `GERME_ALEATOIRE = None`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dH8C8VtAuhJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Définir un germe aléatoire\n",
        "GERME_ALEATOIRE = 21\n",
        "\n",
        "# Définir un état aléatoire pour Python\n",
        "os.environ['PYTHONHASHSEED'] = str(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour Python random\n",
        "import random\n",
        "random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour NumPy\n",
        "import numpy as np\n",
        "np.random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour TensorFlow\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(GERME_ALEATOIRE)\n",
        "\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "print(\"Germe aléatoire fixé\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ndVXUEsAuhK"
      },
      "source": [
        "## Téléchargement des données depuis GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAnp75RiapFx",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/ClaudeCoulombe/open-geo-tutorial/blob/master/data.zip?raw=True -O data.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aL97624AuhM"
      },
      "source": [
        "### Décompression des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcRzCGQjmvkX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile('data.zip','r')\n",
        "zip_ref.extractall('.')\n",
        "zip_ref.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7CxQbgjwHnw"
      },
      "outputs": [],
      "source": [
        "!ls -all data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGxL1XfHAuhP"
      },
      "source": [
        "### Les différentes classes de couverture du sol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ng4KwzvDsmq"
      },
      "outputs": [],
      "source": [
        "# Dictionnaire de toutes les classes et de leur identifiant\n",
        "classes_couverture = dict((\n",
        "    (0,  \"arrière-plan\"), # (0,  'Background'),\n",
        "    (1,  \"non-classé\"), # (1, 'Unclassified'),\n",
        "    # anthropoformé ou aménagé ?\n",
        "    (2,  \"fortement aménagé\"), # (2, 'High Intensity Developed'),\n",
        "    (3,  \"moyennement aménagé\"), # (3, 'Medium Intensity Developed'),\n",
        "    (4,  \"faiblement aménagé\"), # (4, 'Low Intensity Developed'),\n",
        "    (5,  \"espace ouvert aménagé\"),# (5, 'Open Space Developed'),\n",
        "    (6,  \"terre cultivée\"), # (6, 'Cultivated Land'),\n",
        "    (7,  \"pâturage/foin\"), # (7, 'Pasture/Hay')\n",
        "    (8,  \"prairie\"), # (8, 'Grassland'),\n",
        "    (9,  \"forêt de feuillus\"), # (9, 'Deciduous Forest'),\n",
        "    (10, \"forêt de conifères\"), # (10, 'Evergreen Forest'),\n",
        "    (11, \"forêt mixte\"), # (11, 'Mixed Forest'),\n",
        "    (12, \"arbuste/broussaille\"), # (12, 'Scrub/Shrub'),\n",
        "    (13, \"milieu humide boisé palustre\"), # (13, 'Palustrine Forested Wetland'),\n",
        "    (14, \"milieu humide arbustif/broussailleux palustre\"), # (14, 'Palustrine Scrub/Shrub Wetland'),\n",
        "    (15, \"milieu humide émergent palustre\"), # (15, 'Palustrine Emergent Wetland'),\n",
        "    (16, \"milieu humide boisé estuarien\"), # (16, 'Estuarine Forested Wetland'),\n",
        "    (17, \"milieu humide arbustif/broussailleux estuarien\"), # (17, 'Estuarine Scrub/Shrub Wetland')\n",
        "    (18, \"milieu humide émergent estuarien\"), # (18, 'Estuarine Emergent Wetland'),\n",
        "    (19, \"rivage meuble/non consolidé\"), # (19, 'Unconsolidated Shore'),\n",
        "    (20, \"terre nue\"), # (20, 'Bare Land'),\n",
        "    (21, \"eau\"), # (21, 'Water'),\n",
        "    (22, \"lit de cours d'eau palustre\"), # (22, 'Palustrine Aquatic Bed'),\n",
        "    (23, \"lit de cours d'eau estuarien\"), # (23, 'Estuarine Aquatic Bed'),\n",
        "    (24, 'toundra'), # (24, 'Tundra'),\n",
        "    (25, 'neige/glace') # (25, 'Snow/Ice')\n",
        "))\n",
        "\n",
        "print('Code exécuté!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYzZC7gMAuhQ"
      },
      "source": [
        "## Création de fonctions utilitaires"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYzuEFdgAuhS"
      },
      "source": [
        "### Un générateur de pixels aléatoires \n",
        "\n",
        "Générateur de pixels aléatoires définis par leurs positions x, y dans une image. Le générateur tient compte des tailles différentes des classes-cibles et fournit un ensemble de données d'entraînement équilibré.\n",
        "\n",
        "Cette fonction extrait un nombre nbre_donnees_entrainement + nbre_donnees_validation de pixels aléatoires d'une liste de jeux de données matricielles (<i>raster</i>) fournie en entrée. Elle retourne une liste de positions de pixels d'entraînement associée à une image (index_image) et une liste de positions de pixels de validation également avec un index d'image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykV3iJkiAuhS"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "from rasterio.plot import adjust_band\n",
        "import matplotlib.pyplot as plt\n",
        "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
        "from rasterio.plot import show\n",
        "from rasterio.windows import Window\n",
        "import rasterio.features\n",
        "import rasterio.warp\n",
        "import rasterio.mask\n",
        "\n",
        "from pyproj import Proj, transform\n",
        "from tqdm import tqdm\n",
        "from shapely.geometry import Polygon\n",
        "\n",
        "def generer_pixels(liste_jeux_donnees_images,\n",
        "                   label_dataset,\n",
        "                   etiquettes_couverture,\n",
        "                   classes_couverture,\n",
        "                   train_count,\n",
        "                   merge=False):\n",
        "    \n",
        "    # Rappel: système de référence géodésique, en anglais \"Coordinate Reference System\" (CRS)\n",
        "    # Obtenir le système de projection cartographique des étiquettes de classe-cible \n",
        "    projection_cartographique_etiquettes = Proj(label_dataset.crs)  \n",
        "    # initialiser le jeu de pixel d'entraînement\n",
        "    pixels_entrainement = []\n",
        "    nbr_donnees_entrainement_par_jeu = math.ceil(train_count / len(liste_jeux_donnees_images))\n",
        "    print(\"Nombre de donnees d'entraînement par jeu de données:\",nbr_donnees_entrainement_par_jeu)\n",
        "    print(\"Nombre d'images dans le jeu de données:\",len(liste_jeux_donnees_images))\n",
        "    for index, jeu_donnees_images in enumerate(liste_jeux_donnees_images):\n",
        "        # Combien de points de données pour chaque classe-cible?\n",
        "        points_par_classe = nbr_donnees_entrainement_par_jeu // len(np.unique(fusionner_classes(etiquettes_couverture,classes_couverture)[0]))\n",
        "        print(\"Nombre de points de données par classe-cible:\",points_par_classe)\n",
        "        # obtenir les limites (4 coins) de l'image Landsat\n",
        "        # créer un masque approximatif pour le jeu de données dans les coordonnées géographiques\n",
        "        # create approx dataset mask in geographic coords\n",
        "        # this fcn maps pixel locations in (row, col) coordinates to (x, y) spatial positions\n",
        "        raster_points = jeu_donnees_images.transform * (0, 0), jeu_donnees_images.transform * (jeu_donnees_images.width, 0), jeu_donnees_images.transform * (jeu_donnees_images.width, jeu_donnees_images.height), jeu_donnees_images.transform * (0, jeu_donnees_images.height)\n",
        "        print(\"raster_points:\",raster_points)\n",
        "        l8_proj = Proj(jeu_donnees_images.crs)\n",
        "        new_raster_points = []\n",
        "        # convert the raster bounds from landsat into label crs\n",
        "        for x,y in raster_points:\n",
        "            x,y = transform(l8_proj,projection_cartographique_etiquettes,x,y)\n",
        "            # convert from crs into row, col in label image coords\n",
        "            row, col = label_dataset.index(x, y)\n",
        "            # don't forget row, col is actually y, x so need to swap it when we append\n",
        "            new_raster_points.append((col, row))\n",
        "        # turn this into a polygon\n",
        "        raster_poly = Polygon(new_raster_points)\n",
        "        # Window.from_slices((row_start, row_stop), (col_start, col_stop))\n",
        "        masked_label_image = label_dataset.read(window=Window.from_slices((int(raster_poly.bounds[1]), int(raster_poly.bounds[3])), (int(raster_poly.bounds[0]), int(raster_poly.bounds[2]))))\n",
        "        if merge:\n",
        "            masked_label_image = fusionner_classes(masked_label_image,classes_couverture)[0]\n",
        "        # loop for each class\n",
        "        all_points_per_image = []\n",
        "        bar_progression = tqdm(np.unique(fusionner_classes(etiquettes_couverture,classes_couverture)[0]))\n",
        "        for cls in (bar_progression):\n",
        "            bar_progression.set_description(\"Traitement de la classe-cible « %s »\" % str(classes_couverture[int(cls)]))\n",
        "            cls = int(cls)\n",
        "            # print(\"cls:\",cls,'*'*20)\n",
        "            # mask the label subset image to each class\n",
        "            # pull out the indicies where the mask is true\n",
        "            rows,cols = np.where(masked_label_image[0] == cls)\n",
        "            all_locations = list(zip(rows,cols))\n",
        "            # shuffle all locations\n",
        "            random.shuffle(all_locations)\n",
        "            # now convert to landsat image crs\n",
        "            # TODO need to time this to see if it is slow, can probably optimize\n",
        "            l8_points = []\n",
        "            # TODO Will probably need to catch this for classes smaller than the ideal points per class\n",
        "            if len(all_locations)!=0:\n",
        "                for r,c in all_locations[:points_par_classe]:\n",
        "                # convert label row and col into label geographic space\n",
        "                    x,y = label_dataset.xy(r+raster_poly.bounds[1],c+raster_poly.bounds[0])\n",
        "                # go from label projection into landsat projection\n",
        "                    x,y = transform(projection_cartographique_etiquettes,l8_proj,x,y)\n",
        "                # convert from landsat geographic space into row col\n",
        "                    r,c = jeu_donnees_images.index(x,y)\n",
        "                    l8_points.append((r,c))\n",
        "                all_points_per_image += l8_points\n",
        "        dataset_index_list = [index] * len(all_points_per_image)\n",
        "        dataset_pixels = list(zip(all_points_per_image, dataset_index_list))\n",
        "        pixels_entrainement += dataset_pixels\n",
        "    random.shuffle(pixels_entrainement)\n",
        "    return (pixels_entrainement)\n",
        "\n",
        "print('Code generer_pixels prêt!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiOdUd868Sdm"
      },
      "source": [
        "### Un générateur de tuiles de pixels \n",
        "\n",
        "Le générateur de tuiles prend des positions de pixels et construit des tuiles de pixels au bon format.\n",
        "\n",
        "Ce générateur est fourni directement au modèle « keras » et alimente en continu les données du modèle pendant l'entraînement et la validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY7L3cXJDRQz"
      },
      "outputs": [],
      "source": [
        "# Générateur de données compatible avec Keras qui génère des tuiles et \n",
        "# des étiquettes à la volée à partir d'un ensemble de positions de pixels, \n",
        "# d'un jeu de données d'images satellitaires Landsat à 8 canaux d'images \n",
        "# et d'un jeu de données d'étiquettes décrivant la couverture terrestre \n",
        "def generer_tuiles(jeu_images_Landsat_8canaux, \n",
        "                   jeu_etiquettes_couverture, \n",
        "                   classes_couverture,\n",
        "                   hauteur_tuile, largeur_tuile, \n",
        "                   positions_pixel, \n",
        "                   taille_lot, \n",
        "                   merge=False):\n",
        "\n",
        "    rangee_pixel = 0\n",
        "    colonne_pixel = 0\n",
        "    index_pixel = 0\n",
        "    \n",
        "    # Proj effectue des transformations cartographiques,\n",
        "    # convertit la longitude, la latitude en coordonnées \n",
        "    # natives x,y de la projection cartographique et vice versa\n",
        "    label_proj = Proj(jeu_etiquettes_couverture.crs)\n",
        "    \n",
        "    # On suppose que toutes les images ont le même nombre de bandes spectrales ou canaux\n",
        "    compteur_bandes = jeu_images_Landsat_8canaux[0].count \n",
        "    # band_count = compteur_bandes\n",
        "    compteur_classes = len(classes_couverture)\n",
        "    buffer = math.ceil(hauteur_tuile / 2)\n",
        "  \n",
        "    while True:\n",
        "        # compteur_bandes-1, on enleve une bande parce que nous n'utilisons pas la bande QA\n",
        "        # qui est la bande de contrôle de la qualité (Quality Assessment) de l'image Landsat\n",
        "        lot_images = np.zeros((taille_lot, hauteur_tuile, largeur_tuile, compteur_bandes-1)) \n",
        "        lot_etiquettes = np.zeros((taille_lot,compteur_classes))\n",
        "        b = 0\n",
        "        while b < taille_lot:\n",
        "            # si nous sommes arrivés à la fin des données, il suffit de recommencer\n",
        "            if index_pixel >= len(positions_pixel):\n",
        "                index_pixel = 0\n",
        "            rangee_pixel, colonne_pixel = positions_pixel[index_pixel][0]\n",
        "            index_jeu_donnees = positions_pixel[index_pixel][1]\n",
        "            index_pixel += 1\n",
        "            tuile = jeu_images_Landsat_8canaux[index_jeu_donnees].read(list(np.arange(1, compteur_bandes+1)), \n",
        "                                                              window=Window(colonne_pixel-buffer, \n",
        "                                                                            rangee_pixel-buffer, \n",
        "                                                                            largeur_tuile, \n",
        "                                                                            hauteur_tuile))\n",
        "            if tuile.size == 0:\n",
        "                pass\n",
        "            elif np.amax(tuile) == 0: # don't include if it is part of the image with no pixels\n",
        "                pass\n",
        "            elif np.isnan(tuile).any() == True or -9999 in tuile: \n",
        "                # nous ne voulons pas de tuiles contenant nan ou -999 qui viennent des bordures\n",
        "                # cela gaspille du temps et est inefficace\n",
        "                pass\n",
        "            elif tuile.shape != (compteur_bandes, largeur_tuile, hauteur_tuile):\n",
        "                #print('mauvaise dimension')\n",
        "                #print(tuile.shape)\n",
        "                # tuile aux mauvaises dimensions \n",
        "                pass\n",
        "            elif np.isin(tuile[7,:,:], [352, 368, 392, 416, 432, 480, 840, 864, 880, 904, 928, 944, 1352]).any() == True:\n",
        "                # le pixel ne doit pas être un nuage\n",
        "                # cela semble assez inefficace\n",
        "                # lire: https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/atoms/files/LSDS-1873_US_Landsat_ARD_DFCB_0.pdf\n",
        "                #print(\"J'ai trouvé un nuage!\")\n",
        "                #print(tuile[7,:,:])\n",
        "                pass\n",
        "            else:                \n",
        "                # retrait de la bande de contrôle de qualité (QA pour Quality Assessment) qui n'est pas utilisée\n",
        "                tuile = tuile[0:7]\n",
        "                # reformater du format matriciel (raster) au format d'image normalisé\n",
        "                tuile_reformatee = (reshape_as_image(tuile)  - 982.5) / 1076.5\n",
        "\n",
        "                # obtenir l'étiquette de la classe-cible\n",
        "                # obtenir la géolocalisation du pixel dans l'image\n",
        "                (x, y) = jeu_images_Landsat_8canaux[index_jeu_donnees].xy(rangee_pixel, colonne_pixel)\n",
        "\n",
        "                # si la projection cartographique des étiquettes est différente  \n",
        "                # convertir la localisation du point à partir duquel nous échantillonnons en la même projection que \n",
        "                # l'ensemble de données d'étiquettes si nécessaire\n",
        "                # Rappel: système de référence géodésique - Coordinate Reference System (CRS)\n",
        "                l8_proj = Proj(jeu_images_Landsat_8canaux[0].crs)\n",
        "                if l8_proj != label_proj:\n",
        "                    x,y = transform(l8_proj,label_proj,x,y)\n",
        "\n",
        "                # reference gps in label_image\n",
        "                row, col = jeu_etiquettes_couverture.index(x,y)\n",
        "\n",
        "                # find label\n",
        "                # label image could be huge so we need this to just get a single position\n",
        "                window = ((row, row+1), (col, col+1))\n",
        "                data, classes_couverture = fusionner_classes(jeu_etiquettes_couverture.read(1, \n",
        "                                                                                window=window, \n",
        "                                                                                masked=False, \n",
        "                                                                                boundless=True),\n",
        "                                                            classes_couverture)\n",
        "                label = data[0,0]\n",
        "                # si cette étiquette fait partie d'une couverture non classée alors ignorez la\n",
        "                if label == 0 or np.isnan(label).any() == True:\n",
        "                    pass\n",
        "                else:                   \n",
        "                    # ajouter l'étiquette au lot avec un encodage à un bit discriminant (hot encoding)\n",
        "                    lot_etiquettes[b][label] = 1\n",
        "                    lot_images[b] = tuile_reformatee\n",
        "                    b += 1\n",
        "        yield (lot_images, lot_etiquettes)\n",
        "\n",
        "print('Code generer_tuiles prêt!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUEqYMQZ8qqC"
      },
      "source": [
        "### Une fonction pour fusionner les classes en un sous-ensemble plus petit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi3Wr-e1D9xT"
      },
      "outputs": [],
      "source": [
        "def fusionner_classes(y,classes_couverture):\n",
        "    \n",
        "    # reclasser 255 (pixel blanc intense) à 0 (arrière-plan)\n",
        "    y[y == 255] = 0\n",
        "    \n",
        "    # regrouper \"moyennement aménagé\" 3 et \"faiblement aménagé\" 4\n",
        "    # dans \"milieu aménagé\" 2\n",
        "    y[y == 3] = 2\n",
        "    y[y == 4] = 2\n",
        "    classes_couverture[2] = \"milieu aménagé\"\n",
        "\n",
        "    # regrouper \"espace ouvert aménagé\" 5 et \"pâturage/foin\" 7\n",
        "    # dans \"terre cultivée\" 6\n",
        "    y[y == 5] = 6\n",
        "    y[y == 7] = 6\n",
        "    classes_couverture[6] = \"terre cultivée\"\n",
        "\n",
        "    # regrouper \"forêt de feuillus\" 9 et \"forêt de conifères\" 10,\n",
        "    # \"arbuste/broussaille\" 12, et \"milieu humide boisé palustre\" 13\n",
        "    # dans \"milieu forestier\" 11\n",
        "    y[y == 9] = 11\n",
        "    y[y == 10] = 11\n",
        "    y[y == 12] = 11\n",
        "    y[y == 13] = 11\n",
        "    classes_couverture[11] = \"milieu forestier\"\n",
        "    \n",
        "    # regrouper \"milieu humide arbustif/broussailleux palustre\" 14\n",
        "    # \"milieu humide émergent palustre\" 15, \"milieu humide boisé estuarien\") 16 \n",
        "    # et \"milieu humide arbustif/broussailleux estuarien\" 17, \n",
        "    # dans \"milieu humide\" 18\n",
        "    y[y == 14] = 18\n",
        "    y[y == 15] = 18\n",
        "    y[y == 16] = 18\n",
        "    y[y == 17] = 18\n",
        "    classes_couverture[18] = \"milieu humide\"\n",
        "    \n",
        "    # regrouper \"rivage meuble/non consolidé\" 19 et \"lit de cours d'eau palustre\" 22\n",
        "    # dans \"milieu aquatique\" 21\n",
        "    y[y == 22] = 21\n",
        "    y[y == 19] = 21\n",
        "    classes_couverture[21] = \"milieu aquatique\"\n",
        "    \n",
        "    return(y,classes_couverture)\n",
        "\n",
        "print('Code fusionner_classes prêt!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4EFCx718ite"
      },
      "source": [
        "### Matrice de confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnqxxgogQCQj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def afficher_matrice_confusion(y_true, y_pred, classes, class_dict,\n",
        "                               normalize=False,\n",
        "                               title=None,\n",
        "                               cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Matrice de confusion normalisée'\n",
        "        else:\n",
        "            title = 'Matrice de confusion sans normalisation'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    # convert class_id to class_name using the class_dict\n",
        "    cover_names = []\n",
        "    for cover_class in classes:\n",
        "        cover_names.append(class_dict[cover_class])\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    else:\n",
        "        pass\n",
        "    #print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=cover_names, yticklabels=cover_names,\n",
        "           title=title,\n",
        "           ylabel='Étiquette vraie',\n",
        "           xlabel='Étiquette prédite')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "print('Code afficher_matrice_confusion prêt!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfbbU4aX90T1"
      },
      "source": [
        "## Exploration des données du satellite Landsat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR8CLHqcAuhc"
      },
      "source": [
        "### Lecture des métadonnées sur les images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt_q6_SQ48wZ"
      },
      "outputs": [],
      "source": [
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Lecture des métadonnées du fichier de données matricielles (raster) Landsat\n",
        "meta_donnees_images_landsat = rasterio.open(\"data/landsat_image.tif\")\n",
        "\n",
        "# Vérification du nombre de canaux / bandes spectrales par image\n",
        "nombre_canaux = meta_donnees_images_landsat.count\n",
        "print(\"Nombre de canaux par image: {nc}\\n\".format(nc=nombre_canaux))\n",
        "\n",
        "# Combien de rangées et de colonnes dans les données?\n",
        "lignes, colonnes = meta_donnees_images_landsat.shape\n",
        "print(\"Le format des images est: {l} lignes x {c} colonnes\\n\".format(l=lignes, c=colonnes))\n",
        "\n",
        "# Quelle est la version de la bibliothèque Rasterio: \n",
        "print(\"Version de Rasterio: {v}\\n\".format(v=rasterio.__version__))\n",
        "\n",
        "# Quel pilote (driver) a été utilisé pour lire les données matricielles (raster)?\n",
        "pilote = meta_donnees_images_landsat.driver\n",
        "print(\"Pilote données matriciel utilisé: {p}\\n\".format(p=pilote))\n",
        "\n",
        "# Quelle est la projection géographique des données?\n",
        "projection_geo = meta_donnees_images_landsat.crs\n",
        "print(\"Projection géographique utilisée:\\n\",projection_geo)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQOn2wwF96-5"
      },
      "source": [
        "###  Lecture et chargement en mémoire des images \n",
        "ou données matricielles (raster), images satellitaires Landsat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBgu28Kj7WHw"
      },
      "outputs": [],
      "source": [
        "images_landsat = meta_donnees_images_landsat.read()\n",
        "images_landsat.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYIRsrdtAuhd"
      },
      "source": [
        "### Calcul de l'indice de végétation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsFccm-9-ACt"
      },
      "source": [
        "Maintenant calculons l'indice de végétation<sup>1</sup>, un indicateur utilisé en télédétection pour évaluer si la cible observée contient de la végétation. L'indice de végétation se calcule à partir des réflectances mesurées dans les bandes visible rouge et le proche infrarouge.\n",
        "<hr/>\n",
        "<span style=\"font-size:80%\"><sup>1</sup><b>Note - terminologie:</b> En français,  « indice de végétation par différence normalisée (IVDN) » ou « indice différentiel normalisé de végétation » ou plus simplement « indice de végétation ». En anglais, « <i>Normalized Difference Vegetation Index</i> (<i>NDVI</i>) ».</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE4HiOkb7Py4"
      },
      "outputs": [],
      "source": [
        "bande_proche_infrarouge = images_landsat[4, :, :]\n",
        "bande_rouge = images_landsat[3, :, :]\n",
        "\n",
        "indice_vegetation = np.clip((bande_proche_infrarouge.astype(float) - bande_rouge.astype(float)) / (bande_proche_infrarouge.astype(float) + bande_rouge.astype(float)), -1,1)\n",
        "\n",
        "print('Code exécuté!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dyg1pGY7Sjx"
      },
      "outputs": [],
      "source": [
        "print('\\nIndice de végétation maximum: {m:.2f}'.format(m=indice_vegetation.max()))\n",
        "print('Indice de végétation moyen: {m:.2f}'.format(m=indice_vegetation.mean()))\n",
        "print('Indice de végétation médian: {m:.2f}'.format(m=np.median(indice_vegetation)))\n",
        "print('Indice de végétation minimum: {m:.2f}'.format(m=indice_vegetation.min()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxRfYdYzAuhh"
      },
      "source": [
        "Examinons la répartition statistique de l'indice de végétation avec un histogramme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhjFb8M_8HJ4"
      },
      "outputs": [],
      "source": [
        "figure, axes = plt.subplots(figsize=(1.62*7,7))\n",
        "# Nous pouvons définir le nombre de colonnes de l'histogramme avec l'argument `bins`\n",
        "axes.hist(indice_vegetation.flatten(), bins=50)\n",
        "plt.title(\"Histogramme de l'indice de végétation\")\n",
        "plt.xlabel(\"Indice de végétation\")\n",
        "plt.ylabel(\"Fréquence\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJIgZNds-PP2"
      },
      "source": [
        "### Histogramme multicanal de l'image\n",
        "L'indice de végétation semble normal, regardons maintenant l'histogramme de l'image dans son intégralité.\n",
        "\n",
        "Qu'est-ce que la valeur numérique (Digital Number, DN)? Dans les systèmes de télédétection, la la valeur numérique est une valeur attribuée à un pixel, généralement sous la forme d'un entier compris entre 0 et 255 (c'est-à-dire un octet). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-nqFDHh6OtK",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "figure, axes = plt.subplots(figsize=(1.62*7,7))\n",
        "\n",
        "rasterio.plot.show_hist(meta_donnees_images_landsat.read([1,2,3,4,5,6,7]), \n",
        "                        bins=100, \n",
        "                        histtype='stepfilled', \n",
        "                        lw=0.0, \n",
        "                        stacked=False, \n",
        "                        alpha=0.3,\n",
        "                        ax = axes,\n",
        "                       title=\"Histogramme multicanal de l'image\",\n",
        "                       label=[1,2,3,4,5,6,7]\n",
        "                       )\n",
        "axes.set_xlabel('Valeur numérique des pixels')\n",
        "_ = axes.set_ylabel('Fréquence')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOTMZxNz7Vx3"
      },
      "source": [
        "###  Lecture et chargement en mémoire des étiquettes ou annotation de couverture "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVou6etFAgr8"
      },
      "outputs": [],
      "source": [
        "meta_donnees_etiquettes_couverture = rasterio.open('data/labels_image.tif')\n",
        "\n",
        "meta_donnees_etiquettes_couverture.crs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2_5RZq2Auhj"
      },
      "outputs": [],
      "source": [
        "# nous fusionnons pour limiter le nombre de classes avec lesquelles nous travaillons\n",
        "etiquettes_couverture, classes_couverture = fusionner_classes(meta_donnees_etiquettes_couverture.read(),classes_couverture)\n",
        "etiquettes_couverture.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuXF-HFsAuhk"
      },
      "source": [
        "### Visualisation - Image Landsat, couverture terrestre et indice de végétation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2gE319v-EVj"
      },
      "source": [
        "Maintenant, nous allons visualiser l'image Landsat, une carte en fausses couleurs des de la couverture terrestre et l'indice de végétation (NDVI) côte à côte :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odb65Zhy5FRB"
      },
      "outputs": [],
      "source": [
        "from rasterio.plot import adjust_band\n",
        "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
        "from rasterio.plot import show\n",
        "\n",
        "# pull out the bands we want to visualize\n",
        "index = np.array([3, 2, 1])\n",
        "colors = images_landsat[index, :, :].astype(np.float64)\n",
        "\n",
        "# we'll use the values to stretch the landsat image based on the above histogram\n",
        "max_val = 2500\n",
        "min_val = 0\n",
        "\n",
        "# enforce maximum and minimum values\n",
        "colors[colors[:, :, :] > max_val] = max_val\n",
        "colors[colors[:, :, :] < min_val] = min_val\n",
        "\n",
        "for b in range(colors.shape[0]):\n",
        "    colors[b, :, :] = colors[b, :, :] * 1 / (max_val - min_val)\n",
        "\n",
        "# rasters are in the format [bands, rows, cols] \n",
        "# whereas images are typically [rows, cols, bands]\n",
        "# and so our array needs to be reshaped\n",
        "print(colors.shape)\n",
        "colors_reshaped = reshape_as_image(colors)\n",
        "print(colors_reshaped.shape)\n",
        "\n",
        "# next setup a colormap for our map\n",
        "fausses_couleurs = dict((\n",
        "    (0, (245,245,245, 255)), # arrière-plan # Background\n",
        "    (1, (0,0,0)), # non-classé # Unclassified (Cloud, Shadow, etc)\n",
        "    (2, (255,0,0)), # fortement aménagé # High Intensity Developed\n",
        "    (3, (255, 110, 51)), # moyennement aménagé # Medium Intensity Developed\n",
        "    (4, (255, 162, 51)), # faiblement aménagé # Low Intensity Developed\n",
        "    (5, (255, 162, 51)), # espace ouvert aménagé # Open Space Developed\n",
        "    (6, (162, 89, 0)), # terre cultivée # Cultivated Land\n",
        "    (7, (229, 221, 50)), # pâturage/foin # Pasture/Hay\n",
        "    (8, (185, 251, 96)), # prairie # Grassland\n",
        "    (9, (83, 144, 0)), # forêt de feuillus # Deciduous Forest\n",
        "    (10, (13, 118, 0  )), # forêt de conifères # Evergreen Forest\n",
        "    (11, (62, 178, 49)), # forêt mixte / Mixed Forest\n",
        "    (12, (100, 241, 125)), # arbuste/broussaille # Scrub/Shrub\n",
        "    (13, (68, 160, 85)), # milieu humide boisé palustre # Palustrine Forested Wetland\n",
        "    (14, (118, 192, 131)), # milieu humide arbustif/broussailleux palustre # Palustrine Scrub/Shrub Wetland\n",
        "    (15, (188, 0, 211)), # milieu humide émergent palustre # Palustrine Emergent Wetland\n",
        "    (16, (188, 0, 211)), # milieu humide boisé estuarien # Estuarine Forested Wetland\n",
        "    (17, (0, 0, 0)), # milieu humide arbustif/broussailleux estuarien # Estuarine Scrub/Shrub Wetland\n",
        "    (18, (172, 0, 191)), # milieu humide émergent estuarien # Estuarine Emergent Wetland\n",
        "    (19, (159, 251, 255)), # rivage meuble/non consolidé # Unconsolidated Shore \n",
        "    (20, (172, 177, 68)), # terre nue # Bare Land\n",
        "    (21, (29, 0, 189)), # eau # Water\n",
        "    (22, (40, 40, 40)), # lit de cours d'eau palustre # Pal Bed\n",
        "))\n",
        "\n",
        "# n = int(np.max(jeu_etiquettes_couverture)) + 1\n",
        "n = int(np.max(etiquettes_couverture)) + 1\n",
        "\n",
        "# Put 0 - 255 as float 0 - 1\n",
        "for k in fausses_couleurs:\n",
        "    v = fausses_couleurs[k]\n",
        "    _v = [_v / 255.0 for _v in v]\n",
        "    fausses_couleurs[k] = _v\n",
        "    \n",
        "index_fausses_couleurs = [fausses_couleurs[key] for key in range(0, n)]\n",
        "\n",
        "cmap_fausses_couleurs = plt.matplotlib.colors.ListedColormap(index_fausses_couleurs, \n",
        "                                                             'Classification', \n",
        "                                                             n)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(1.62*17, 17)) \n",
        "\n",
        "# Afficher l'image en couleur\n",
        "axes[0].imshow(colors_reshaped)\n",
        "axes[0].set_title('Image Landsat couleur')\n",
        "\n",
        "# Afficher les classes de couverture en fausses couleurs\n",
        "axes[1].imshow(etiquettes_couverture[0,:, :],\n",
        "               cmap=cmap_fausses_couleurs,\n",
        "               interpolation='none')\n",
        "import matplotlib.patches as mpatches\n",
        "patches =[mpatches.Patch(color=cmap_fausses_couleurs.colors[classe_id],label=classes_couverture[classe_id]) \n",
        "          for classe_id in range(len(cmap_fausses_couleurs.colors))]\n",
        "axes[1].set_title('Classes\\nde couverture')\n",
        "axes[1].legend(handles=patches, loc=(1.01,0), borderaxespad=0.)\n",
        "\n",
        "# Afficher l'indice de végétation\n",
        "axes[2].imshow(indice_vegetation, \n",
        "              cmap='RdYlGn')\n",
        "axes[2].set_title('Indice de végégation')\n",
        "\n",
        "# Afficher les images\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKPUf1cNAuhl"
      },
      "outputs": [],
      "source": [
        "cmap_fausses_couleurs.colors[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE-bM05N-m66"
      },
      "source": [
        "Combien y a-t-il de pixels dans chaque classe ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2unJDbI-BKyd"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(etiquettes_couverture, return_counts=True)\n",
        "hist_data = [(classes_couverture[classe_id],counts) for classe_id,counts in list(zip(unique, counts))]\n",
        "hist_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM19RXI7Auhs"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(1.62*6, 6)) \n",
        "plt.yscale('log')\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel(\"Type de couverture\")\n",
        "plt.ylabel(\"Log(Fréquence)\")\n",
        "plt.title(\"Répartition des types de couverture terrestre - échelle logarithmique\")\n",
        "_ = plt.bar([classe[0] for classe in hist_data], [classe[1] for classe in hist_data])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prfxo0NFAuhu"
      },
      "source": [
        "### Génération des données d'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gedIuuS8Auhv"
      },
      "outputs": [],
      "source": [
        "# Le code ci-dessous génère des avertissements\n",
        "# nous allons donc les supprimer pour le moment \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "URzhYRbRAuhv"
      },
      "outputs": [],
      "source": [
        "pixels_entrainement = generer_pixels([meta_donnees_images_landsat],\n",
        "                                     meta_donnees_etiquettes_couverture,\n",
        "                                     etiquettes_couverture,\n",
        "                                     classes_couverture,\n",
        "                                     3000,\n",
        "                                     True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9krQTTu-tkwU"
      },
      "source": [
        "### Test du générateur de tuiles\n",
        "\n",
        "Afficher des lots d'images et d'étiquettes et vérifier leurs dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCXTnWK8J8LE",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "im_batch = None\n",
        "\n",
        "count = 0\n",
        "\n",
        "for (im, label) in generer_tuiles([meta_donnees_images_landsat], \n",
        "                                  meta_donnees_etiquettes_couverture, \n",
        "                                  classes_couverture,\n",
        "                                  128, 128, \n",
        "                                  pixels_entrainement, \n",
        "                                  10):\n",
        "    # Arrêter après 3 images \n",
        "    if count > 3:\n",
        "        break\n",
        "    print('Image')\n",
        "    print(im.shape)\n",
        "#     for index_lot in range(10):\n",
        "#         for canal in range(7):\n",
        "#             plt.imshow((normalize(im[index_lot,:,:,canal])))\n",
        "#             plt.show()\n",
        "    print('Label')\n",
        "    print(label.shape)\n",
        "    print('----')\n",
        "    count += 1\n",
        "    im_batch = im\n",
        "    label_batch = label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JirwdIwpAuhw"
      },
      "source": [
        "### Visualisation de tuiles\n",
        "\n",
        "Maintenant, visualisons des tuiles réelles. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Nzeov9QKNGx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize(image):\n",
        "    return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(1.62*10, 10)) \n",
        "axes[0,0].imshow(normalize(im_batch[0,:,:,3:6]))\n",
        "axes[0,0].set_title(classes_couverture[np.argmax(label_batch[0])])\n",
        "axes[0,1].imshow(normalize(im_batch[1,:,:,3:6]))\n",
        "axes[0,1].set_title(classes_couverture[np.argmax(label_batch[1])])\n",
        "axes[0,2].imshow(normalize(im_batch[2,:,:,3:6]))\n",
        "axes[0,2].set_title(classes_couverture[np.argmax(label_batch[2])])\n",
        "axes[1,0].imshow(normalize(im_batch[3,:,:,3:6]))\n",
        "axes[1,0].set_title(classes_couverture[np.argmax(label_batch[3])])\n",
        "axes[1,1].imshow(normalize(im_batch[4,:,:,3:6]))\n",
        "axes[1,1].set_title(classes_couverture[np.argmax(label_batch[4])])\n",
        "axes[1,2].imshow(normalize(im_batch[5,:,:,3:6]))\n",
        "axes[1,2].set_title(classes_couverture[np.argmax(label_batch[5])])\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VMWZ9hMuIBO"
      },
      "source": [
        "### Générer un jeu de données d'entraînement de tuiles 1x1 pour scikit-learn \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxVPxQPW6yks"
      },
      "outputs": [],
      "source": [
        "im_batch = None\n",
        "label_batch = None\n",
        "\n",
        "sample_size = 500\n",
        "\n",
        "count = 0\n",
        "    \n",
        "for (im, label) in generer_tuiles([meta_donnees_images_landsat], \n",
        "                                  meta_donnees_etiquettes_couverture, \n",
        "                                  classes_couverture, \n",
        "                                  1, 1, \n",
        "                                  pixels_entrainement, \n",
        "                                  sample_size):\n",
        "    if count > 0:\n",
        "        break\n",
        "    print('Batch Shape')\n",
        "    print(im.shape)\n",
        "    print('Label Shape')\n",
        "    print(label.shape)\n",
        "    print('----')\n",
        "    count += 1\n",
        "    im_batch = im\n",
        "    label_batch = label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZJKYR_DTcCU"
      },
      "source": [
        "#### Reformater les données\n",
        "Reformater les donnés pour scikit-learn qui a besoin de données au format `(echantillons, bandes)` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZqFVntt7k2y"
      },
      "outputs": [],
      "source": [
        "im_batch[0,:,:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUhfVaq28Xfi"
      },
      "outputs": [],
      "source": [
        "im_batch_reshaped = im_batch.reshape(sample_size,7)\n",
        "im_batch_reshaped[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNs6MwKz-myd"
      },
      "source": [
        "### Visualiser les signatures spectrales\n",
        "\n",
        "Examinons le spectre des intensités pour les différentes bandes ou canaux. Rappelons que la réflectance est le rapport de l'intensité d'une onde réfléchie sur l'intensité de l'onde incidente. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgYCvsiA8NFd"
      },
      "outputs": [],
      "source": [
        "fig, axe = plt.subplots(1,1, figsize=[1.62*8,8])\n",
        "\n",
        "liste_couleurs = ['red', # 'milieu aménagé' 2\n",
        "                  'gold', # 'terre cultivée' 6\n",
        "                  'orange', # 'prairie' 8\n",
        "                  'forestgreen', # 'milieu forestier' 11\n",
        "                  'skyblue', # 'milieu humide' 18\n",
        "                  'brown', # 'terre nue' 20\n",
        "                  'blue'] # eau 21\n",
        "\n",
        "# numbers 1-8\n",
        "band_count = np.arange(1,8)\n",
        "\n",
        "y = np.argmax(label_batch, axis=1)\n",
        "X = im_batch_reshaped\n",
        "\n",
        "classes = np.unique(y)\n",
        "for index_couleur,class_type in enumerate(classes): \n",
        "    band_intensity = np.mean(X[y==class_type, :], axis=0)\n",
        "    axe.plot(band_count, \n",
        "             band_intensity, \n",
        "             color=liste_couleurs[index_couleur], \n",
        "             label=classes_couverture[class_type])\n",
        "# plot them as lines\n",
        "\n",
        "# Add some axis labels\n",
        "axe.set_xlabel('Bande #')\n",
        "axe.set_ylabel('Valeur de réflectance')\n",
        "\n",
        "# Add a title\n",
        "axe.set_title(\"Spectre d'intensité des différentes bandes\")\n",
        "_ = axe.legend(loc='upper left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM6eYaTsAuh0"
      },
      "source": [
        "## Création d'une base de référence pour la classification "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFyPPa6K_VmH"
      },
      "source": [
        "### Générer un ensemble de données d'entraînement de tuiles 1x1 pour scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNfWrnY9_DXe"
      },
      "outputs": [],
      "source": [
        "im_batch = None\n",
        "label_batch = None\n",
        "\n",
        "sample_size = 800\n",
        "train_count = 600\n",
        "\n",
        "count = 0\n",
        "    \n",
        "for (img, label) in generer_tuiles([meta_donnees_images_landsat], \n",
        "                                  meta_donnees_etiquettes_couverture,\n",
        "                                  classes_couverture,\n",
        "                                  1, 1, \n",
        "                                  pixels_entrainement, \n",
        "                                  sample_size):\n",
        "    if count > 0:\n",
        "        break\n",
        "    print('Batch Shape')\n",
        "    print(img.shape)\n",
        "    print('Label Shape')\n",
        "    print(label.shape)\n",
        "    print('----')\n",
        "    count += 1\n",
        "    img_batch = img\n",
        "    label_batch = label\n",
        "\n",
        "img_batch_reshaped = img_batch.reshape(sample_size,7)\n",
        "\n",
        "X_train = img_batch_reshaped[:train_count]\n",
        "X_val = img_batch_reshaped[train_count:]\n",
        "y_train = np.argmax(label_batch, axis=1)[:train_count]\n",
        "y_val = np.argmax(label_batch, axis=1)[train_count:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR4cckuf_ihh"
      },
      "source": [
        "### Algorithme de la forêt aléatoire (<i>random forest</i>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CBzgR_L_8nV"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize our model with 500 trees\n",
        "rf = RandomForestClassifier(n_estimators=500, \n",
        "                            oob_score=True)\n",
        "\n",
        "# Fit our model to training data\n",
        "rf = rf.fit(X_train, y_train)\n",
        "\n",
        "print('Exactitude de: {accuracy:.2f}%'.format(accuracy = rf.score(X_val, y_val)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwXYA-f-A1cc"
      },
      "outputs": [],
      "source": [
        "pred_index = rf.predict(X_val)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "_ = afficher_matrice_confusion(y_val,\n",
        "                               pred_index,\n",
        "                               classes=np.array(list(classes_couverture)),\n",
        "                               class_dict=classes_couverture)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o50pTRgkvvMU"
      },
      "outputs": [],
      "source": [
        "# Plot normalized confusion matrix\n",
        "_ = afficher_matrice_confusion(y_val,\n",
        "                               pred_index,\n",
        "                               classes=np.array(list(classes_couverture)),\n",
        "                               class_dict=classes_couverture,\n",
        "                               normalize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owJqFXTAAuh2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
        "print(\"Exactitude: {exactitude:.2f}%\".format(exactitude = accuracy_score(y_val, pred_index)*100)) \n",
        "print(\"Précision: {precision:.2f}%\".format(precision = precision_score(y_val, pred_index, average='weighted')*100))\n",
        "print(\"Rappel: {rappel:.2f}%\".format(rappel = recall_score(y_val, pred_index, average='weighted')*100))\n",
        "print(\"Métrique F1: {f1:.2f}%\".format(f1 = f1_score(y_val, pred_index, average='weighted')*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmjcVCo0VDZu"
      },
      "source": [
        "Ces modèles ne sont pas terribles mais ils classent mal une bonne partie des prairies, des terres cultivées et des terres anthropoformées. Voyons si nous pouvons l'améliorer !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdRkZ7QDtrTF"
      },
      "source": [
        "## Création et entraînement d'un réseau convolutif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imb4uCzIAuh2"
      },
      "source": [
        "### Importer les bibliothèques `keras` nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgPrE7nfKgBK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CSQtcDutv5R"
      },
      "source": [
        "### Définir les hyperparamètres du résau convolutif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so-MzsE6K9wY"
      },
      "outputs": [],
      "source": [
        "batch_size = 25\n",
        "epochs = 50\n",
        "num_classes = len(classes_couverture)\n",
        "\n",
        "# input image dimensions\n",
        "tile_side = 32\n",
        "img_rows, img_cols = tile_side, tile_side\n",
        "img_bands = meta_donnees_images_landsat.count- 1\n",
        "\n",
        "input_shape = (img_rows, img_cols, img_bands)\n",
        "print(input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otFus3i5txy6"
      },
      "source": [
        "### Créer l'architecture du réseau convolutif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku9yk42NKq4g"
      },
      "outputs": [],
      "source": [
        "modele = Sequential()\n",
        "\n",
        "modele.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "modele.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modele.add(Conv2D(64, (3, 3), padding='same'))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "\n",
        "modele.add(Conv2D(64, (3, 3), padding='same'))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "modele.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modele.add(Conv2D(128, (3, 3), padding='same'))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "modele.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modele.add(Conv2D(256, (3, 3), padding='same'))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "modele.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modele.add(Dropout(0.25))\n",
        "\n",
        "modele.add(Flatten())\n",
        "modele.add(Dense(128))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "modele.add(Dropout(0.25))\n",
        "\n",
        "modele.add(Dense(128))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "modele.add(Dropout(0.25))\n",
        "\n",
        "modele.add(Dense(num_classes))\n",
        "modele.add(Activation('softmax'))\n",
        "\n",
        "modele.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkvcOnqLt2cz"
      },
      "source": [
        "### Choisir la fonction d'optimisation et compiler le modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLAmHQJXLXBo"
      },
      "outputs": [],
      "source": [
        "sgd = tf.keras.optimizers.SGD(learning_rate=0.0001, \n",
        "                              decay=1e-6, \n",
        "                              momentum=0.9, \n",
        "                              nesterov=True)\n",
        "metrics=['accuracy']\n",
        "\n",
        "modele.compile(optimizer=sgd, \n",
        "               loss='categorical_crossentropy', \n",
        "               metrics=metrics)\n",
        "\n",
        "print(\"Modèle compilé\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7MkRMH9t0Em"
      },
      "source": [
        "### Diviser les données entre donnés d'entraînement et données de validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSvnToUNLQj4"
      },
      "outputs": [],
      "source": [
        "train_to_val_ratio = 0.8\n",
        "train_px = pixels_entrainement[:int(len(pixels_entrainement)*train_to_val_ratio)]\n",
        "val_px = pixels_entrainement[int(len(pixels_entrainement)*train_to_val_ratio):]\n",
        "print(\"Nombre d'exemples d'entraînement: {n_entrainement} \\nNombre d'exemples de validation: {n_validation}\".\n",
        "      format(n_entrainement=len(train_px),n_validation=len(val_px)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faJAqfMFt-To"
      },
      "source": [
        "### Entraîner le modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU8eVd2rLciQ"
      },
      "outputs": [],
      "source": [
        "traces = modele.fit(generer_tuiles([meta_donnees_images_landsat], \n",
        "                                   meta_donnees_etiquettes_couverture, \n",
        "                                   classes_couverture,\n",
        "                                   tile_side, \n",
        "                                   tile_side, \n",
        "                                   train_px, \n",
        "                                   batch_size, \n",
        "                                   merge=True), \n",
        "                    steps_per_epoch=len(train_px) // batch_size, \n",
        "                    epochs=epochs, \n",
        "                    verbose=1,\n",
        "                    validation_data=generer_tuiles([meta_donnees_images_landsat], \n",
        "                                                   meta_donnees_etiquettes_couverture, \n",
        "                                                   classes_couverture,\n",
        "                                                   tile_side, \n",
        "                                                   tile_side, \n",
        "                                                   val_px, \n",
        "                                                   batch_size, \n",
        "                                                   merge=True),\n",
        "                    validation_steps=len(val_px) // batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc5KFRqQAuh-"
      },
      "source": [
        "### Affichage des courbes d'entraînement et de validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHmYVE7eAuh-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(1.62*7,7))\n",
        "plt.plot(traces.history['accuracy'])\n",
        "plt.plot(traces.history['val_accuracy'])\n",
        "plt.title(\"Courbes d'exactitude du modèle\")\n",
        "plt.ylabel(\"Exactitude (%)\")\n",
        "plt.xlabel(\"Nombre d'itérations / époques\")\n",
        "_ = plt.legend(['Entraînement', 'Validation'], loc='upper left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7Wcp2MMAuh_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(1.62*7,7))\n",
        "plt.plot(traces.history['loss'])\n",
        "plt.plot(traces.history['val_loss'])\n",
        "plt.title(\"Courbes d'erreur du modèle\")\n",
        "plt.ylabel(\"Erreur\")\n",
        "plt.xlabel(\"Nombre d'itérations / époques\")\n",
        "_ = plt.legend(['Entraînement', 'Validation'], loc='upper left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkdfUOwEAuh_"
      },
      "source": [
        "### Génération de données test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMXSqDvgAuh_"
      },
      "outputs": [],
      "source": [
        "predictions = modele.predict(generer_tuiles([meta_donnees_images_landsat],\n",
        "                                            meta_donnees_etiquettes_couverture,\n",
        "                                            classes_couverture,\n",
        "                                            tile_side,\n",
        "                                            tile_side,\n",
        "                                            val_px,\n",
        "                                            batch_size,\n",
        "                                            merge=True),\n",
        "                             steps=len(val_px) // batch_size,\n",
        "                             verbose=1)\n",
        "\n",
        "eval_generator = generer_tuiles([meta_donnees_images_landsat], \n",
        "                                meta_donnees_etiquettes_couverture,\n",
        "                                classes_couverture,\n",
        "                                tile_side, \n",
        "                                tile_side, \n",
        "                                val_px, \n",
        "                                1, \n",
        "                                merge=True)\n",
        "\n",
        "labels = np.empty(predictions.shape)\n",
        "count = 0\n",
        "while count < len(labels):\n",
        "    image_b, label_b = next(eval_generator)\n",
        "    labels[count] = label_b\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRTAYA-nuCE4"
      },
      "source": [
        "###  Affichage d'une matrice de confusion :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tUXLrxLAuiA"
      },
      "outputs": [],
      "source": [
        "label_index = np.argmax(labels, axis=1)     \n",
        "pred_index = np.argmax(predictions, axis=1)\n",
        "\n",
        "np.set_printoptions(precision=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR9xuMWgYTO7"
      },
      "outputs": [],
      "source": [
        "# Plot non-normalized confusion matrix\n",
        "_ = afficher_matrice_confusion(label_index,\n",
        "                               pred_index,\n",
        "                               classes=np.array(list(classes_couverture)),\n",
        "                               class_dict=classes_couverture)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB7hQr-SwLf9"
      },
      "outputs": [],
      "source": [
        "# Plot normalized confusion matrix\n",
        "_ = afficher_matrice_confusion(label_index, \n",
        "                               pred_index,\n",
        "                               classes=np.array(list(classes_couverture)),\n",
        "                               class_dict=classes_couverture,\n",
        "                               normalize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDG9R3PJAuiA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
        "print(\"Exactitude: {exactitude:.2f}%\".format(exactitude = accuracy_score(label_index, pred_index)*100)) \n",
        "print(\"Précision: {precision:.2f}%\".format(precision = precision_score(label_index, pred_index, average='weighted')*100))\n",
        "print(\"Rappel: {rappel:.2f}%\".format(rappel = recall_score(label_index, pred_index, average='weighted')*100))\n",
        "print(\"Métrique F1: {f1:.2f}%\".format(f1 = f1_score(label_index, pred_index, average='weighted')*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWPacOScAuiB"
      },
      "source": [
        "Pas mal! Environ 10 % d'amélioration pour un réseau convolutif par rapport à un algorithme d'apprentissage automatique plus classique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB5tbfy0umpM"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Vous avez expérimenté avec un certain nombre de techniques d'exploration de données satellitaires et vu comment utiliser Keras pour construire un réseau convolutif profond pour une classification efficace de la couverture terrestre. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8or116_iuohq"
      },
      "outputs": [],
      "source": [
        "print(\"Exécution du carnet web IPython terminée\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94Jx1CH8AuiB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "landcover_analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}