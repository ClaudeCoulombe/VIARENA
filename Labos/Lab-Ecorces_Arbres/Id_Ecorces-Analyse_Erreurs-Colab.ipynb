{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca876af",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-Ecorces_Arbres/Id_Ecorces-Analyse_Erreurs-Colab\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "### Rappel - Fonctionnement d'un carnet web iPython\n",
    "\n",
    "* Pour exécuter le code contenu dans une cellule d'un carnet iPython, cliquez dans la cellule et faites (⇧↵, shift-enter) \n",
    "* Le code d'un carnet iPython s'exécute séquentiellement de haut en bas de la page. Souvent, l'importation d'une bibliothèque Python ou l'initialisation d'une variable est préalable à l'exécution d'une cellule située plus bas. Il est donc recommandé d'exécuter les cellules en séquence. Enfin, méfiez-vous quand vous faites des retours en arrière, cela peut réinitialiser certaines variables.\n",
    "\n",
    "SVP, déployez toutes les cellules en sélectionnant l'item « Développer les rubriques » de l'onglet « Affichage »."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa8407",
   "metadata": {},
   "source": [
    "# Identification d'arbres à partir de leur écorce\n",
    "## Réseau convolutif, apprentissage par transfert et amplification des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e722d1",
   "metadata": {},
   "source": [
    "### Inspiration et droits d'auteur\n",
    "\n",
    "Ce laboratoire s'inspire de plusieurs oeuvres en logiciels libres qui ont été transformées dont:\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/tutorials/images/transfer_learning\" target='_blank'>Transfer learning and fine-tuning</a> - site Google / Tutoriels TensorFlow\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/tutorials/images/data_augmentation\" target='_blank'>Data augmentation</a> - site Google / Tutoriels TensorFlow\n",
    "\n",
    "##### Copyright (c) 2017,  François Chollet  \n",
    "##### Copyright (c) 2019-2022, The TensorFlow Authors.\n",
    "##### Copyright (c) 2022, Claude Coulombe\n",
    "\n",
    "Le contenu de cette page est sous licence <a href=\"https://creativecommons.org/licenses/by/4.0/deed.fr\" target='_blank'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>,<br/>et les exemples de code sont sous <a href=\"https://www.apache.org/licenses/LICENSE-2.0\" target='_blank'>licence Apache 2.0</a>.\n",
    "\n",
    "#### Données\n",
    "\n",
    "Les données sur les écorces d'arbres proviennent de <a href=\"https://data.mendeley.com/research-data/?search=barknet\">BarkNet<sup>1</sup></a>, une banque en données ouvertes sous licence MIT de 23 000 photos d'écorces d'arbres en haute résolution prises avec des téléphones intelligents par une équipe d'étudiants et de chercheurs du <a href=\"https://www.sbf.ulaval.ca/\" target='_blank'>Département des sciences du bois et de la forêt de l'Université Laval</a> à Québec.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c20f2a",
   "metadata": {},
   "source": [
    "# Analyse d'erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5571b00f",
   "metadata": {},
   "source": [
    "## Fixer le hasard pour la reproductibilité\n",
    "\n",
    "La mise au point de réseaux de neurones implique certains processus aléatoires. Afin de pouvoir reproduire et comparer vos résultats d'expérience, vous fixez temporairement l'état aléatoire grâce à un germe aléatoire unique.\n",
    "\n",
    "Pendant la mise au point, vous fixez temporairement l'état aléatoire pour la reproductibilité mais vous répétez l'expérience avec différents germes ou états aléatoires et prenez la moyenne des résultats.\n",
    "<br/>\n",
    "\n",
    "**Note** : Pour un système en production, vous ravivez simplement l'état  purement aléatoire avec l'instruction `GERME_ALEATOIRE = None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3869214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germe aléatoire fixé\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Définir un germe aléatoire\n",
    "GERME_ALEATOIRE = 1\n",
    "\n",
    "# Définir un état aléatoire pour Python\n",
    "os.environ['PYTHONHASHSEED'] = str(GERME_ALEATOIRE)\n",
    "\n",
    "# Définir un état aléatoire pour Python random\n",
    "import random\n",
    "random.seed(GERME_ALEATOIRE)\n",
    "\n",
    "# Définir un état aléatoire pour NumPy\n",
    "import numpy as np\n",
    "np.random.seed(GERME_ALEATOIRE)\n",
    "\n",
    "# Définir un état aléatoire pour TensorFlow\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(GERME_ALEATOIRE)\n",
    "\n",
    "# Note: Retrait du comportement déterministe\n",
    "# à cause de keras.layers.RandomContrast(...)\n",
    "# dont il n'existe pas de version déterministe\n",
    "# os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "# os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "print(\"Germe aléatoire fixé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19692be9",
   "metadata": {},
   "source": [
    "## Acquisition des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7da08",
   "metadata": {},
   "source": [
    "L'analyse d'erreur requiert l'examen des données d'entraînement, il faut donc les obtenir.\n",
    "\n",
    "\n",
    "Notez qu'en raison, des limites imposées par Colab, nous avons échantillonné 1.5 Go de données sur les 32 Go de données initiales de BarkNet. \n",
    "\n",
    "Aussi, nous n'avons pas inclus Acer platanoides (2), Pinus rigida (15) et Populus grandidentata (18) car il n'y a pas suffisamment d'images dans ces catégories pour obtenir des résultats significatifs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c87fb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code exécuté\n"
     ]
    }
   ],
   "source": [
    "data_ecorces = {\n",
    "    'SAB': 1,  \n",
    "#    'ERB': 2,  # Pas assez de spécimens - seulement 1\n",
    "    'ERR': 3, \n",
    "    'ERS': 4, \n",
    "    'BOJ': 5, \n",
    "    'BOP': 6,\n",
    "    'HEG': 7,  \n",
    "    'FRA': 8, \n",
    "    'MEL': 9,  \n",
    "    'OSV': 10, \n",
    "    'EPO': 11,\n",
    "    'EPB': 12,\n",
    "    'EPN': 13,\n",
    "    'EPR': 14,\n",
    "#    'PID': 15, # Pas assez de spécimens - seulement 4\n",
    "    'PIR': 16, \n",
    "    'PIB': 17, \n",
    "#    'PEG': 18, # Pas assez de spécimens - seulement 3\n",
    "    'PET': 19, \n",
    "    'CHR': 20,\n",
    "    'THO': 21, \n",
    "    'PRU': 22, \n",
    "    'ORA': 23  \n",
    "}\n",
    "\n",
    "noms_arbres = {\n",
    "            1: '\\emph{Abies balsamea} - Sapin Baumier - Balsam fir',\n",
    "            2: '\\emph{Acer platanoides} - Érable de Norvège - Norway maple',\n",
    "            3: '\\emph{Acer rubrum} - Érable rouge - Red maple',\n",
    "            4: '\\emph{Acer saccharum} - Érable à sucre - Sugar maple',\n",
    "            5: '\\emph{Betula alleghaniensis} - Bouleau jaune - Yellow birch',\n",
    "            6: '\\emph{Betula papyrifera} - Bouleau à papier - White birch',\n",
    "            7: '\\emph{Fagus grandifolia} - Hêtre à grandes feuilles - American beech',\n",
    "            8: \"\\emph{Fraxinus americana} - Frêne d'Amérique - White ash\",\n",
    "            9: '\\emph{Larix laricina} - Mélèze - Tamarack',\n",
    "            10: '\\emph{Ostrya virginiana} - Ostryer de Virginie - American hophornbeam',\n",
    "            11: '\\emph{Picea abies} - Épinette de Norvège - Norway spruce',\n",
    "            12: '\\emph{Picea glauca} - Épinette blanche - White spruce',\n",
    "            13: '\\emph{Picea mariana} - Épinette noire - Black spruce',\n",
    "            14: '\\emph{Picea rubens} - Épinette rouge - Red spruce',\n",
    "            15: '\\emph{Pinus rigida} - Pin rigide - Pitch pine',\n",
    "            16: '\\emph{Pinus resinosa} - Pin rouge - Red pine',\n",
    "            17: '\\emph{Pinus strobus} - Pin blanc - Eastern white pine',\n",
    "            18: '\\emph{Populus grandidentata} - Peuplier à grandes dents - Big-tooth aspen',\n",
    "            19: '\\emph{Populus tremuloides} - Peuplier faux tremble - Quaking aspen',\n",
    "            20: '\\emph{Quercus rubra} - Chêne rouge - Northern red oak',\n",
    "            21: '\\emph{Thuja occidentalis} - Thuya occidental - Northern white cedar',\n",
    "            22: '\\emph{Tsuga canadensis} - Pruche du Canada - Eastern Hemlock',\n",
    "            23: \"\\emph{Ulmus americana} - Orme d'Amérique - American elm\"\n",
    "        }\n",
    "\n",
    "dict_no_arbres_ID = {\n",
    "    '1':'SAB',  \n",
    "    '2':'ERB',\n",
    "    '3':'ERR', \n",
    "    '4':'ERS', \n",
    "    '5':'BOJ', \n",
    "    '6':'BOP',\n",
    "    '7':'HEG',  \n",
    "    '8':'FRA', \n",
    "    '9':'MEL',  \n",
    "    '10':'OSV', \n",
    "    '11':'EPO',\n",
    "    '12':'EPB',\n",
    "    '13':'EPN',\n",
    "    '14':'EPR',\n",
    "    '15':'PID',\n",
    "    '16':'PIR', \n",
    "    '17':'PIB',\n",
    "    '18':'PEG',\n",
    "    '19':'PET', \n",
    "    '20':'CHR',\n",
    "    '21':'THO', \n",
    "    '22':'PRU', \n",
    "    '23':'ORA'  \n",
    "}\n",
    "\n",
    "print(\"Code exécuté\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa1ad42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BOJ': 'https://drive.google.com/file/d/1d2zxg2pt5S8UJIK-E7IuWfGN0d1kxxMw/view?usp=sharing',\n",
       " 'BOP': 'https://drive.google.com/file/d/12cg6UO4HLnjk5fE_KXtrgdC2s8uGh4Zp/view?usp=sharing',\n",
       " 'CHR': 'https://drive.google.com/file/d/1Nq19-I-Q577KXMTFrkhlJDhMfclh0cWn/view?usp=sharing',\n",
       " 'EPB': 'https://drive.google.com/file/d/1K_Ncw8VEiuDZ_iJDbYToMq-GO5dzKHns/view?usp=sharing',\n",
       " 'EPN': 'https://drive.google.com/file/d/1S309DYmg76SrIA89aVQWXCMwm6CzhN8b/view?usp=sharing',\n",
       " 'EPO': 'https://drive.google.com/file/d/1fTKEcpYgmRg4spUpcH0FAiAnoRgANafL/view?usp=sharing',\n",
       " 'EPR': 'https://drive.google.com/file/d/1qRhtZ8LZjH_45fxetG7swg3ok3znk8CJ/view?usp=sharing',\n",
       " 'ERR': 'https://drive.google.com/file/d/1rEo1thMNJTgFeTzTOfI11_FPSqMgbHSL/view?usp=sharing',\n",
       " 'ERS': 'https://drive.google.com/file/d/1ts-t7bOH9DfKj0q0v35nMgKHgVT0ZjyG/view?usp=sharing',\n",
       " 'FRA': 'https://drive.google.com/file/d/1yLacRGW7JtlFWV5asEXHpAToClL38D64/view?usp=sharing',\n",
       " 'HEG': 'https://drive.google.com/file/d/1zoJKEIrsCD1XxglgPJkEygumev1xRQ3U/view?usp=sharing',\n",
       " 'MEL': 'https://drive.google.com/file/d/1Wdy3DDnWfUysXjcIFFq12UFW7tlTYDT2/view?usp=sharing',\n",
       " 'ORA': 'https://drive.google.com/file/d/19_oYwCAaPfP6vMuqUnAzIQAa39Brxhfi/view?usp=sharing',\n",
       " 'OSV': 'https://drive.google.com/file/d/1VJCCZN1iwBK2Nzh_PHC9xvw63xiLuXXI/view?usp=sharing',\n",
       " 'PET': 'https://drive.google.com/file/d/13bMkvr_1mRz1TuOcX8-c-LfTSIsNKrve/view?usp=sharing',\n",
       " 'PIB': 'https://drive.google.com/file/d/17J9g1xm6-ji52k2pgJr7mUrJdS1ASSqP/view?usp=sharing',\n",
       " 'PIR': 'https://drive.google.com/file/d/1qny4meuoT-HYZ_KTyPQbQnzLhebkgkfU/view?usp=sharing',\n",
       " 'PRU': 'https://drive.google.com/file/d/1xQWHQvIbwRRBoi2F27q22_drUeM8m3S8/view?usp=sharing',\n",
       " 'SAB': 'https://drive.google.com/file/d/1ol2mlYAz5bMfQkwqcnxhCOg4avftYtRe/view?usp=sharing',\n",
       " 'THO': 'https://drive.google.com/file/d/1_mI0saGpfxb4wnhElCzxg0WU4OiFHkfP/view?usp=sharing'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionnaire Python des URL qui pointent vers des données sur Google Doc\n",
    "\n",
    "data_zip_urls_dict = {\n",
    "   \"BOJ\":\"https://drive.google.com/file/d/1d2zxg2pt5S8UJIK-E7IuWfGN0d1kxxMw/view?usp=sharing\",\n",
    "   \"BOP\":\"https://drive.google.com/file/d/12cg6UO4HLnjk5fE_KXtrgdC2s8uGh4Zp/view?usp=sharing\",\n",
    "   \"CHR\":\"https://drive.google.com/file/d/1Nq19-I-Q577KXMTFrkhlJDhMfclh0cWn/view?usp=sharing\",\n",
    "   \"EPB\":\"https://drive.google.com/file/d/1K_Ncw8VEiuDZ_iJDbYToMq-GO5dzKHns/view?usp=sharing\",\n",
    "   \"EPN\":\"https://drive.google.com/file/d/1S309DYmg76SrIA89aVQWXCMwm6CzhN8b/view?usp=sharing\",\n",
    "   \"EPO\":\"https://drive.google.com/file/d/1fTKEcpYgmRg4spUpcH0FAiAnoRgANafL/view?usp=sharing\",\n",
    "   \"EPR\":\"https://drive.google.com/file/d/1qRhtZ8LZjH_45fxetG7swg3ok3znk8CJ/view?usp=sharing\",\n",
    "#   \"ERB\":\"https://drive.google.com/file/d/1ighbGniKAT_GrPm4RtsIAuN1STg9sjR9/view?usp=sharing\", # Assez de données?\n",
    "   \"ERR\":\"https://drive.google.com/file/d/1rEo1thMNJTgFeTzTOfI11_FPSqMgbHSL/view?usp=sharing\",\n",
    "   \"ERS\":\"https://drive.google.com/file/d/1ts-t7bOH9DfKj0q0v35nMgKHgVT0ZjyG/view?usp=sharing\",\n",
    "   \"FRA\":\"https://drive.google.com/file/d/1yLacRGW7JtlFWV5asEXHpAToClL38D64/view?usp=sharing\",\n",
    "   \"HEG\":\"https://drive.google.com/file/d/1zoJKEIrsCD1XxglgPJkEygumev1xRQ3U/view?usp=sharing\",\n",
    "   \"MEL\":\"https://drive.google.com/file/d/1Wdy3DDnWfUysXjcIFFq12UFW7tlTYDT2/view?usp=sharing\",\n",
    "   \"ORA\":\"https://drive.google.com/file/d/19_oYwCAaPfP6vMuqUnAzIQAa39Brxhfi/view?usp=sharing\",\n",
    "   \"OSV\":\"https://drive.google.com/file/d/1VJCCZN1iwBK2Nzh_PHC9xvw63xiLuXXI/view?usp=sharing\",\n",
    "#   \"PEG\":\"https://drive.google.com/file/d/1YUWH4IaTnmcoIAavZq8HyXByJxO7_zBg/view?usp=sharing\", # Assez de données?\n",
    "   \"PET\":\"https://drive.google.com/file/d/13bMkvr_1mRz1TuOcX8-c-LfTSIsNKrve/view?usp=sharing\",\n",
    "   \"PIB\":\"https://drive.google.com/file/d/17J9g1xm6-ji52k2pgJr7mUrJdS1ASSqP/view?usp=sharing\",\n",
    "#   \"PID\":\"https://drive.google.com/file/d/12xswrf4pDmTAcYZDAY9D-0HniLjGJCxp/view?usp=sharing\", # Assez de données?\n",
    "   \"PIR\":\"https://drive.google.com/file/d/1qny4meuoT-HYZ_KTyPQbQnzLhebkgkfU/view?usp=sharing\",\n",
    "   \"PRU\":\"https://drive.google.com/file/d/1xQWHQvIbwRRBoi2F27q22_drUeM8m3S8/view?usp=sharing\",\n",
    "   \"SAB\":\"https://drive.google.com/file/d/1ol2mlYAz5bMfQkwqcnxhCOg4avftYtRe/view?usp=sharing\",\n",
    "   \"THO\":\"https://drive.google.com/file/d/1_mI0saGpfxb4wnhElCzxg0WU4OiFHkfP/view?usp=sharing\",\n",
    "  \n",
    "}\n",
    "\n",
    "data_zip_urls_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd6407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des répertoires de données\n",
    "# Nous allons créer un répertoire de base `data` et des répertoires pour les données \n",
    "# d'entrainement, de validation et de test pour chaque étiquette cible.\n",
    "# Enfin, un répertoire `modeles` pour mémoriser les modèles entraînés\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"/content/data/\")\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(\"/content/lab_ecorces/\")\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(\"/content/modeles/\")\n",
    "except OSError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demande d'autorisation pour télécharger les données sur Google Drive \n",
    "# Référence: https://colab.research.google.com/notebooks/io.ipynb\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import os\n",
    "import shutil\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaaaeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement et décompression des données\n",
    "\n",
    "nombre_classes = 0\n",
    "for arbre_id in data_zip_urls_dict.keys():\n",
    "    url = data_zip_urls_dict[arbre_id]\n",
    "    id_fichier = url.split('/')[5]\n",
    "    fichier = drive.CreateFile({'id':id_fichier})\n",
    "    nom_fichier = arbre_id + \".zip\"\n",
    "    # télécharger le fichier nom_fichier\n",
    "    fichier.GetContentFile(\"/content/data/\" + nom_fichier)\n",
    "    print(\"Fichier \" + nom_fichier + \" téléchargé\")\n",
    "    zip_ref = zipfile.ZipFile(\"/content/data/\" + nom_fichier, 'r')\n",
    "    zip_ref.extractall(\"/content/data\")\n",
    "    zip_ref.close()\n",
    "    print(\"Fichier \" + nom_fichier + \" décompressé\")\n",
    "    try:\n",
    "        os.remove(\"/content/data/\"+nom_fichier)\n",
    "        print(\"Fichier \" + nom_fichier + \" effacé\")\n",
    "    except:\n",
    "        print(\"?\")\n",
    "    nombre_classes += 1\n",
    "shutil.rmtree('/content/data/__MACOSX')\n",
    "print(\"nombre_classes:\",nombre_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48fa644",
   "metadata": {},
   "source": [
    "### Répartition des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd4a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des bibliothèques Python `split-folders` et `tqdm`\n",
    "\n",
    "!pip3 install split-folders tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb09828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition des données d'entraînement, de validation et de tests\n",
    "\n",
    "import splitfolders\n",
    "import pathlib\n",
    "\n",
    "#### répertoire des données en entrée et des données une fois réparties\n",
    "repertoire_entree = \"/content/data\"\n",
    "repertoire_donnees_reparties = \"/content/lab_ecorces\"\n",
    "# => train, val, test\n",
    "\n",
    "nombre_images = len(list(pathlib.Path(repertoire_entree).glob('*/*.jpg')))\n",
    "print(\"Nombre total d'images:\",nombre_images)\n",
    "\n",
    "splitfolders.ratio(repertoire_entree, output=repertoire_donnees_reparties, seed=42, ratio = (0.80, 0.15, 0.05))\n",
    "\n",
    "print(\"\\nRépartition des données terminée!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46883aa",
   "metadata": {},
   "source": [
    "### Charger un modèle Keras sauvegardé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d1ff9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de Keras: 2.5.0\n",
      "Version de TensorFlow : 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "print(\"Version de Keras:\",keras.__version__)\n",
    "import tensorflow as tf\n",
    "print(\"Version de TensorFlow :\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f98d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPERTOIRE_ENTRAINEMENT = \"/content/lab_ecorces/train/\"\n",
    "\n",
    "TAILLE_LOT = 32\n",
    "HAUTEUR_IMAGE = 150\n",
    "LARGEUR_IMAGE = 150\n",
    "TAILLE_IMAGE = (HAUTEUR_IMAGE, LARGEUR_IMAGE)\n",
    "NOMBRE_CANAUX = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a9095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_modele_sauvegarde = \"/content/modeles/\"\n",
    "nom_modele = \"1646627256\"\n",
    "modele_de_transfert = tf.keras.models.load_model(chemin_modele_sauvegarde+nom_modele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b56780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_de_transfert.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14234b5",
   "metadata": {},
   "source": [
    "#### Prédiction sur les données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_entrainement = tf.keras.utils.image_dataset_from_directory(REPERTOIRE_ENTRAINEMENT,\n",
    "                                                                   batch_size=TAILLE_LOT,\n",
    "                                                                   image_size=TAILLE_IMAGE,\n",
    "                                                                   shuffle=False)\n",
    "\n",
    "donnees_entrainement_normalisees = pretraitement(donnees_entrainement,\n",
    "                                                 melanger=False,\n",
    "                                                 amplifier=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e322fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "les_images = [] \n",
    "etiquettes_vraies = []  \n",
    "etiquettes_predites = [] \n",
    "\n",
    "# boucler sur le jeu de données d'entraînement\n",
    "for lot_images, lot_etiquettes in donnees_entrainement_normalisees: \n",
    "   # accumuler les imags\n",
    "   les_images.append(lot_images)\n",
    "   # accumuler les vraies étiquettes\n",
    "   etiquettes_vraies.append(lot_etiquettes)\n",
    "   # faire des prédictions\n",
    "   predictions = modele_de_transfert.predict(lot_images)\n",
    "   # accumuler les étiquettes prédites\n",
    "   etiquettes_predites.append(np.argmax(predictions, axis = - 1))\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "liste_vraies_etiquettes_entrainement = tf.concat([item+1 for item in etiquettes_vraies], axis = 0)\n",
    "liste_etiquettes_predites_entrainement = tf.concat([item+1 for item in etiquettes_predites], axis = 0)\n",
    "liste_images = tf.concat([item for item in les_images], axis = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b951f07",
   "metadata": {},
   "source": [
    "#### Mesure d'exactitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "exactitude_test = metrics.accuracy_score(liste_vraies_etiquettes_entrainement, liste_etiquettes_predites_entrainement)\n",
    "print(\"Exactitude:   %0.2f\" % exactitude_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5625e8f9",
   "metadata": {},
   "source": [
    "#### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43281df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/65618137/confusion-matrix-for-multiple-classes-in-python\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def afficher_matrice_de_confusion(matrice_confusion_brute, classes,\n",
    "                          normalisation=False,\n",
    "                          titre='Matrice de confusion',\n",
    "                          carte_des_couleurs=plt.cm.Blues):\n",
    "    plt.figure(figsize=(14,12))\n",
    "    plt.imshow(matrice_confusion_brute, interpolation='nearest', cmap=carte_des_couleurs)\n",
    "    plt.title(titre)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalisation:\n",
    "        matrice_confusion_brute = matrice_confusion_brute.astype('float') / matrice_confusion_brute.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Matrice de confusion normalisée\")\n",
    "    else:\n",
    "        print('Matrice de confusion non normalisée')\n",
    "\n",
    "    seuil = matrice_confusion_brute.max() / 2.\n",
    "    for i, j in itertools.product(range(matrice_confusion_brute.shape[0]), range(matrice_confusion_brute.shape[1])):\n",
    "        plt.text(j, i, matrice_confusion_brute[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if matrice_confusion_brute[i, j] > seuil else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Vraies étiquettes')\n",
    "    plt.xlabel('Étiquettes prédites')\n",
    "\n",
    "print(\"Afficher_matrice_de_confusion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_confusion_brute = metrics.confusion_matrix(liste_vraies_etiquettes_entrainement, liste_etiquettes_predites_entrainement)\n",
    "afficher_matrice_de_confusion(matrice_confusion_brute, classes=liste_noms_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344eff98",
   "metadata": {},
   "source": [
    "#### Rapport de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ef4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(liste_vraies_etiquettes_entrainement, liste_etiquettes_predites_entrainement, target_names=liste_noms_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8247a3",
   "metadata": {},
   "source": [
    "#### Examen des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ba314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trouver_nom_arbre(index):\n",
    "    return noms_arbres[index].split(\"-\")[1]\n",
    "\n",
    "nombre_erreurs = 0\n",
    "images_mal_classees = []\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "for (index,etiq_vraie,etiq_pred,image) in zip(range(len(liste_images)),\n",
    "                                              liste_vraies_etiquettes_entrainement,\n",
    "                                              liste_etiquettes_predites_entrainement,\n",
    "                                              liste_images):\n",
    "    if (etiq_vraie.numpy() != etiq_pred.numpy()):\n",
    "        etiq_pred = etiq_pred.numpy()\n",
    "        etiq_vraie = etiq_vraie.numpy()\n",
    "        print(\"_\"*80)\n",
    "        print(\"*** ERREUR*** Prédiction:\",etiq_pred,trouver_nom_arbre(etiq_pred),\"- Vraie:\",etiq_vraie,trouver_nom_arbre(etiq_vraie))\n",
    "        chemin_image_originale = donnees_entrainement.file_paths[index]\n",
    "        print(\"Chemin image originale:\",chemin_image_originale)\n",
    "        images_mal_classees.append(chemin_image_originale)\n",
    "        image_originale = mpimg.imread(chemin_image_originale)\n",
    "        plt.axis('Off')\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(image_originale)\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(image)\n",
    "        nombre_erreurs += 1\n",
    "        plt.show()\n",
    "print(\"_\"*80)\n",
    "print(\"Nombre total d'erreurs:\",nombre_erreurs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
