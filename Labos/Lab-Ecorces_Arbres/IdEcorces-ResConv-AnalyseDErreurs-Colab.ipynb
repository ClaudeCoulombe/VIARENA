{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "df673147",
      "metadata": {
        "id": "df673147"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-Ecorces_Arbres/IdEcorces-ResConv-AnalyseDErreurs-Colab.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n",
        "### Rappel - Fonctionnement d'un carnet web iPython\n",
        "\n",
        "* Pour exécuter le code contenu dans une cellule d'un carnet iPython, cliquez dans la cellule et faites (⇧↵, shift-enter) \n",
        "* Le code d'un carnet iPython s'exécute séquentiellement de haut en bas de la page. Souvent, l'importation d'une bibliothèque Python ou l'initialisation d'une variable est préalable à l'exécution d'une cellule située plus bas. Il est donc recommandé d'exécuter les cellules en séquence. Enfin, méfiez-vous quand vous faites des retours en arrière, cela peut réinitialiser certaines variables.\n",
        "\n",
        "SVP, déployez toutes les cellules en sélectionnant l'item « Développer les rubriques » de l'onglet « Affichage »."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "838a366c",
      "metadata": {
        "id": "838a366c"
      },
      "source": [
        "# Analyse d'erreur\n",
        "## Identification d'arbres à partir de leur écorce\n",
        "### Réseau convolutif, apprentissage par transfert et amplification des données"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a5736de",
      "metadata": {
        "id": "3a5736de"
      },
      "source": [
        "### Inspiration et droits d'auteur\n",
        "\n",
        "Ce laboratoire s'inspire de plusieurs oeuvres en logiciels libres qui ont été transformées dont:\n",
        "\n",
        "<a href=\"https://www.tensorflow.org/tutorials/images/transfer_learning\" target='_blank'>Transfer learning and fine-tuning</a> - site Google / Tutoriels TensorFlow\n",
        "\n",
        "<a href=\"https://www.tensorflow.org/tutorials/images/data_augmentation\" target='_blank'>Data augmentation</a> - site Google / Tutoriels TensorFlow\n",
        "\n",
        "##### Copyright (c) 2017, François Chollet  \n",
        "##### Copyright (c) 2019-2022, The TensorFlow Authors.\n",
        "##### Copyright (c) 2022, Claude Coulombe\n",
        "\n",
        "Le contenu de cette page est sous licence <a href=\"https://creativecommons.org/licenses/by/4.0/deed.fr\" target='_blank'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>,<br/>et les exemples de code sont sous <a href=\"https://www.apache.org/licenses/LICENSE-2.0\" target='_blank'>licence Apache 2.0</a>.\n",
        "\n",
        "#### Données\n",
        "\n",
        "Les données sur les écorces d'arbres proviennent de <a href=\"https://data.mendeley.com/research-data/?search=barknet\">BarkNet</a>, une banque en données ouvertes sous licence MIT de 23 000 photos d'écorces d'arbres en haute résolution prises avec des téléphones intelligents par une équipe d'étudiants et de chercheurs du <a href=\"https://www.sbf.ulaval.ca/\" target='_blank'>Département des sciences du bois et de la forêt de l'Université Laval</a> à Québec.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33455f39",
      "metadata": {
        "id": "33455f39"
      },
      "source": [
        "## Fixer le hasard pour la reproductibilité\n",
        "\n",
        "La mise au point de réseaux de neurones implique certains processus aléatoires. Afin de pouvoir reproduire et comparer vos résultats d'expérience, vous fixez temporairement l'état aléatoire grâce à un germe aléatoire unique.\n",
        "\n",
        "Pendant la mise au point, vous fixez temporairement l'état aléatoire pour la reproductibilité mais vous répétez l'expérience avec différents germes ou états aléatoires et prenez la moyenne des résultats.\n",
        "<br/>\n",
        "\n",
        "**Note** : Pour un système en production, vous ravivez simplement l'état  purement aléatoire avec l'instruction `GERME_ALEATOIRE = None`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d50b84ec",
      "metadata": {
        "id": "d50b84ec"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Définir un germe aléatoire\n",
        "GERME_ALEATOIRE = 42\n",
        "\n",
        "# Définir un état aléatoire pour Python\n",
        "os.environ['PYTHONHASHSEED'] = str(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour Python random\n",
        "import random\n",
        "random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour NumPy\n",
        "import numpy as np\n",
        "np.random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour TensorFlow\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Note: Retrait du comportement déterministe\n",
        "# à cause de keras.layers.RandomContrast(...)\n",
        "# dont il n'existe pas de version déterministe\n",
        "# os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "# os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "print(\"Germe aléatoire fixé\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03b439de",
      "metadata": {
        "id": "03b439de"
      },
      "source": [
        "## Acquisition des données"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca994251",
      "metadata": {
        "id": "ca994251"
      },
      "source": [
        "L'analyse d'erreur requiert l'examen des données d'entraînement, il faut donc les obtenir.\n",
        "\n",
        "Les <a href=\"https://www.kaggle.com/claudecoulombe/barknet\" target='_blank'>données de BarkNet</a>  peuvent être téléchargées à partir du site de Kaggle. Mais vous allez utiliser l'IPA (<i>API</i>) de Kaggle pour accélérer les transferts de données."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_arbres = {\n",
        "    'BOJ' : \"Betula alleghaniensis - Bouleau jaune - Yellow birch\",\n",
        "    'BOP' : \"Betula papyrifera - Bouleau à papier - White birch\",\n",
        "    'CHR' : \"Quercus rubra - Chêne rouge - Northern red oak\",\n",
        "    'EPB' : \"Picea glauca - Épinette blanche - White spruce\",\n",
        "    'EPN' : \" Picea mariana - Épinette noire - Black spruce\",\n",
        "    'EPO' : \"Picea abies - Épinette de Norvège - Norway spruce\",\n",
        "    'EPR' : \"Picea rubens - Épinette rouge - Red spruce\",\n",
        "    'ERB' : \"Acer platanoides - Érable de Norvège - Norway maple\",\n",
        "    'ERR' : \"Acer rubrum - Érable rouge - Red maple\",\n",
        "    'ERS' : \"Acer saccharum - Érable à sucre - Sugar maple\",\n",
        "    'FRA' : \"Fraxinus americana - Frêne d'Amérique - White ash\",\n",
        "    'HEG' : \"Fagus grandifolia - Hêtre à grandes feuilles - American beech\",\n",
        "    'MEL' : \"Larix laricina - Mélèze - Tamarack\",\n",
        "    'ORA' : \"Ulmus americana - Orme d'Amérique - American elm\",\n",
        "    'OSV' : \"Ostrya virginiana - Ostryer de Virginie - American hophornbeam\",\n",
        "    'PEG' : \"Populus grandidentata - Peuplier à grandes dents - Big-tooth aspen\",\n",
        "    'PET' : \"Populus tremuloides - Peuplier faux tremble - Quaking aspen\",\n",
        "    'PIB' : \"Pinus strobus - Pin blanc - Eastern white pine\",\n",
        "    'PID' : \"Pinus rigida - Pin rigide - Pitch pine\",\n",
        "    'PIR' : \"Pinus resinosa - Pin rouge - Red pine\",\n",
        "    'PRU' : \"Tsuga canadensis - Pruche du Canada - Eastern Hemlock\",\n",
        "    'SAB' : \"Abies balsamea - Sapin Baumier - Balsam fir\",\n",
        "    'THO' : \"Thuja occidentalis - Thuya occidental - Northern white cedar\",\n",
        "}\n",
        "\n",
        "print(\"Dictionnaire mémorisé\")"
      ],
      "metadata": {
        "id": "Itugisoe0f3N"
      },
      "id": "Itugisoe0f3N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ba7b3043",
      "metadata": {
        "id": "ba7b3043"
      },
      "source": [
        "### Création des répertoires de données\n",
        "\n",
        "Nous allons créer un répertoire de base `donnees`, un répertoire `lab_ecorces` où les données seront réparties en données d'entraînement, de validation et de test pour chaque classe cible.\n",
        "\n",
        "Enfin, un répertoire `modeles` pour mémoriser les modèles une fois entraînés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92cdb326",
      "metadata": {
        "id": "92cdb326"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    os.mkdir(\"/content/donnees/\")\n",
        "except OSError:\n",
        "    pass\n",
        "try:\n",
        "    os.mkdir(\"/content/lab_ecorces/\")\n",
        "except OSError:\n",
        "    pass\n",
        "try:\n",
        "    os.mkdir(\"/content/modeles/\")\n",
        "except OSError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84b71448",
      "metadata": {
        "id": "84b71448"
      },
      "source": [
        "### Utilisation de l'IPA (<i>API</i>) de Kaggle pour l'importation directe du jeu de données BarkNet\n",
        "\n",
        "1. Commencez par installer la bibliothèque Python `kaggle`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "063d9919",
      "metadata": {
        "id": "063d9919"
      },
      "outputs": [],
      "source": [
        "!pip3 install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ab01523",
      "metadata": {
        "id": "0ab01523"
      },
      "source": [
        "2. Si ce n'est déjà fait, devenez membre de Kaggle avec votre adresse de courriel GMail:<br/>\n",
        "\n",
        "<img src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Kaggle_API-1.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c6a9f31",
      "metadata": {
        "id": "9c6a9f31"
      },
      "source": [
        "3. Maintenant, vous devez télécharger votre clé privée pour utiliser l'IPA de Kaggle.\n",
        "\n",
        "4. Cliquez sur l'onglet « account » de votre profil Kaggle\n",
        "\n",
        "<img src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Kaggle_API-2.png\"/>\n",
        "\n",
        "5. Sur la page « Account » cliquez sur le bouton « Create New API Token ».\n",
        "    \n",
        "<img style=\"margin-left:40px;\" src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Kaggle_API-3.png\"/>\n",
        "\n",
        "6. Téléchargez votre clé privée « kaggle.json » pour l'IPA Kaggle dans un endroit temporaire sur votre poste de travail.\n",
        "\n",
        "<img style=\"margin-left:40px;\" src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Kaggle_API-5.png\"/>\n",
        "\n",
        "7. Maintenant, transférez (téléversez) votre clé privée « kaggle.json » dans votre environnement Colab.\n",
        "\n",
        "La fenêtre de l'outil de fichiers de votre ordinateur s'ouvre alors. Allez chercher votre clé privée « kaggle.json » que vous avez sauvegardée sur votre  ordinateur.\n",
        "\n",
        "<img style=\"margin-left:40px;\" src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Colab_Importer_Fichier.png\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b58d4efa",
      "metadata": {
        "id": "b58d4efa"
      },
      "source": [
        "8. Créer à la racine un répertoire .kaggle et déplacez votre clé privée « kaggle.json » dans ce répertoire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8158fa08",
      "metadata": {
        "id": "8158fa08"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle -all"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "925bdf54",
      "metadata": {
        "id": "925bdf54"
      },
      "source": [
        "9. Maintenant téléchargez le jeu de données réduit « barknet-mini » de 1.6 Go ou le jeu de données « barknet » complet de 32 Go avec la commande suivante:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb978fa",
      "metadata": {
        "id": "5eb978fa"
      },
      "outputs": [],
      "source": [
        "# Attention! Jeu réduit de données 1.5 Go - plus rapide à télécharger et à traiter\n",
        "!kaggle datasets download claudecoulombe/barknet-mini --unzip -p /content/donnees/\n",
        "repertoire_entree = \"/content/donnees/BarkNet-mini\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d904d1e4",
      "metadata": {
        "id": "d904d1e4"
      },
      "outputs": [],
      "source": [
        "# Attention! Jeu complet de données 32 Go - plus long à télécharger et à traiter\n",
        "# retirer les commentaires ci-dessous pour activer le code  \n",
        "# !kaggle datasets download claudecoulombe/barknet --unzip -p /content/donnees/\n",
        "# repertoire_entree = \"/content/donnees/BarkNet\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e2d6209",
      "metadata": {
        "id": "9e2d6209"
      },
      "source": [
        "### Répartition des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2d55047",
      "metadata": {
        "id": "e2d55047"
      },
      "outputs": [],
      "source": [
        "# Installation des bibliothèques Python `split-folders` et `tqdm`\n",
        "!pip3 install split-folders tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81bc150b",
      "metadata": {
        "id": "81bc150b"
      },
      "outputs": [],
      "source": [
        "# Répartition des données d'entraînement, de validation et de tests\n",
        "import splitfolders\n",
        "import pathlib\n",
        "\n",
        "#### répertoire des données une fois réparties\n",
        "repertoire_donnees_reparties = \"/content/lab_ecorces\"\n",
        "# => train, val, test\n",
        "\n",
        "nombre_images = len(list(pathlib.Path(repertoire_entree).glob('*/*.jpg')))\n",
        "print(\"Nombre total d'images:\",nombre_images)\n",
        "\n",
        "splitfolders.ratio(repertoire_entree, \n",
        "                   output=repertoire_donnees_reparties, \n",
        "                   seed=42, \n",
        "                   ratio = (0.65, 0.15, 0.20)\n",
        "                   )\n",
        "\n",
        "print(\"\\nRépartition des données terminée!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "711f37a2",
      "metadata": {
        "id": "711f37a2"
      },
      "source": [
        "## Acquisition du modèle entraîné dont on veut analyser les erreurs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e91c2234",
      "metadata": {
        "id": "e91c2234"
      },
      "source": [
        "### Téléversement et décompression d'un modèle Keras sauvegardé sur un poste local"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86b13b6c",
      "metadata": {
        "id": "86b13b6c"
      },
      "source": [
        "1. & 2. Vous allez téléverser le modèle d'identification d'écorces entraîné précédemment.\n",
        "\n",
        "<img src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Colab_Importer_Fichier.png\"/>\n",
        "\n",
        "3. La fenêtre de l'outil de fichiers de votre ordinateur s'ouvre alors. Allez chercher le modèle d'identification d'écorces modele_....zip que vous avez sauvegardé précédemment sur votre ordinateur local.\n",
        "\n",
        "Attention! Le téléchargement peut prendre plusieurs minutes. Assurez-vous que le fichier est entièrement téléversé et que l'icône d'état du téléversement (un cercle jaune, comme ci-dessous) disparaisse. \n",
        "\n",
        "<img style=\"margin-left:0px\" src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Colab_Importer_Fichier-3.png\"/>\n",
        "\n",
        "4. Décompressez le fichier modele_....zip en exécutant la commande ci-dessous:<br/>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d9ebc0",
      "metadata": {
        "id": "20d9ebc0"
      },
      "outputs": [],
      "source": [
        "!unzip /content/modele_*.zip -d /content/modeles && rm /content/modele_*.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7834b3d1",
      "metadata": {
        "id": "7834b3d1"
      },
      "source": [
        "## Chargement du modèle entraîné dont on veut analyser les erreurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6f3fd71",
      "metadata": {
        "id": "b6f3fd71"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "print(\"Version de Keras:\",keras.__version__)\n",
        "import tensorflow as tf\n",
        "print(\"Version de TensorFlow :\",tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28575063",
      "metadata": {
        "id": "28575063"
      },
      "outputs": [],
      "source": [
        "chemin_modele_sauvegarde = \"/content/modeles/\"\n",
        "\n",
        "modele_de_transfert = tf.keras.models.load_model(chemin_modele_sauvegarde)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4360686b",
      "metadata": {
        "id": "4360686b"
      },
      "outputs": [],
      "source": [
        "print(\"Architecture du modèle préentraîné\")\n",
        "modele_de_transfert.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44b24622",
      "metadata": {
        "id": "44b24622"
      },
      "source": [
        "## Prédiction sur les données d'entraînement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da839a9e",
      "metadata": {
        "id": "da839a9e"
      },
      "source": [
        "Pour procéder à l'analyse des erreurs, vous allez débuter par l'examen des erreurs sur les données d'entraînement. \n",
        "\n",
        "Par la suite, vous utiliserez des données fraîches qui n'ont pas servi à entraîner le modèle. Ces données devraient être disctinctes des données de test qui doivent être conservées pour l'évaluation finale du modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab62e915",
      "metadata": {
        "id": "ab62e915"
      },
      "source": [
        "### Prétraitement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b645635",
      "metadata": {
        "id": "8b645635"
      },
      "outputs": [],
      "source": [
        "REPERTOIRE_ENTRAINEMENT = \"/content/lab_ecorces/train/\"\n",
        "TAILLE_LOT = 32\n",
        "HAUTEUR_IMAGE = 150\n",
        "LARGEUR_IMAGE = 150\n",
        "TAILLE_IMAGE = (HAUTEUR_IMAGE, LARGEUR_IMAGE)\n",
        "NOMBRE_CANAUX = 3\n",
        "\n",
        "couches_amplification = tf.keras.Sequential([\n",
        "    # Retournement horizontal - gauche / droite\n",
        "    keras.layers.RandomFlip(\"horizontal\"),\n",
        "    # Retournement vertical - haut / bas\n",
        "    keras.layers.RandomFlip(\"vertical\"),\n",
        "    # Rotation\n",
        "    keras.layers.RandomRotation(0.1),\n",
        "    # Agrandissement / zoom\n",
        "    keras.layers.RandomZoom(0.3),\n",
        "    # Variation du contraste de l'image\n",
        "    keras.layers.RandomContrast(0.3),\n",
        "])\n",
        "\n",
        "couches_normalisation = keras.Sequential([\n",
        "    # Redimensionnement de l'image\n",
        "    keras.layers.Resizing(HAUTEUR_IMAGE,LARGEUR_IMAGE),\n",
        "    # Changement d'échelle de luminosité\n",
        "    keras.layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def pretraitement(jeu_donnees, melanger=False, normaliser=False, amplifier=False):\n",
        "    if melanger:\n",
        "        jeu_donnees = jeu_donnees.shuffle(1000)\n",
        "                \n",
        "    # Normaliser les jeux de données\n",
        "    if normaliser:\n",
        "        jeu_donnees = jeu_donnees.map(lambda x, y: (couches_normalisation(x), y),\n",
        "                                    num_parallel_calls=AUTOTUNE\n",
        "                                    )\n",
        "    # Amplifier seulement les données d'entraînement\n",
        "    if amplifier:\n",
        "        jeu_donnees = jeu_donnees.map(lambda x, y: (couches_amplification(x,training=True), y),\n",
        "                                      num_parallel_calls=AUTOTUNE\n",
        "                                     )\n",
        "    # Utiliser des tampons de préextraction sur tous les jeux de données\n",
        "    return jeu_donnees.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print(\"Fonction de prétraitement prête!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d1feb2",
      "metadata": {
        "id": "48d1feb2"
      },
      "outputs": [],
      "source": [
        "donnees_entrainement = tf.keras.utils.image_dataset_from_directory(REPERTOIRE_ENTRAINEMENT,\n",
        "                                                                   batch_size=TAILLE_LOT,\n",
        "                                                                   image_size=TAILLE_IMAGE,\n",
        "                                                                   shuffle=False)\n",
        "\n",
        "donnees_entrainement_normalisees = pretraitement(donnees_entrainement,\n",
        "                                                 melanger=False,\n",
        "                                                 normaliser=True,\n",
        "                                                 amplifier=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c77390",
      "metadata": {
        "id": "79c77390"
      },
      "source": [
        "### Inférence sur les donnés d'entraînement*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c285b0",
      "metadata": {
        "id": "49c285b0"
      },
      "outputs": [],
      "source": [
        "les_images = [] \n",
        "etiquettes_vraies = []  \n",
        "etiquettes_predites = [] \n",
        "liste_noms_classes = donnees_entrainement.class_names\n",
        "print(\"Noms de classes:\\n\",liste_noms_classes)\n",
        "print()\n",
        "# boucler sur le jeu de données d'entraînement\n",
        "for lot_images, lot_etiquettes in donnees_entrainement_normalisees: \n",
        "   # accumuler les images\n",
        "   les_images.append(lot_images)\n",
        "   # accumuler les vraies étiquettes\n",
        "   etiquettes_vraies.append(lot_etiquettes)\n",
        "   # faire des prédictions\n",
        "   predictions = modele_de_transfert.predict(lot_images)\n",
        "   # accumuler les étiquettes prédites\n",
        "   etiquettes_predites.append(np.argmax(predictions, axis = - 1))\n",
        "# convertir les listes d'étiquettes en tenseurs\n",
        "liste_vraies_etiquettes_entrainement = tf.concat([item for item in etiquettes_vraies], axis = 0)\n",
        "liste_etiquettes_predites_entrainement = tf.concat([item for item in etiquettes_predites], axis = 0)\n",
        "liste_images = tf.concat([item for item in les_images], axis = 0)\n",
        "print(\"Étiquettes prêtes!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dcb8eac",
      "metadata": {
        "id": "1dcb8eac"
      },
      "source": [
        "### Mesure d'exactitude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ec887c",
      "metadata": {
        "id": "e7ec887c"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "exactitude_test = metrics.accuracy_score(liste_vraies_etiquettes_entrainement, liste_etiquettes_predites_entrainement)\n",
        "print(\"Exactitude:   %0.2f\" % exactitude_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "920dae45",
      "metadata": {
        "id": "920dae45"
      },
      "source": [
        "### Matrice de confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3855b16",
      "metadata": {
        "id": "c3855b16"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/questions/65618137/confusion-matrix-for-multiple-classes-in-python\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "\n",
        "def afficher_matrice_de_confusion(matrice_confusion_brute, classes,\n",
        "                          normalisation=False,\n",
        "                          titre='Matrice de confusion',\n",
        "                          carte_des_couleurs=plt.cm.Blues):\n",
        "    plt.figure(figsize=(14,12))\n",
        "    plt.imshow(matrice_confusion_brute, interpolation='nearest', cmap=carte_des_couleurs)\n",
        "    plt.title(titre)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalisation:\n",
        "        matrice_confusion_brute = matrice_confusion_brute.astype('float') / matrice_confusion_brute.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Matrice de confusion normalisée\")\n",
        "    else:\n",
        "        print('Matrice de confusion non normalisée')\n",
        "\n",
        "    seuil = matrice_confusion_brute.max() / 2.\n",
        "    for i, j in itertools.product(range(matrice_confusion_brute.shape[0]), range(matrice_confusion_brute.shape[1])):\n",
        "        plt.text(j, i, matrice_confusion_brute[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if matrice_confusion_brute[i, j] > seuil else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('Vraies étiquettes')\n",
        "    plt.xlabel('Étiquettes prédites')\n",
        "\n",
        "print(\"Code affichage matrice de confusion\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc39ace7",
      "metadata": {
        "id": "dc39ace7"
      },
      "outputs": [],
      "source": [
        "matrice_confusion_brute = metrics.confusion_matrix(liste_vraies_etiquettes_entrainement, liste_etiquettes_predites_entrainement)\n",
        "afficher_matrice_de_confusion(matrice_confusion_brute, classes=liste_noms_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3cdebed",
      "metadata": {
        "id": "c3cdebed"
      },
      "source": [
        "### Rapport de classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773d8a10",
      "metadata": {
        "id": "773d8a10"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(liste_vraies_etiquettes_entrainement, \n",
        "                            liste_etiquettes_predites_entrainement, \n",
        "                            target_names=liste_noms_classes))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e587d4f8",
      "metadata": {
        "id": "e587d4f8"
      },
      "source": [
        "## Examen manuel et visualisation des erreurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ea9554",
      "metadata": {
        "id": "41ea9554"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "def trouver_nom_arbre(index):\n",
        "    id_arbre = liste_noms_classes[int(index)]\n",
        "    return dict_arbres[id_arbre].split(\"-\")[1]\n",
        "\n",
        "def trouver_id_arbre(index):\n",
        "    return liste_noms_classes[int(index)]\n",
        "\n",
        "nombre_erreurs = 0\n",
        "images_mal_classees = []\n",
        "fig = plt.figure(figsize=(12,4))\n",
        "for (index,etiq_vraie,etiq_pred) in zip(range(len(liste_images)),\n",
        "                                              liste_vraies_etiquettes_entrainement,\n",
        "                                              liste_etiquettes_predites_entrainement):\n",
        "    etiq_pred = etiq_pred.numpy()\n",
        "    etiq_vraie = etiq_vraie.numpy()\n",
        "    if (etiq_vraie != etiq_pred):\n",
        "        print(\"_\"*80)\n",
        "        nombre_erreurs += 1\n",
        "        print(\"*** ERREUR*** Prédiction:\",etiq_pred,\"-\",trouver_id_arbre(etiq_pred),\"-\",trouver_nom_arbre(str(etiq_pred)),\n",
        "              \"- Vraie:\",etiq_vraie,\"-\",trouver_id_arbre(etiq_vraie),\"-\",trouver_nom_arbre(str(etiq_vraie)))\n",
        "        chemin_image_originale = donnees_entrainement.file_paths[index]\n",
        "        print(\"Chemin image originale:\",chemin_image_originale)\n",
        "        images_mal_classees.append(chemin_image_originale)\n",
        "        image_originale = mpimg.imread(chemin_image_originale)\n",
        "        plt.axis('Off')\n",
        "        plt.imshow(image_originale)\n",
        "        plt.show()\n",
        "print(\"_\"*80)\n",
        "print(\"Nombre total d'erreurs:\",nombre_erreurs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f82c43e1",
      "metadata": {
        "id": "f82c43e1"
      },
      "source": [
        "## Résultats \n",
        "\n",
        "Typiquement, l'analyse d'erreur permet de découvrir des anomalies, des données aberrantes ou mal étiquetées que vous allez corriger, remplacer ou simplement écarter. L'analyse d'erreur peut également déboucher sur de nouvelles étapes de prétraitement de vos données.\n",
        "\n",
        "Ici, nous n'avons pu procéder à cette analyse car nous n'avions pas d'expertise en identification d'écorces. \n",
        "\n",
        "Nous avons toutefois noté que des espèces d'arbres manquaient probablement de variété dans leurs données. En fait, il n'y a pas suffisamment de spécimens différents. Il n'y a qu'un seul spécimen d'érable de Norvège (Acer platanoides), 3 spécimens de Peuplier à grandes dents (Populus grandidentata) et 4 spécimens de Pin rigide (Pinus rigida). La solution simple est de supprimer ces trois classs, ce qui augmente l'exactitude d'environ 3%. Pour bien faire, il faudrait ajouter quelques spécimens en allant sur le terrain ou en trouvant de bonnes photos sur la Toile.\n",
        "\n",
        "De plus, il nous a semblé que certaines photos floues ou mal éclairées pouvaient être à l'origine de certaines erreurs de classification. Cela suggère un prétraitement photographique de ces images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08919b14",
      "metadata": {
        "id": "08919b14"
      },
      "outputs": [],
      "source": [
        "print(\"Fin de l'exécution du carnet IPython\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-xw9hRhb8y7d"
      },
      "id": "-xw9hRhb8y7d",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "IdEcorces-ResConv-AnalyseDErreurs-Colab.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}