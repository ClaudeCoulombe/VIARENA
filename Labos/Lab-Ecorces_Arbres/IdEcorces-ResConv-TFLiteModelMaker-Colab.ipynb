{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2q27gKz1H20"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-Ecorces_Arbres/IdEcorces-ResConv-TFLiteModelMaker-Colab.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "### Rappel - Fonctionnement d'un carnet web iPython\n",
    "\n",
    "* Pour exécuter le code contenu dans une cellule d'un carnet iPython, cliquez dans la cellule et faites (⇧↵, shift-enter) \n",
    "* Le code d'un carnet iPython s'exécute séquentiellement de haut en bas de la page. Souvent, l'importation d'une bibliothèque Python ou l'initialisation d'une variable est préalable à l'exécution d'une cellule située plus bas. Il est donc recommandé d'exécuter les cellules en séquence. Enfin, méfiez-vous des retours en arrière qui peuvent réinitialiser certaines variables.\n",
    "\n",
    "SVP, déployez toutes les cellules en sélectionnant l'item « Développer les rubriques » de l'onglet « Affichage »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "TUfAcER1oUS6"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gb7qyhNL1yWt"
   },
   "source": [
    "# Flower classification with TensorFlow Lite Model Maker with TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDABAblytltI"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/lite/codelabs/flower_classification/ml/Flower_Classification_with_TFLite_Model_Maker.ipynb\">      \n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/lite/codelabs/flower_classification/ml/Flower_Classification_with_TFLite_Model_Maker.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m86-Nh4pMHqY"
   },
   "source": [
    "Model Maker library simplifies the process of adapting and converting a TensorFlow neural-network model to particular input data when deploying this model for on-device ML applications.\n",
    "\n",
    "This notebook shows an end-to-end example that utilizes this Model Maker library to illustrate the adaption and conversion of a commonly-used image classification model to classify flowers on a mobile device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcLF2PKkSbV3"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "To run this example, we first need to make a copy of this notebook. Click on \"Copy to Drive\" at the top of this notebook. Then we need to install serveral required packages, including Model Maker package that in github [repo](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cv3K3oaksJv",
    "outputId": "975ba270-690c-4474-c025-f0db62742a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 616 kB 4.3 MB/s \n",
      "\u001b[K     |████████████████████████████████| 87 kB 8.8 MB/s \n",
      "\u001b[K     |████████████████████████████████| 234 kB 61.8 MB/s \n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 67.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 53.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 55.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 596 kB 55.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 51.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 840 kB 56.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 120 kB 49.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 53.7 MB/s \n",
      "\u001b[K     |████████████████████████████████| 77 kB 6.2 MB/s \n",
      "\u001b[K     |████████████████████████████████| 25.3 MB 1.3 MB/s \n",
      "\u001b[K     |████████████████████████████████| 99 kB 12.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 47.7 MB 76 kB/s \n",
      "\u001b[K     |████████████████████████████████| 352 kB 72.2 MB/s \n",
      "\u001b[K     |████████████████████████████████| 462 kB 48.3 MB/s \n",
      "\u001b[K     |████████████████████████████████| 211 kB 75.7 MB/s \n",
      "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tflite-model-maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx1HGRoFQ54j"
   },
   "source": [
    "Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XtxiUeZEiXpt"
   },
   "outputs": [],
   "source": [
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKRaYHABpob5"
   },
   "source": [
    "## Simple End-to-End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiZZ5DHXotaW"
   },
   "source": [
    "### Get the data path\n",
    "\n",
    "Let's get some images to play with this simple end-to-end example. Hundreds of images is a good start for Model Maker while more data could achieve better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "3jz5x0JoskPv"
   },
   "outputs": [],
   "source": [
    "# image_path = tf.keras.utils.get_file(\n",
    "#       'flower_photos',\n",
    "#       'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "#       untar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a55MR6i6nuDm"
   },
   "source": [
    "You could replace `image_path` with your own image folders. As for uploading data to colab, you could find the upload button in the left sidebar shown in the image below with the red rectangle. Just have a try to upload a zip file and unzip it. The root file path is the current path.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/screenshots/model_maker_image_classification.png\" alt=\"Upload File\" width=\"800\" hspace=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNRNv_mloS89"
   },
   "source": [
    "If you prefer not to upload your images to the cloud, you could try to run the library locally following the [guide](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker) in github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPn9Jxn-tTlW",
    "outputId": "17471338-0118-4161-fc50-1b852ceea385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionnaire mémorisé\n"
     ]
    }
   ],
   "source": [
    "dict_arbres = {\n",
    "    'BOJ' : \"Betula alleghaniensis - Bouleau jaune - Yellow birch\",\n",
    "    'BOP' : \"Betula papyrifera - Bouleau à papier - White birch\",\n",
    "    'CHR' : \"Quercus rubra - Chêne rouge - Northern red oak\",\n",
    "    'EPB' : \"Picea glauca - Épinette blanche - White spruce\",\n",
    "    'EPN' : \" Picea mariana - Épinette noire - Black spruce\",\n",
    "    'EPO' : \"Picea abies - Épinette de Norvège - Norway spruce\",\n",
    "    'EPR' : \"Picea rubens - Épinette rouge - Red spruce\",\n",
    "    'ERB' : \"Acer platanoides - Érable de Norvège - Norway maple\",\n",
    "    'ERR' : \"Acer rubrum - Érable rouge - Red maple\",\n",
    "    'ERS' : \"Acer saccharum - Érable à sucre - Sugar maple\",\n",
    "    'FRA' : \"Fraxinus americana - Frêne d'Amérique - White ash\",\n",
    "    'HEG' : \"Fagus grandifolia - Hêtre à grandes feuilles - American beech\",\n",
    "    'MEL' : \"Larix laricina - Mélèze - Tamarack\",\n",
    "    'ORA' : \"Ulmus americana - Orme d'Amérique - American elm\",\n",
    "    'OSV' : \"Ostrya virginiana - Ostryer de Virginie - American hophornbeam\",\n",
    "    'PEG' : \"Populus grandidentata - Peuplier à grandes dents - Big-tooth aspen\",\n",
    "    'PET' : \"Populus tremuloides - Peuplier faux tremble - Quaking aspen\",\n",
    "    'PIB' : \"Pinus strobus - Pin blanc - Eastern white pine\",\n",
    "    'PID' : \"Pinus rigida - Pin rigide - Pitch pine\",\n",
    "    'PIR' : \"Pinus resinosa - Pin rouge - Red pine\",\n",
    "    'PRU' : \"Tsuga canadensis - Pruche du Canada - Eastern Hemlock\",\n",
    "    'SAB' : \"Abies balsamea - Sapin Baumier - Balsam fir\",\n",
    "    'THO' : \"Thuja occidentalis - Thuya occidental - Northern white cedar\",\n",
    "}\n",
    "\n",
    "print(\"Dictionnaire mémorisé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7yi4LRItp3m"
   },
   "source": [
    "### Création des répertoires de données\n",
    "\n",
    "Nous allons créer un répertoire de base `donnees`, un répertoire `lab_ecorces` où les données seront réparties en données d'entraînement, de validation et de test pour chaque classe cible.\n",
    "\n",
    "Enfin, un répertoire `modeles` pour mémoriser les modèles une fois entraînés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cvRvZrgDtyhr"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"/content/donnees/\")\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(\"/content/lab_ecorces/\")\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(\"/content/modeles/\")\n",
    "except OSError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8UUEiaNuCUv",
    "outputId": "2ae4c1a5-ab88-4c10-9496-ff1c4e0754f4"
   },
   "source": [
    "### Utilisation de l'IPA (<i>API</i>) de Kaggle pour l'importation directe du jeu de données BarkNet\n",
    "\n",
    "1. Commencez par installer la bibliothèque Python `kaggle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Si ce n'est déjà fait, devenez membre de Kaggle avec votre adresse de courriel GMail:<br/>\n",
    "\n",
    "<img src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Kaggle_API-1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Maintenant, vous devez télécharger votre clé privée pour utiliser l'IPA de Kaggle.\n",
    "\n",
    "4. Cliquez sur l'onglet « account » de votre profil Kaggle\n",
    "\n",
    "<img src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Kaggle_API-2.png\"/>\n",
    "\n",
    "5. Sur la page « Account » cliquez sur le bouton « Create New API Token ».\n",
    "    \n",
    "<img style=\"margin-left:40px;\" src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Kaggle_API-3.png\"/>\n",
    "\n",
    "6. Téléchargez votre clé privée « kaggle.json » pour l'IPA Kaggle dans un endroit temporaire sur votre poste de travail.\n",
    "\n",
    "<img style=\"margin-left:40px;\" src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Kaggle_API-5.png\"/>\n",
    "\n",
    "7. Maintenant, transférez (téléversez) votre clé privée « kaggle.json » dans votre environnement Colab.\n",
    "\n",
    "La fenêtre de l'outil de fichiers de votre ordinateur s'ouvre alors. Allez chercher votre clé privée « kaggle.json » que vous avez sauvegardée sur votre  ordinateur.\n",
    "\n",
    "<img style=\"margin-left:40px;\" src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Colab_Importer_Fichier.png\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Créer à la racine un répertoire .kaggle et déplacez votre clé privée « kaggle.json » dans ce répertoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp /content/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!ls ~/.kaggle -all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Maintenant téléchargez le jeu de données « barknet » de 32 Go avec la commande suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention! Jeu réduit de données 1.5 Go - plus rapide à télécharger et à traiter\n",
    "!kaggle datasets download claudecoulombe/barknet --unzip -p /content/donnees/\n",
    "repertoire_entree = \"/content/donnees/BarkNet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Répartition des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPpkL78QuH2S",
    "outputId": "297e392c-bf01-4c56-946a-4bcf50b67d51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
      "Installing collected packages: split-folders\n",
      "Successfully installed split-folders-0.5.1\n"
     ]
    }
   ],
   "source": [
    "# Installation des bibliothèques Python `split-folders` et `tqdm`\n",
    "!pip3 install split-folders tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7B6KaLezuP0w",
    "outputId": "3844402d-251c-4c3a-e669-1e7dc8296fdf"
   },
   "outputs": [],
   "source": [
    "# Répartition des données d'entraînement, de validation et de tests\n",
    "import splitfolders\n",
    "import pathlib\n",
    "\n",
    "#### répertoire des données une fois réparties\n",
    "repertoire_donnees_reparties = \"/content/lab_ecorces\"\n",
    "# => train, val, test\n",
    "\n",
    "nombre_images = len(list(pathlib.Path(repertoire_entree).glob('*/*.jpg')))\n",
    "print(\"Nombre total d'images:\",nombre_images)\n",
    "\n",
    "splitfolders.ratio(repertoire_entree, \n",
    "                   output=repertoire_donnees_reparties, \n",
    "                   seed=42, \n",
    "                   ratio = (0.65, 0.15, 0.20)\n",
    "                   )\n",
    "\n",
    "print(\"\\nRépartition des données terminée!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "N3niK_O1uhAQ"
   },
   "outputs": [],
   "source": [
    "image_path = \"/content/lab_ecorces/train/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-VDriAdsowu"
   },
   "source": [
    "### Run the example\n",
    "The example just consists of 4 lines of code as shown below, each of which representing one step of the overall process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ahtcO86tZBL"
   },
   "source": [
    "1.   Load input data specific to an on-device ML app. Split it to training data and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lANoNS_gtdH1",
    "outputId": "c2aa0cdc-591c-4280-a032-c65c11f9c277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 3981, num_label: 20, labels: BOJ, BOP, CHR, EPB, EPN, EPO, EPR, ERR, ERS, FRA, HEG, MEL, ORA, OSV, PET, PIB, PIR, PRU, SAB, THO.\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader.from_folder(image_path)\n",
    "train_data, test_data = data.split(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_9IWyIztuRF"
   },
   "source": [
    "2. Customize the TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRXMZbrwtyRD",
    "outputId": "10e1046b-975a-44ff-8317-449508c37313",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hub_keras_layer_v1v2_5 (Hub  (None, 1280)             3413024   \n",
      " KerasLayerV1V2)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20)                25620     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,438,644\n",
      "Trainable params: 25,620\n",
      "Non-trainable params: 3,413,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n",
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "111/111 [==============================] - 35s 290ms/step - loss: 2.1394 - accuracy: 0.4158\n",
      "Epoch 2/50\n",
      "111/111 [==============================] - 32s 290ms/step - loss: 1.6251 - accuracy: 0.6028\n",
      "Epoch 3/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.5631 - accuracy: 0.6298\n",
      "Epoch 4/50\n",
      "111/111 [==============================] - 32s 290ms/step - loss: 1.4994 - accuracy: 0.6613\n",
      "Epoch 5/50\n",
      "111/111 [==============================] - 32s 290ms/step - loss: 1.4589 - accuracy: 0.6799\n",
      "Epoch 6/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.4427 - accuracy: 0.6867\n",
      "Epoch 7/50\n",
      "111/111 [==============================] - 32s 290ms/step - loss: 1.4250 - accuracy: 0.7066\n",
      "Epoch 8/50\n",
      "111/111 [==============================] - 37s 330ms/step - loss: 1.4094 - accuracy: 0.7019\n",
      "Epoch 9/50\n",
      "111/111 [==============================] - 38s 337ms/step - loss: 1.3881 - accuracy: 0.7128\n",
      "Epoch 10/50\n",
      "111/111 [==============================] - 33s 294ms/step - loss: 1.3725 - accuracy: 0.7216\n",
      "Epoch 11/50\n",
      "111/111 [==============================] - 35s 320ms/step - loss: 1.3558 - accuracy: 0.7359\n",
      "Epoch 12/50\n",
      "111/111 [==============================] - 37s 331ms/step - loss: 1.3495 - accuracy: 0.7278\n",
      "Epoch 13/50\n",
      "111/111 [==============================] - 41s 367ms/step - loss: 1.3432 - accuracy: 0.7241\n",
      "Epoch 14/50\n",
      "111/111 [==============================] - 36s 322ms/step - loss: 1.3586 - accuracy: 0.7269\n",
      "Epoch 15/50\n",
      "111/111 [==============================] - 36s 325ms/step - loss: 1.3487 - accuracy: 0.7334\n",
      "Epoch 16/50\n",
      "111/111 [==============================] - 36s 326ms/step - loss: 1.3336 - accuracy: 0.7379\n",
      "Epoch 17/50\n",
      "111/111 [==============================] - 33s 299ms/step - loss: 1.3267 - accuracy: 0.7328\n",
      "Epoch 18/50\n",
      "111/111 [==============================] - 40s 364ms/step - loss: 1.3179 - accuracy: 0.7410\n",
      "Epoch 19/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.3167 - accuracy: 0.7407\n",
      "Epoch 20/50\n",
      "111/111 [==============================] - 35s 313ms/step - loss: 1.3057 - accuracy: 0.7441\n",
      "Epoch 21/50\n",
      "111/111 [==============================] - 33s 298ms/step - loss: 1.3122 - accuracy: 0.7458\n",
      "Epoch 22/50\n",
      "111/111 [==============================] - 33s 298ms/step - loss: 1.3074 - accuracy: 0.7475\n",
      "Epoch 23/50\n",
      "111/111 [==============================] - 32s 290ms/step - loss: 1.3076 - accuracy: 0.7523\n",
      "Epoch 24/50\n",
      "111/111 [==============================] - 32s 290ms/step - loss: 1.3107 - accuracy: 0.7475\n",
      "Epoch 25/50\n",
      "111/111 [==============================] - 32s 290ms/step - loss: 1.2963 - accuracy: 0.7573\n",
      "Epoch 26/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2986 - accuracy: 0.7466\n",
      "Epoch 27/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2944 - accuracy: 0.7497\n",
      "Epoch 28/50\n",
      "111/111 [==============================] - 32s 289ms/step - loss: 1.2866 - accuracy: 0.7630\n",
      "Epoch 29/50\n",
      "111/111 [==============================] - 32s 290ms/step - loss: 1.2888 - accuracy: 0.7539\n",
      "Epoch 30/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2908 - accuracy: 0.7545\n",
      "Epoch 31/50\n",
      "111/111 [==============================] - 32s 290ms/step - loss: 1.2694 - accuracy: 0.7655\n",
      "Epoch 32/50\n",
      "111/111 [==============================] - 32s 292ms/step - loss: 1.2668 - accuracy: 0.7677\n",
      "Epoch 33/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2903 - accuracy: 0.7610\n",
      "Epoch 34/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2705 - accuracy: 0.7666\n",
      "Epoch 35/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2759 - accuracy: 0.7590\n",
      "Epoch 36/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2514 - accuracy: 0.7829\n",
      "Epoch 37/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2694 - accuracy: 0.7644\n",
      "Epoch 38/50\n",
      "111/111 [==============================] - 32s 292ms/step - loss: 1.2724 - accuracy: 0.7646\n",
      "Epoch 39/50\n",
      "111/111 [==============================] - 32s 292ms/step - loss: 1.2653 - accuracy: 0.7734\n",
      "Epoch 40/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2706 - accuracy: 0.7706\n",
      "Epoch 41/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2674 - accuracy: 0.7624\n",
      "Epoch 42/50\n",
      "111/111 [==============================] - 32s 292ms/step - loss: 1.2618 - accuracy: 0.7790\n",
      "Epoch 43/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2558 - accuracy: 0.7663\n",
      "Epoch 44/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2541 - accuracy: 0.7689\n",
      "Epoch 45/50\n",
      "111/111 [==============================] - 32s 289ms/step - loss: 1.2575 - accuracy: 0.7683\n",
      "Epoch 46/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2683 - accuracy: 0.7691\n",
      "Epoch 47/50\n",
      "111/111 [==============================] - 33s 293ms/step - loss: 1.2718 - accuracy: 0.7694\n",
      "Epoch 48/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2496 - accuracy: 0.7753\n",
      "Epoch 49/50\n",
      "111/111 [==============================] - 32s 291ms/step - loss: 1.2509 - accuracy: 0.7717\n",
      "Epoch 50/50\n",
      "111/111 [==============================] - 32s 292ms/step - loss: 1.2372 - accuracy: 0.7832\n"
     ]
    }
   ],
   "source": [
    "model = image_classifier.create(train_data,use_augmentation=True,epochs=50,dropout_rate=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxU2fDr-t2Ya"
   },
   "source": [
    "3. Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQr02VxJt6Cs",
    "outputId": "5b3a37ad-a66f-4df0-8013-e40b3ea99d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 27s 283ms/step - loss: 1.1507 - accuracy: 0.8070\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "4JijeCd79Wmf"
   },
   "outputs": [],
   "source": [
    "# history = model.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPEHGZuZ9weB",
    "outputId": "d1d4b766-f656-4b39-d56e-880ee0abe989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitude données de test accuracy:   0.81\n"
     ]
    }
   ],
   "source": [
    "print(\"Exactitude données de test accuracy:   %0.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ouWEKIc9-F9m",
    "outputId": "4232e5e3-fb9a-4c6c-a818-59b34030d68e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MEL', 'PRU', 'EPO', 'PIB', 'HEG', 'FRA', 'FRA', 'ERS', 'BOJ', 'ORA', 'MEL', 'MEL', 'EPO', 'EPO', 'EPB', 'FRA', 'EPO', 'ERS', 'SAB', 'ERS', 'PRU', 'ORA', 'CHR', 'BOP', 'BOP', 'FRA', 'FRA', 'ERS', 'CHR', 'ERS', 'ERS', 'BOJ', 'MEL', 'BOP', 'MEL', 'CHR', 'EPB', 'HEG', 'EPR', 'ERS', 'EPO', 'BOJ', 'BOJ', 'BOP', 'ERS', 'FRA', 'BOP', 'OSV', 'EPB', 'THO', 'ERS', 'ERS', 'ERR', 'BOJ', 'MEL', 'ERS', 'CHR', 'FRA', 'CHR', 'EPB', 'MEL', 'SAB', 'ERS', 'BOJ', 'MEL', 'MEL', 'CHR', 'CHR', 'EPR', 'CHR', 'ERR', 'PET', 'ERR', 'EPN', 'SAB', 'ERR', 'BOP', 'CHR', 'ERS', 'THO', 'THO', 'ERR', 'CHR', 'EPR', 'CHR', 'ERR', 'EPO', 'CHR', 'BOJ', 'FRA', 'PIB', 'OSV', 'CHR', 'EPN', 'HEG', 'ERR', 'ORA', 'EPN', 'THO', 'PIB', 'PIR', 'SAB', 'EPR', 'FRA', 'THO', 'EPO', 'FRA', 'EPN', 'SAB', 'CHR', 'HEG', 'MEL', 'CHR', 'FRA', 'PET', 'ORA', 'ERR', 'BOP', 'ERR', 'CHR', 'OSV', 'ERS', 'OSV', 'FRA', 'THO', 'THO', 'OSV', 'PIB', 'MEL', 'ERR', 'EPN', 'ERR', 'HEG', 'ERR', 'PIB', 'BOJ', 'PET', 'MEL', 'CHR', 'ERR', 'EPN', 'THO', 'BOP', 'ORA', 'PRU', 'FRA', 'ERR', 'SAB', 'ERS', 'MEL', 'OSV', 'ERS', 'EPO', 'FRA', 'CHR', 'SAB', 'OSV', 'OSV', 'PET', 'EPO', 'HEG', 'SAB', 'CHR', 'ERS', 'EPO', 'MEL', 'PIB', 'THO', 'OSV', 'PRU', 'FRA', 'FRA', 'MEL', 'CHR', 'CHR', 'EPB', 'FRA', 'MEL', 'ERR', 'ERR', 'PET', 'PIB', 'EPR', 'PIR', 'PET', 'SAB', 'PET', 'CHR', 'FRA', 'ERR', 'FRA', 'PIR', 'PRU', 'FRA', 'ERS', 'ERS', 'SAB', 'PET', 'EPB', 'EPB', 'EPN', 'PIR', 'CHR', 'SAB', 'BOP', 'ERR', 'EPN', 'ERS', 'EPO', 'EPO', 'PET', 'HEG', 'SAB', 'EPR', 'CHR', 'PET', 'ERR', 'CHR', 'PET', 'SAB', 'FRA', 'MEL', 'EPO', 'BOP', 'EPO', 'CHR', 'ERS', 'ERR', 'EPO', 'CHR', 'CHR', 'MEL', 'FRA', 'EPO', 'BOJ', 'BOJ', 'ERS', 'FRA', 'PRU', 'HEG', 'PRU', 'BOP', 'SAB', 'ERS', 'PRU', 'ERS', 'FRA', 'EPO', 'EPO', 'PRU', 'BOP', 'FRA', 'EPN', 'CHR', 'ERS', 'PIR', 'HEG', 'EPN', 'ERR', 'PIB', 'SAB', 'OSV', 'PRU', 'EPN', 'CHR', 'BOJ', 'EPO', 'SAB', 'OSV', 'ERS', 'ERS', 'EPO', 'THO', 'CHR', 'EPR', 'BOP', 'EPO', 'PET', 'THO', 'EPB', 'FRA', 'OSV', 'ERS', 'BOJ', 'MEL', 'CHR', 'PRU', 'BOJ', 'PIR', 'PIB', 'MEL', 'ERR', 'SAB', 'CHR', 'ERS', 'EPO', 'PRU', 'EPR', 'MEL', 'MEL', 'PIB', 'PIB', 'OSV', 'EPO', 'PRU', 'BOP', 'EPR', 'BOJ', 'FRA', 'EPO', 'PET', 'PET', 'ERS', 'THO', 'CHR', 'OSV', 'OSV', 'FRA', 'EPO', 'CHR', 'ORA', 'ORA', 'ERS', 'THO', 'MEL', 'ORA', 'HEG', 'ERS', 'SAB', 'FRA', 'MEL', 'ERR', 'CHR', 'SAB', 'CHR', 'ERS', 'PET', 'FRA', 'ERR', 'CHR', 'PET', 'MEL', 'SAB', 'FRA', 'FRA', 'PIR', 'EPO', 'ERR', 'ORA', 'EPO', 'PRU', 'ORA', 'CHR', 'PRU', 'MEL', 'CHR', 'EPB', 'CHR', 'EPN', 'CHR', 'ERR', 'CHR', 'FRA', 'EPR', 'PET', 'ERS', 'ERR', 'FRA', 'BOP', 'ERR', 'THO', 'EPO', 'PIB', 'OSV', 'OSV', 'CHR', 'ERR', 'CHR', 'EPN', 'EPR', 'EPO', 'CHR', 'ERR', 'EPB', 'THO', 'CHR', 'ERS', 'FRA', 'SAB', 'CHR', 'MEL', 'EPO', 'EPO', 'ERR', 'MEL', 'ERR', 'PIR', 'HEG', 'EPO']\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_top_k(test_data)\n",
    "# predictions_index = np.argmax(predictions, axis=1)\n",
    "predictions_index = [resultat[0][0] for resultat in predictions]\n",
    "print(predictions_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cpwfIQu8RwQz",
    "outputId": "f41aa889-037a-4ab0-ac54-ef8d88b5e631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "XbKZdOkvQWqw"
   },
   "outputs": [],
   "source": [
    "test_data = test_data.gen_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOLo1cQYR1k-",
    "outputId": "c9fa65e2-29ad-4177-ce1c-ea24418c550c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "o66gvKqoR9cp"
   },
   "outputs": [],
   "source": [
    "def get_labels_from_tfdataset(tfdataset, batched=False):\n",
    "    labels = list(map(lambda x: x[1], tfdataset)) # Get labels \n",
    "    if not batched:\n",
    "        return tf.concat(labels, axis=0) # concat the list of batched labels\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nj_7e9akRRW1",
    "outputId": "e2c90683-a467-4f2c-e49d-57656c4ba84b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 17, 3, 15, 10, 9, 9, 8, 0, 4, 11, 11, 5, 4, 3, 9, 5, 8, 18, 8, 17, 13, 2, 0, 1, 9, 9, 8, 2, 8, 8, 0, 17, 0, 11, 2, 3, 10, 6, 8, 3, 0, 0, 1, 8, 9, 1, 2, 14, 19, 8, 8, 7, 0, 11, 13, 2, 9, 2, 3, 11, 18, 8, 0, 11, 11, 18, 13, 6, 1, 7, 14, 17, 4, 18, 7, 1, 2, 8, 19, 19, 10, 7, 6, 2, 7, 5, 2, 1, 9, 15, 13, 2, 11, 10, 10, 12, 4, 19, 15, 16, 18, 4, 9, 19, 5, 9, 4, 15, 2, 3, 11, 2, 9, 14, 12, 12, 1, 7, 2, 13, 8, 13, 9, 13, 19, 13, 15, 11, 7, 4, 2, 10, 7, 15, 0, 14, 11, 2, 7, 4, 19, 1, 12, 17, 9, 8, 18, 8, 11, 13, 8, 5, 9, 7, 18, 13, 7, 14, 5, 10, 18, 2, 8, 5, 11, 15, 19, 13, 17, 9, 9, 11, 2, 2, 3, 9, 11, 7, 7, 14, 15, 6, 16, 14, 18, 14, 14, 9, 7, 8, 16, 17, 9, 8, 2, 18, 14, 18, 3, 4, 16, 5, 18, 1, 7, 4, 8, 5, 5, 14, 18, 18, 11, 2, 18, 7, 2, 14, 18, 9, 11, 3, 1, 5, 2, 15, 7, 0, 2, 2, 6, 12, 5, 0, 0, 8, 9, 17, 10, 17, 1, 18, 8, 17, 8, 9, 5, 5, 17, 1, 9, 4, 2, 8, 16, 10, 4, 7, 15, 18, 13, 7, 4, 8, 0, 5, 18, 8, 8, 9, 5, 19, 3, 6, 1, 5, 7, 19, 3, 9, 13, 8, 0, 11, 2, 17, 18, 16, 15, 15, 2, 18, 2, 8, 5, 17, 6, 11, 6, 15, 16, 13, 3, 17, 0, 5, 0, 9, 5, 14, 14, 8, 19, 2, 13, 19, 9, 5, 2, 12, 9, 7, 19, 11, 8, 10, 8, 18, 9, 18, 15, 2, 18, 10, 9, 14, 9, 7, 14, 10, 11, 18, 9, 9, 16, 5, 7, 8, 5, 17, 15, 2, 17, 11, 2, 3, 2, 2, 2, 7, 8, 9, 6, 14, 8, 7, 9, 1, 7, 19, 5, 15, 13, 13, 2, 7, 2, 18, 4, 5, 2, 13, 18, 19, 7, 8, 9, 18, 9, 11, 0, 4, 8, 11, 8, 16, 10, 5]\n",
      "['EPB', 'PEG', 'ERS', 'PIR', 'EPO', 'OSV', 'OSV', 'MEL', 'SAB', 'BOJ', 'EPB', 'EPB', 'BOP', 'BOJ', 'ERS', 'OSV', 'BOP', 'MEL', 'PET', 'MEL', 'PEG', 'EPR', 'ERR', 'SAB', 'ERB', 'OSV', 'OSV', 'MEL', 'ERR', 'MEL', 'MEL', 'SAB', 'PEG', 'SAB', 'EPB', 'ERR', 'ERS', 'EPO', 'HEG', 'MEL', 'ERS', 'SAB', 'SAB', 'ERB', 'MEL', 'OSV', 'ERB', 'ERR', 'PID', 'CHR', 'MEL', 'MEL', 'FRA', 'SAB', 'EPB', 'EPR', 'ERR', 'OSV', 'ERR', 'ERS', 'EPB', 'PET', 'MEL', 'SAB', 'EPB', 'EPB', 'PET', 'EPR', 'HEG', 'ERB', 'FRA', 'PID', 'PEG', 'BOJ', 'PET', 'FRA', 'ERB', 'ERR', 'MEL', 'CHR', 'CHR', 'EPO', 'FRA', 'HEG', 'ERR', 'FRA', 'BOP', 'ERR', 'ERB', 'OSV', 'PIR', 'EPR', 'ERR', 'EPB', 'EPO', 'EPO', 'EPN', 'BOJ', 'CHR', 'PIR', 'PIB', 'PET', 'BOJ', 'OSV', 'CHR', 'BOP', 'OSV', 'BOJ', 'PIR', 'ERR', 'ERS', 'EPB', 'ERR', 'OSV', 'PID', 'EPN', 'EPN', 'ERB', 'FRA', 'ERR', 'EPR', 'MEL', 'EPR', 'OSV', 'EPR', 'CHR', 'EPR', 'PIR', 'EPB', 'FRA', 'BOJ', 'ERR', 'EPO', 'FRA', 'PIR', 'SAB', 'PID', 'EPB', 'ERR', 'FRA', 'BOJ', 'CHR', 'ERB', 'EPN', 'PEG', 'OSV', 'MEL', 'PET', 'MEL', 'EPB', 'EPR', 'MEL', 'BOP', 'OSV', 'FRA', 'PET', 'EPR', 'FRA', 'PID', 'BOP', 'EPO', 'PET', 'ERR', 'MEL', 'BOP', 'EPB', 'PIR', 'CHR', 'EPR', 'PEG', 'OSV', 'OSV', 'EPB', 'ERR', 'ERR', 'ERS', 'OSV', 'EPB', 'FRA', 'FRA', 'PID', 'PIR', 'HEG', 'PIB', 'PID', 'PET', 'PID', 'PID', 'OSV', 'FRA', 'MEL', 'PIB', 'PEG', 'OSV', 'MEL', 'ERR', 'PET', 'PID', 'PET', 'ERS', 'BOJ', 'PIB', 'BOP', 'PET', 'ERB', 'FRA', 'BOJ', 'MEL', 'BOP', 'BOP', 'PID', 'PET', 'PET', 'EPB', 'ERR', 'PET', 'FRA', 'ERR', 'PID', 'PET', 'OSV', 'EPB', 'ERS', 'ERB', 'BOP', 'ERR', 'PIR', 'FRA', 'SAB', 'ERR', 'ERR', 'HEG', 'EPN', 'BOP', 'SAB', 'SAB', 'MEL', 'OSV', 'PEG', 'EPO', 'PEG', 'ERB', 'PET', 'MEL', 'PEG', 'MEL', 'OSV', 'BOP', 'BOP', 'PEG', 'ERB', 'OSV', 'BOJ', 'ERR', 'MEL', 'PIB', 'EPO', 'BOJ', 'FRA', 'PIR', 'PET', 'EPR', 'FRA', 'BOJ', 'MEL', 'SAB', 'BOP', 'PET', 'MEL', 'MEL', 'OSV', 'BOP', 'CHR', 'ERS', 'HEG', 'ERB', 'BOP', 'FRA', 'CHR', 'ERS', 'OSV', 'EPR', 'MEL', 'SAB', 'EPB', 'ERR', 'PEG', 'PET', 'PIB', 'PIR', 'PIR', 'ERR', 'PET', 'ERR', 'MEL', 'BOP', 'PEG', 'HEG', 'EPB', 'HEG', 'PIR', 'PIB', 'EPR', 'ERS', 'PEG', 'SAB', 'BOP', 'SAB', 'OSV', 'BOP', 'PID', 'PID', 'MEL', 'CHR', 'ERR', 'EPR', 'CHR', 'OSV', 'BOP', 'ERR', 'EPN', 'OSV', 'FRA', 'CHR', 'EPB', 'MEL', 'EPO', 'MEL', 'PET', 'OSV', 'PET', 'PIR', 'ERR', 'PET', 'EPO', 'OSV', 'PID', 'OSV', 'FRA', 'PID', 'EPO', 'EPB', 'PET', 'OSV', 'OSV', 'PIB', 'BOP', 'FRA', 'MEL', 'BOP', 'PEG', 'PIR', 'ERR', 'PEG', 'EPB', 'ERR', 'ERS', 'ERR', 'ERR', 'ERR', 'FRA', 'MEL', 'OSV', 'HEG', 'PID', 'MEL', 'FRA', 'OSV', 'ERB', 'FRA', 'CHR', 'BOP', 'PIR', 'EPR', 'EPR', 'ERR', 'FRA', 'ERR', 'PET', 'BOJ', 'BOP', 'ERR', 'EPR', 'PET', 'CHR', 'FRA', 'MEL', 'OSV', 'PET', 'OSV', 'EPB', 'SAB', 'BOJ', 'MEL', 'EPB', 'MEL', 'PIB', 'EPO', 'BOP']\n"
     ]
    }
   ],
   "source": [
    "list_no_arbres = get_labels_from_tfdataset(test_data)._numpy().tolist()\n",
    "print(list_no_arbres)\n",
    "vraies_etiquettes_index = [dict_no_arbres_ID[str(no_arbres+1)] for no_arbres in list_no_arbres]\n",
    "print(vraies_etiquettes_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Tk895l8-eFP",
    "outputId": "6a2c98f0-fc50-469d-b4a2-21c4577f1d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitude:   0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "score = metrics.accuracy_score(vraies_etiquettes_index, predictions_index)\n",
    "print(\"Exactitude:   %0.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "BvewF718-lca",
    "outputId": "59f9d2ee-2732-4206-ee84-5cb1ecd1a7d2"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-238b6c51ad2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvraies_etiquettes_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageClassifierDataLoader' object has no attribute 'class_names'"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Matrice de confusion',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(14,12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Matrice de confusion normalisée\")\n",
    "    else:\n",
    "        print('Matrice de confusion non normalisée')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Vraies étiquettes')\n",
    "    plt.xlabel('Étiquettes prédites')\n",
    "\n",
    "cm = metrics.confusion_matrix(vraies_etiquettes_index, predictions_index)\n",
    "class_names = list(train_data.class_names)\n",
    "plot_confusion_matrix(cm, classes=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVZw9zU8t84y"
   },
   "source": [
    "4.  Export to TensorFlow Lite model.\n",
    "You could download it in the left sidebar same as the uploading part for your own use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zb-eIzfluCoa",
    "outputId": "302926ae-476c-4cba-d5e7-de321b307d24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmuzghih_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmuzghih_/assets\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /tmp/tmp6i4hne_c/labels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /tmp/tmp6i4hne_c/labels.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully: ./ModeleEcorceIA.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully: ./ModeleEcorceIA.tflite\n"
     ]
    }
   ],
   "source": [
    "model.export(export_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyju1qc_v-wy"
   },
   "source": [
    "5. Download the trained model by clicking on the folder icon on the left hand side. Right-click on \"ModeleEcorceIA.tflite\" and select download. Or run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "7hSmJsgWM0Lp",
    "outputId": "48c8e295-fbe5-4727-fea6-149721ef6436"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_5f1a18cc-96aa-4235-880c-2db5bbef9be0\", \"ModeleEcorceIA.tflite\", 4030677)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('ModeleEcorceIA.tflite') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QujcbgibNR1e"
   },
   "source": [
    "After this simple 5 steps, we can now continue to the next step in the [codelab](https://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android-beta/#2).\n",
    "\n",
    "For a more comprehensive guide to TFLite Model Maker, please refer to this [notebook](https://colab.sandbox.google.com/github/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/demo/image_classification.ipynb) and its [documentation](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Flower_Classification_with_TFLite_Model_Maker (Beta).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
