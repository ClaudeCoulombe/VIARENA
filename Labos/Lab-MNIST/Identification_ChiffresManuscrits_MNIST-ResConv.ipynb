{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6428aeb9",
      "metadata": {
        "id": "6428aeb9"
      },
      "source": [
        "<a style=\"float:left;\" href=\"https://colab.research.google.com/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-MNIST/Identification_ChiffresManuscrits_MNIST-ResConv.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<br/>\n",
        "### Rappel - Fonctionnement d'un carnet web iPython\n",
        "\n",
        "* Pour exécuter le code contenu dans une cellule d'un carnet iPython, cliquez dans la cellule et faites (⇧↵, shift-enter);\n",
        "* Le code d'un carnet iPython s'exécute séquentiellement de haut en bas de la page. Souvent, l'importation d'une bibliothèque Python ou l'initialisation d'une variable est préalable à l'exécution d'une cellule située plus bas. Il est donc recommandé d'exécuter les cellules en séquence. Enfin, méfiez-vous des retours en arrière qui peuvent réinitialiser certaines variables;\n",
        "* Pour obtenir de l'information sur une fonction, utilisez la commande Python `help(`\"nom de la fonction\"`)`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40c12a2e",
      "metadata": {
        "id": "40c12a2e"
      },
      "source": [
        "# Identification de chiffres manuscrits - jeu de données MNIST\n",
        "## Réseau convolutif - LeNet\n",
        "\n",
        "#### Inspiration:\n",
        "\n",
        "Richmond Alake - <a href=\"https://towardsdatascience.com/understanding-and-implementing-lenet-5-cnn-architecture-deep-learning-a2d531ebc342\" target='_blank'>Understanding and Implementing LeNet-5 CNN Architecture</a> - 25 juin 2020\n",
        "\n",
        "Yann LeCun, Léon Bottou, Yoshua Bengio et Patrick Haffner <a href=\"http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf\" target='_blank'>Gradient-Based Learning Applied to Document Recognition</a> - 1998\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b819907f",
      "metadata": {
        "id": "b819907f"
      },
      "source": [
        "## Importation des bibliothèques Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4235134",
      "metadata": {
        "id": "d4235134"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\",tf.__version__)\n",
        "import keras\n",
        "print(\"Keras version:\",keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixer le hasard pour la reproductibilité\n",
        "\n",
        "La mise au point de réseaux de neurones implique certains processus aléatoires. Afin de pouvoir reproduire et comparer vos résultats d'expérience, vous fixez temporairement l'état aléatoire grâce à un germe aléatoire unique.\n",
        "\n",
        "Pendant la mise au point, vous fixez temporairement l'état aléatoire pour la reproductibilité mais vous répétez l'expérience avec différents germes ou états aléatoires et prenez la moyenne des résultats.\n",
        "<br/>\n",
        "##### **Note**: Pour un système en production, vous ravivez simplement l'état  purement aléatoire avec l'instruction `GERME_ALEATOIRE = None`"
      ],
      "metadata": {
        "id": "NNFC3AN-yqP2"
      },
      "id": "NNFC3AN-yqP2"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Définir un germe aléatoire\n",
        "GERME_ALEATOIRE = 21\n",
        "\n",
        "# Définir un état aléatoire pour Python\n",
        "os.environ['PYTHONHASHSEED'] = str(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour Python random\n",
        "import random\n",
        "random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour NumPy\n",
        "import numpy as np\n",
        "np.random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour TensorFlow\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(GERME_ALEATOIRE)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "print(\"Germe aléatoire fixé\")"
      ],
      "metadata": {
        "id": "txP9WU9oysRc"
      },
      "id": "txP9WU9oysRc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0edea099",
      "metadata": {
        "id": "0edea099"
      },
      "source": [
        "## Jeu de données - chiffres manuscrits MNIST\n",
        "\n",
        "Le jeu de données MNIST (Modified National Institute of Standards and Technology) comporte 60,000 images en tons de gris de 28×28 pixels de chiffres manuscrits étiquetés de 0 à 9. Site web: http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "Il est incorporé dans keras.datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7abc7fec",
      "metadata": {
        "id": "7abc7fec"
      },
      "source": [
        "### Lecture des données\n",
        "### Séparation entre jeu de données d'entraînement et jeux de données de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c5c18a",
      "metadata": {
        "id": "41c5c18a"
      },
      "outputs": [],
      "source": [
        "# le jeu de données MNIST\n",
        "from keras.datasets import mnist\n",
        "\n",
        "dic_noms_classe = {\n",
        "    0 : \"0\",\n",
        "    1 : \"1\",\n",
        "    2 : \"2\",\n",
        "    3 : \"3\",\n",
        "    4 : \"4\",\n",
        "    5 : \"5\",\n",
        "    6 : \"6\",\n",
        "    7 : \"7\",\n",
        "    8 : \"8\",\n",
        "    9 : \"9\",\n",
        "}\n",
        "\n",
        "# lire le jeu de données MNIST et le diviser entre\n",
        "# les données d'entrainement et les données de test\n",
        "# MNIST est déjà divisé en un jeu de données d'entraînement (les 60 000 premières images)\n",
        "# et un jeu de données de test (les 10 000 dernières images).\n",
        "(attributs_entrainement, classes_cibles_entrainement), (attributs_test, classes_cibles_test) = mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d72b18c",
      "metadata": {
        "id": "9d72b18c"
      },
      "source": [
        "## Exploration des données"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f5eb0f8",
      "metadata": {
        "id": "5f5eb0f8"
      },
      "source": [
        "### Portrait des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1cb8d3",
      "metadata": {
        "id": "ae1cb8d3"
      },
      "outputs": [],
      "source": [
        "# Portrait des données\n",
        "print()\n",
        "print('Entraînement: attributs=%s, classes=%s' % (attributs_entrainement.shape, classes_cibles_entrainement.shape))\n",
        "print('Test: attributs=%s, classes=%s' % (attributs_test.shape, classes_cibles_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc2b759f",
      "metadata": {
        "id": "bc2b759f"
      },
      "outputs": [],
      "source": [
        "attributs_entrainement.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0377c9d",
      "metadata": {
        "id": "f0377c9d"
      },
      "source": [
        "### Visualisation de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9ca8b9",
      "metadata": {
        "id": "3a9ca8b9"
      },
      "outputs": [],
      "source": [
        "# Afficher les 24 premières images\n",
        "print()\n",
        "print(\"Quelques images avec leur étiquette de classe-cible...\")\n",
        "%matplotlib inline\n",
        "# définir subplot\n",
        "fig, axes = plt.subplots(nrows=4,ncols=6,figsize=(13,10))\n",
        "for i_rangee in range(0,4):\n",
        "    for i_colonne in range(0,6):\n",
        "        axes[i_rangee,i_colonne].set_title(dic_noms_classe[int(classes_cibles_entrainement[i_rangee*6+i_colonne])],\n",
        "                                           fontsize=10, color='red')\n",
        "        axes[i_rangee,i_colonne].imshow(attributs_entrainement[i_rangee*6+i_colonne],cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac22f32c",
      "metadata": {
        "id": "ac22f32c"
      },
      "source": [
        "## Préparation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a41603a9",
      "metadata": {
        "id": "a41603a9"
      },
      "source": [
        "### Conversion des étiquettes-cibles en vecteurs binaires à un bit discriminant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c16cc87f",
      "metadata": {
        "id": "c16cc87f"
      },
      "outputs": [],
      "source": [
        "# Conversion des étiquettes-cibles en vecteurs binaires à un bit discriminant\n",
        "from keras.utils import to_categorical\n",
        "classes_cibles_entrainement = to_categorical(classes_cibles_entrainement)\n",
        "classes_cibles_test = to_categorical(classes_cibles_test)\n",
        "print(\"Conversion des étiquettes-cibles en vecteurs binaires terminée!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3269ae81",
      "metadata": {
        "id": "3269ae81"
      },
      "source": [
        "### Normalisation des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "023cb1ec",
      "metadata": {
        "id": "023cb1ec"
      },
      "outputs": [],
      "source": [
        "# Normalisation\n",
        "def normalisation(entrainement, test):\n",
        "    # convertir de nombres entiers à nombres décimaux\n",
        "    entrainement_normalise = entrainement.astype('float32')\n",
        "    test_normalise = test.astype('float32')\n",
        "    # normalisation à un nombre entre 0 et 1\n",
        "    entrainement_normalise = entrainement_normalise / 255.0\n",
        "    test_normalise = test_normalise / 255.0\n",
        "    return entrainement_normalise, test_normalise\n",
        "\n",
        "attributs_entrainement, attributs_test = normalisation(attributs_entrainement, attributs_test)\n",
        "\n",
        "print(\"Normalisation des images terminée!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7933c907",
      "metadata": {
        "id": "7933c907"
      },
      "source": [
        "## Construction d'un réseau convolutif - LeNet\n",
        "\n",
        "<img src=\"https://courses.edx.org/asset-v1:UMontrealX+Cegep-Matane-VIARENA+2T2024+type@asset+block@LeNet-52.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "334320dc",
      "metadata": {
        "id": "334320dc"
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
        "\n",
        "print(\"Création d'un modèle LeNet...\")\n",
        "\n",
        "# vecteur / tenseur d'entrée:\n",
        "#   28 pixels de hauteur,\n",
        "#   28 pixels de largeur,\n",
        "#   1 canal de couleur, puisque noir et blanc\n",
        "dimensions_entree = (28, 28, 1)\n",
        "\n",
        "# nombre de classes, chiffres de 0 à 9\n",
        "nombre_classes_cibles = 10\n",
        "\n",
        "leNet = Sequential()\n",
        "\n",
        "# Apprentissage et extraction des attributs\n",
        "\n",
        "# Couche convolutive - C1\n",
        "#   6 filtres de 5 par 5 pixels\n",
        "#      5 pixels de hauteur\n",
        "#      5 pixels de largeur\n",
        "#   bordure (padding) de 1 pixel, 'same'\n",
        "#   fonction d'activation tanh\n",
        "#   incrément de balayage (strides):\n",
        "#      horizontal = 1\n",
        "#      vertical = 1\n",
        "leNet.add(Conv2D(filters=6,\n",
        "                 kernel_size=(5,5),\n",
        "                 strides = (1,1),\n",
        "                 padding = 'same',\n",
        "                 activation='tanh',\n",
        "                 input_shape=dimensions_entree))\n",
        "\n",
        "# Couche sous-échantillonnage (pooling) - S2\n",
        "#   fenêtre d'échantillonnage de 2 par 2 pixels\n",
        "#   incrément de balayage (strides):\n",
        "#      horizontal = 2\n",
        "#      vertical = 2\n",
        "leNet.add(AveragePooling2D(pool_size=(2, 2),\n",
        "                           strides=(2,2)))\n",
        "\n",
        "# Couche convolutive - C3\n",
        "#   16 filtres de 5 par 5 pixels\n",
        "#      5 pixels de hauteur\n",
        "#      5 pixels de largeur\n",
        "#   pas de bordure (padding), 'valid'\n",
        "#   fonction d'activation tanh\n",
        "#   incrément de balayage (strides):\n",
        "#      horizontal = 1\n",
        "#      vertical = 1\n",
        "leNet.add(Conv2D(filters=16,\n",
        "                 kernel_size=(5, 5),\n",
        "                 strides = (1,1),\n",
        "                 padding = 'valid',\n",
        "                 activation='tanh'))\n",
        "\n",
        "# Couche sous-échantillonnage (pooling) - S4\n",
        "#   fenêtre d'échantillonnage de 2 par 2 pixels\n",
        "#   incrément de balayage (strides):\n",
        "#      horizontal = 2\n",
        "#      vertical = 2\n",
        "leNet.add(AveragePooling2D(pool_size=(2, 2),\n",
        "                           strides=(2,2)))\n",
        "\n",
        "# Classification des représentations par un perceptron multicouche\n",
        "# aplatissement des représentations en un vecteur unique\n",
        "leNet.add(Flatten())\n",
        "\n",
        "# Couche cachée intégralement connectée - C5\n",
        "leNet.add(Dense(units=120,\n",
        "                activation='tanh'))\n",
        "# 2e couche cachée intégralement connectée - F6\n",
        "leNet.add(Dense(units=84,\n",
        "                activation='relu'))\n",
        "\n",
        "# Couche de sortie intégralement connectée\n",
        "#    nombre de neurones de sortie = nombre_classes_cibles\n",
        "#    fonction d'activation de sortie = softmax (exponentielle normalisée)\n",
        "leNet.add(Dense(units=nombre_classes_cibles,\n",
        "                activation = 'softmax'))\n",
        "\n",
        "print()\n",
        "print(\"Description du modèle de base:\")\n",
        "leNet.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ac8ffd8",
      "metadata": {
        "id": "7ac8ffd8"
      },
      "source": [
        "### Compilation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3672c9a",
      "metadata": {
        "id": "c3672c9a"
      },
      "outputs": [],
      "source": [
        "print()\n",
        "print(\"Compilation du modèle...\")\n",
        "\n",
        "#   comme il s'agit d'une classification multiclasses avec des attributs catégoriels\n",
        "#   vous allez utiliser categorical_crossentropy\n",
        "leNet.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"Modèle compilé!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Évaluation du modèle avant entraînement"
      ],
      "metadata": {
        "id": "rqD-mBvKKtJw"
      },
      "id": "rqD-mBvKKtJw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluation du modèle avant entraînement\n",
        "\n",
        "print()\n",
        "print(\"Évaluation du modèle de base avant entraînement...\")\n",
        "\n",
        "resultats = leNet.evaluate(attributs_test, classes_cibles_test, verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats[1]*100))"
      ],
      "metadata": {
        "id": "Zoc5fpHMEam5"
      },
      "id": "Zoc5fpHMEam5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voila qui est tout à fait normal. Puisque MNIST a 10 étiquettes de classe. Ainsi, en devinant au hasard, nous devrions obtenir une exactitude de 10%."
      ],
      "metadata": {
        "id": "iHtmNl5mGSXE"
      },
      "id": "iHtmNl5mGSXE"
    },
    {
      "cell_type": "markdown",
      "id": "62d75a67",
      "metadata": {
        "id": "62d75a67"
      },
      "source": [
        "## Entraînement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "858ee15a",
      "metadata": {
        "id": "858ee15a"
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "\n",
        "print()\n",
        "print(\"Entraînement du modèle...\")\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "taille_jeu_validation = 0.1\n",
        "\n",
        "# Les images MNIST sont de 28x28 pixels, ce qui est plus petit que ce que LeNet-5\n",
        "# attend de 32x32 pixels. Une solution simple consiste à utiliser des images de\n",
        "# 28 par 28 pixels. Une solution plus complexe, serait d'ajouter une bordure de 2 pixels.\n",
        "\n",
        "# Rappel: attributs_entrainement.shape = (60000, 28, 28) => (60000, 28, 28, 1)\n",
        "\n",
        "traces_entrainement = leNet.fit(attributs_entrainement,\n",
        "                                classes_cibles_entrainement,\n",
        "                                batch_size=batch_size,\n",
        "                                epochs=epochs,\n",
        "                                validation_split=taille_jeu_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4ff02d0",
      "metadata": {
        "id": "f4ff02d0"
      },
      "source": [
        "## Évaluation du modèle avec un jeu de données test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e40319bd",
      "metadata": {
        "id": "e40319bd"
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "\n",
        "print()\n",
        "print(\"Évaluation du modèle...\")\n",
        "\n",
        "# Rappel: attributs_test.shape = (10000, 28, 28) => (10000, 28, 28, 1)\n",
        "\n",
        "resultats = leNet.evaluate(attributs_test, classes_cibles_test, verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c7b6a55",
      "metadata": {
        "id": "2c7b6a55"
      },
      "source": [
        "**Note:** On constate un gain d'environ 5% avec l'utilisation d'un réseau convolutif comme LeNet et l'exactitude obtenue avec un perceptron multicouche. Cette différence démontre l'avantage des réseaux convolutifs pour la reconnaissance d'images même simples comme des chiffres manuscrits en noir et blanc."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Affichage des courbes d'entraînement"
      ],
      "metadata": {
        "id": "cZEZPIv0OJ_M"
      },
      "id": "cZEZPIv0OJ_M"
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichage des courbes d'entraînement\n",
        "hauteur = 6\n",
        "plt.figure(figsize=(1.618*hauteur,hauteur))\n",
        "plt.title('Erreur entropie croisée')\n",
        "plt.plot(traces_entrainement.history['loss'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_loss'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Erreur\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D_3-Ck64OMLw"
      },
      "id": "D_3-Ck64OMLw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tracer l'exactitude\n",
        "hauteur = 6\n",
        "plt.figure(figsize=(1.618*hauteur,hauteur))\n",
        "plt.title('\\nExactitude de la classification')\n",
        "plt.plot(traces_entrainement.history['accuracy'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_accuracy'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Exactitude\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Sauvegarde du graphique en format .png\n",
        "# nom_graphique = \"modele_de_base-courbes_entraînement.png\"\n",
        "# plt.savefig(nom_graphique)\n",
        "# plt.close()"
      ],
      "metadata": {
        "id": "zzJEHQcSIl2H"
      },
      "id": "zzJEHQcSIl2H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84499d11",
      "metadata": {
        "id": "84499d11"
      },
      "outputs": [],
      "source": [
        "print(\"Exécution carnet IPython terminée!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LeBZ71ulZa4-"
      },
      "id": "LeBZ71ulZa4-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Identification_ChiffresManuscrits_MNIST-ResConv.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}