{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "generic-answer",
      "metadata": {
        "id": "generic-answer"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-CIFAR_10/Identification_Objets-ResConv-CIFAR_10.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "### Rappel - Fonctionnement d'un carnet web iPython\n",
        "\n",
        "* Pour exécuter le code contenu dans une cellule d'un carnet iPython, cliquez dans la cellule et faites (⇧↵, shift-enter) \n",
        "* Le code d'un carnet iPython s'exécute séquentiellement de haut en bas de la page. Souvent, l'importation d'une bibliothèque Python ou l'initialisation d'une variable est préalable à l'exécution d'une cellule située plus bas. Il est donc recommandé d'exécuter les cellules en séquence. Enfin, méfiez-vous des retours en arrière qui peuvent réinitialiser certaines variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "decent-calculator",
      "metadata": {
        "id": "decent-calculator"
      },
      "source": [
        "# Identification d'objets à partir de photos - jeu de données CIFAR-10\n",
        "## Labo réseau convolutif - architecture de base\n",
        "\n",
        "Inspiration: TensorFlow Tutorial <a href=\"https://www.tensorflow.org/tutorials/images/cnn?hl=fr\" target='_blank'>Tutoriel TensorFlow - Réseau neuronal convolutif</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importation bibliothèques Python\n",
        "\n"
      ],
      "metadata": {
        "id": "2vofdtmXJuGj"
      },
      "id": "2vofdtmXJuGj"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\",tf.__version__)\n",
        "import keras\n",
        "print(\"Keras version:\",keras.__version__)"
      ],
      "metadata": {
        "id": "Rezoo9EPJ0CD"
      },
      "id": "Rezoo9EPJ0CD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixer le hasard pour la reproductibilité\n",
        "\n",
        "La mise au point de réseaux de neurones implique certains processus aléatoires. Afin de pouvoir reproduire et comparer vos résultats d'expérience, vous fixez temporairement l'état aléatoire grâce à un germe aléatoire unique.\n",
        "\n",
        "Pendant la mise au point, vous fixez temporairement l'état aléatoire pour la reproductibilité mais vous répétez l'expérience avec différents germes ou états aléatoires et prenez la moyenne des résultats.\n",
        "<br/>\n",
        "##### **Note**: Pour un système en production, vous ravivez simplement l'état  purement aléatoire avec l'instruction `GERME_ALEATOIRE = None`"
      ],
      "metadata": {
        "id": "fdmq3VOEEvJP"
      },
      "id": "fdmq3VOEEvJP"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Définir un germe aléatoire\n",
        "GERME_ALEATOIRE = 21\n",
        "\n",
        "# Définir un état aléatoire pour Python\n",
        "os.environ['PYTHONHASHSEED'] = str(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour Python random\n",
        "import random\n",
        "random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour NumPy\n",
        "import numpy as np\n",
        "np.random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour TensorFlow\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(GERME_ALEATOIRE)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "print(\"Germe aléatoire fixé\")"
      ],
      "metadata": {
        "id": "weNtv8-OEuLI"
      },
      "id": "weNtv8-OEuLI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "exposed-ownership",
      "metadata": {
        "id": "exposed-ownership"
      },
      "source": [
        "## Jeu de données - photos CIFAR-10\n",
        "L'ensemble de données CIFAR-10 (Canadian Institute For Advanced Research) comporte 60 000 photographies en couleur de 32×32 pixels d'objets de 10 classes différentes. Il est relativement simple d'atteindre une précision de 80 %. On peut obtenir des performances de 90 % avec ces données avec des réseaux neuronaux convolutifs. \n",
        "\n",
        "* 0 : avion\n",
        "* 1 : automobile\n",
        "* 2 : oiseau\n",
        "* 3 : chat\n",
        "* 4 : chevreuil\n",
        "* 5 : chien\n",
        "* 6 : grenouille\n",
        "* 7 : cheval\n",
        "* 8 : bateau\n",
        "* 9 : camion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "obvious-pittsburgh",
      "metadata": {
        "id": "obvious-pittsburgh"
      },
      "outputs": [],
      "source": [
        "# Importer le jeu de données CIFAR-10\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "dic_noms_classe = { \n",
        "    0 : \"avion\",\n",
        "    1 : \"automobile\",\n",
        "    2 : \"oiseau\",\n",
        "    3 : \"chat\",\n",
        "    4 : \"chevreuil\",\n",
        "    5 : \"chien\",\n",
        "    6 : \"grenouille\",\n",
        "    7 : \"cheval\",\n",
        "    8 : \"bateau\",\n",
        "    9 : \"camion\",\n",
        "}\n",
        "\n",
        "# Lire le jeu de données CIFAR-10 et le diviser entre\n",
        "# les données d'entrainement et les données de test\n",
        "(attributs_entrainement, classes_cibles_entrainement), (attributs_test, classes_cibles_test) = cifar10.load_data()\n",
        "\n",
        "# résumé des données \n",
        "print()\n",
        "print('Entraînement: attributs=%s, classes-cibles=%s' % (attributs_entrainement.shape, classes_cibles_entrainement.shape))\n",
        "print('Test: attributs=%s, classes-cibles=%s' % (attributs_test.shape, classes_cibles_test.shape))\n",
        "\n",
        "# Afficher les 24 premières images\n",
        "print()\n",
        "print(\"Quelques images avec leur étiquette de classe-cible...\")\n",
        "%matplotlib inline\n",
        "# définir lagrill d'affichage des images\n",
        "fig, axes = plt.subplots(nrows=4,ncols=6,figsize=(10,8))\n",
        "for i_rangee in range(0,4):\n",
        "    for i_colonne in range(0,6):\n",
        "        axes[i_rangee,i_colonne].set_title(dic_noms_classe[int(classes_cibles_entrainement[i_rangee*6+i_colonne])],\n",
        "                                           fontsize=10)\n",
        "        axes[i_rangee,i_colonne].imshow(attributs_entrainement[i_rangee*6+i_colonne])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "difficult-prompt",
      "metadata": {
        "id": "difficult-prompt"
      },
      "source": [
        "## Prétraitement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "constant-louisiana",
      "metadata": {
        "id": "constant-louisiana"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Conversion des étiquettes de classes (ou classes-cibles) en attributs catégoriels,\n",
        "# c'est-à-dire en vecteurs binaires à un bit discriminant\n",
        "classes_cibles_entrainement = to_categorical(classes_cibles_entrainement)\n",
        "classes_cibles_test = to_categorical(classes_cibles_test)\n",
        "\n",
        "# Normalisation\n",
        "def normalisation(entrainement, test):\n",
        "    # convertir de nombres entiers à nombres décimaux\n",
        "    entrainement_normalise = entrainement.astype('float32')\n",
        "    test_normalise = test.astype('float32')\n",
        "    # normalisation à un nombre entre 0 et 1\n",
        "    entrainement_normalise = entrainement_normalise / 255.0\n",
        "    test_normalise = test_normalise / 255.0\n",
        "    return entrainement_normalise, test_normalise\n",
        "\n",
        "attributs_entrainement, attributs_test = normalisation(attributs_entrainement, attributs_test)\n",
        "\n",
        "print(\"Normalisation terminée!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aggressive-brother",
      "metadata": {
        "id": "aggressive-brother"
      },
      "source": [
        "## Modèle de base - réseau convolutif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prerequisite-minutes",
      "metadata": {
        "id": "prerequisite-minutes"
      },
      "outputs": [],
      "source": [
        "## Construction du modèle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "print(\"Création d'un modèle de base...\")\n",
        "# vecteur / tenseur d'entrée: \n",
        "#   32 pixels de hauteur,\n",
        "#   32 pixels de largeur,\n",
        "#   3 canaux ou couleurs\n",
        "dimensions_entree = (32, 32, 3)\n",
        "\n",
        "# nombre de classes\n",
        "nombre_classes_cibles = 10\n",
        "\n",
        "modele_de_base = Sequential()\n",
        "\n",
        "# Apprentissage et extraction des attributs\n",
        "# couche convolutive\n",
        "#   32 filtres de 3 par 3 pixels\n",
        "#      3 pixels de hauteur\n",
        "#      3 pixels de largeur\n",
        "#   bordure de 1 pixel, 'same'\n",
        "#   fonction d'activation ReLU \n",
        "#   incrément de balayage:\n",
        "#      horizontal = 1\n",
        "#      vertical = 1 \n",
        "modele_de_base.add(Conv2D(32, \n",
        "                          kernel_size=(3,3),\n",
        "                          activation='relu',\n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),\n",
        "                          input_shape=dimensions_entree))\n",
        "# couche de sous-échantillonnage (pooling)\n",
        "#   fenêtre d'échantillonnage de 2 par 2 pixels\n",
        "modele_de_base.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Classification des représentations par un perceptron multicouche\n",
        "# aplatissement des représentations en un vecteur unique\n",
        "modele_de_base.add(Flatten())\n",
        "# Couche cachée intégralement connectée\n",
        "modele_de_base.add(Dense(128,\n",
        "                         activation='relu'))\n",
        "# Couche de sortie intégralement connectée\n",
        "#    nombre de neurones de sortie = nombre_classes_cibles\n",
        "#    fonction d'activation de sortie = softmax (exponentielle normalisée)\n",
        "modele_de_base.add(Dense(nombre_classes_cibles, \n",
        "                         activation='softmax'))\n",
        "\n",
        "print()\n",
        "print(\"Description du modèle de base:\")\n",
        "modele_de_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modele_de_base.count_params()"
      ],
      "metadata": {
        "id": "UKUsLEEfFG04"
      },
      "id": "UKUsLEEfFG04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "entertaining-classroom",
      "metadata": {
        "id": "entertaining-classroom"
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "#   comme il s'agit d'une classifcation multiclasses\n",
        "#   vous allez utilisez \n",
        "modele_de_base.compile(loss=\"categorical_crossentropy\", \n",
        "                       optimizer=\"adam\", \n",
        "                       metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"Modèle de base compilé\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "third-queens",
      "metadata": {
        "id": "third-queens"
      },
      "source": [
        "## Entraînement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "equipped-situation",
      "metadata": {
        "id": "equipped-situation"
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "print(\"Entraînement du modèle de base...\")\n",
        "\n",
        "taille_lot = 128\n",
        "epoques = 15\n",
        "\n",
        "traces_entrainement = modele_de_base.fit(attributs_entrainement,\n",
        "                                         classes_cibles_entrainement,\n",
        "                                         batch_size=taille_lot,\n",
        "                                         epochs=epoques,\n",
        "                                         validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "brutal-belief",
      "metadata": {
        "id": "brutal-belief"
      },
      "source": [
        "## Évaluation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thirty-economy",
      "metadata": {
        "id": "thirty-economy"
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "# environ 63 %\n",
        "print()\n",
        "print(\"Évaluation du modèle de base...\")\n",
        "\n",
        "resultats = modele_de_base.evaluate(attributs_test, classes_cibles_test, verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "north-material",
      "metadata": {
        "id": "north-material"
      },
      "source": [
        "## Affichage des courbes d'entraînement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "indie-airport",
      "metadata": {
        "scrolled": false,
        "id": "indie-airport"
      },
      "outputs": [],
      "source": [
        "# Affichage des courbes d'entraînement\n",
        "hauteur = 10\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(211)\n",
        "plt.title('Erreur entropie croisée')\n",
        "plt.plot(traces_entrainement.history['loss'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_loss'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Erreur\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# tracer l'exactitude\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(212)\n",
        "plt.title('\\nExactitude de la classification')\n",
        "plt.plot(traces_entrainement.history['accuracy'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_accuracy'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Exactitude\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Sauvegarde du graphique en format .png\n",
        "# nom_graphique = \"modele_de_base-courbes_entraînement.png\"\n",
        "# plt.savefig(nom_graphique)\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "automated-martial",
      "metadata": {
        "id": "automated-martial"
      },
      "outputs": [],
      "source": [
        "print(\"Carnet IPython exécution terminée!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "Identification_Objets-ResConv-CIFAR_10.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}