{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "scheduled-sudan",
      "metadata": {
        "id": "scheduled-sudan"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-CIFAR_10/Identification_Objets-ResConv-VariantesArchitectures-CIFAR_10.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "### Rappel - Fonctionnement d'un carnet web iPython\n",
        "\n",
        "* Pour exécuter le code contenu dans une cellule d'un carnet iPython, cliquez dans la cellule et faites (⇧↵, shift-enter) \n",
        "* Le code d'un carnet iPython s'exécute séquentiellement de haut en bas de la page. Souvent, l'importation d'une bibliothèque Python ou l'initialisation d'une variable est préalable à l'exécution d'une cellule située plus bas. Il est donc recommandé d'exécuter les cellules en séquence. Enfin, méfiez-vous des retours en arrière qui peuvent réinitialiser certaines variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daily-basic",
      "metadata": {
        "id": "daily-basic"
      },
      "source": [
        "# Identification d'objets à partir de photos - jeu de données CIFAR-10\n",
        "## Labo réseau convolutif - variantes d'architecture\n",
        "\n",
        "Inspirations: \n",
        "\n",
        "* TensorFlow Tutorial - Google: <a href=\"https://www.tensorflow.org/tutorials/images/cnn?hl=fr\" target='_blank'>Tutoriel TensorFlow - Réseau neuronal convolutif</a>\n",
        "* Machine Learning Mastery - Jason Brownlee: <a href=\"https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\" target='_blank'>How to Develop a CNN From Scratch for CIFAR-10 Photo Classification</a> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "convertible-bishop",
      "metadata": {
        "id": "convertible-bishop"
      },
      "source": [
        "## Jeu de données - photos CIFAR-10\n",
        "L'ensemble de données CIFAR-10 (Canadian Institute For Advanced Research) comporte 60 000 photographies en couleur de 32×32 pixels d'objets de 10 classes différentes. Il est relativement simple d'atteindre une précision de 80 %. On peut obtenir des performances de 90 % avec ces données avec des réseaux neuronaux convolutifs. \n",
        "\n",
        "* 0 : avion\n",
        "* 1 : automobile\n",
        "* 2 : oiseau\n",
        "* 3 : chat\n",
        "* 4 : cerf\n",
        "* 5 : chien\n",
        "* 6 : grenouille\n",
        "* 7 : cheval\n",
        "* 8 : bateau\n",
        "* 9 : camion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bigger-netherlands",
      "metadata": {
        "id": "bigger-netherlands"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\",tf.__version__)\n",
        "import keras\n",
        "print(\"Keras version:\",keras.__version__)\n",
        "\n",
        "# Importer le jeu de données CIFAR-10\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "dic_noms_classe = { \n",
        "    0 : \"avion\",\n",
        "    1 : \"automobile\",\n",
        "    2 : \"oiseau\",\n",
        "    3 : \"chat\",\n",
        "    4 : \"cerf\",\n",
        "    5 : \"chien\",\n",
        "    6 : \"grenouille\",\n",
        "    7 : \"cheval\",\n",
        "    8 : \"bateau\",\n",
        "    9 : \"camion\",\n",
        "}\n",
        "\n",
        "# Lire le jeu de données CIFAR-10 et le diviser entre\n",
        "# les données d'entrainement et les données de test\n",
        "(attributs_entrainement, classes_cibles_entrainement), (attributs_test, classes_cibles_test) = cifar10.load_data()\n",
        "\n",
        "# résumé des données \n",
        "print()\n",
        "print('Entraînement: attributs=%s, classes-cibles=%s' % (attributs_entrainement.shape, classes_cibles_entrainement.shape))\n",
        "print('Test: attributs=%s, classes-cibles=%s' % (attributs_test.shape, classes_cibles_test.shape))\n",
        "\n",
        "# Afficher les 24 premières images\n",
        "print()\n",
        "print(\"Quelques images avec leur étiquette de classe-cible...\")\n",
        "%matplotlib inline\n",
        "# définir lagrill d'affichage des images\n",
        "fig, axes = plt.subplots(nrows=4,ncols=6,figsize=(10,8))\n",
        "for i_rangee in range(0,4):\n",
        "    for i_colonne in range(0,6):\n",
        "        axes[i_rangee,i_colonne].set_title(dic_noms_classe[int(classes_cibles_entrainement[i_rangee*6+i_colonne])],\n",
        "                                           fontsize=10)\n",
        "        axes[i_rangee,i_colonne].imshow(attributs_entrainement[i_rangee*6+i_colonne])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cellular-theorem",
      "metadata": {
        "id": "cellular-theorem"
      },
      "source": [
        "## Prétraitement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "certified-location",
      "metadata": {
        "id": "certified-location"
      },
      "outputs": [],
      "source": [
        "# Conversion des classes-cibles en vecteurs binaires à un bit discriminant\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "classes_cibles_entrainement = to_categorical(classes_cibles_entrainement)\n",
        "classes_cibles_test = to_categorical(classes_cibles_test)\n",
        "\n",
        "# Normalisation\n",
        "\n",
        "def normalisation(entrainement, test):\n",
        "    # convertir de nombres entiers à nombres décimaux\n",
        "    entrainement_normalise = entrainement.astype('float32')\n",
        "    test_normalise = test.astype('float32')\n",
        "    # normalisation à un nombre entre 0 et 1\n",
        "    entrainement_normalise = entrainement_normalise / 255.0\n",
        "    test_normalise = test_normalise / 255.0\n",
        "    return entrainement_normalise, test_normalise\n",
        "\n",
        "attributs_entrainement, attributs_test = normalisation(attributs_entrainement, attributs_test)\n",
        "\n",
        "print(\"Normalisation terminée!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conservative-brook",
      "metadata": {
        "id": "conservative-brook"
      },
      "source": [
        "# 1- Modèle de base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "canadian-application",
      "metadata": {
        "id": "canadian-application"
      },
      "outputs": [],
      "source": [
        "## Construction du modèle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "print(\"Création d'un modèle de base...\")\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "batch_size = 32\n",
        "# ou nombre de classes\n",
        "nombre_classes_cibles = 10\n",
        "\n",
        "modele_de_base = Sequential()\n",
        "# Apprentissage et extraction des attributs\n",
        "modele_de_base.add(Conv2D(32, \n",
        "                          kernel_size=(3,3),\n",
        "                          activation='relu',\n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),\n",
        "                          input_shape=input_shape))\n",
        "modele_de_base.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Classification des images\n",
        "# Classificateur perceptron multicouche\n",
        "modele_de_base.add(Flatten())\n",
        "modele_de_base.add(Dense(128,\n",
        "                         activation='relu',\n",
        "                         kernel_initializer='glorot_uniform'))\n",
        "modele_de_base.add(Dense(nombre_classes_cibles, \n",
        "                         activation='softmax'))\n",
        "\n",
        "print()\n",
        "print(\"Description du modèle de base:\")\n",
        "modele_de_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "twenty-football",
      "metadata": {
        "id": "twenty-football"
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "\n",
        "print()\n",
        "print(\"Compilation du modèle de base...\")\n",
        "\n",
        "modele_de_base.compile(loss=\"categorical_crossentropy\", \n",
        "                       optimizer=\"adam\", \n",
        "                       metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "animal-winning",
      "metadata": {
        "id": "animal-winning"
      },
      "source": [
        "## Entraînement du modèle de base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "optical-procurement",
      "metadata": {
        "id": "optical-procurement"
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "\n",
        "print()\n",
        "print(\"Entraînement du modèle de base...\")\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "traces_entrainement = modele_de_base.fit(attributs_entrainement,\n",
        "                                         classes_cibles_entrainement,\n",
        "                                         batch_size=batch_size,\n",
        "                                         epochs=epochs,\n",
        "                                         validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "expired-drinking",
      "metadata": {
        "id": "expired-drinking"
      },
      "source": [
        "## Évaluation du modèle de base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "norman-fairy",
      "metadata": {
        "id": "norman-fairy"
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print()\n",
        "print(\"Évaluation du modèle de base...\")\n",
        "\n",
        "resultats = modele_de_base.evaluate(attributs_test, classes_cibles_test, verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "demanding-disco",
      "metadata": {
        "id": "demanding-disco"
      },
      "source": [
        "## Affichage courbes d'entraînement du modèle de base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adverse-permit",
      "metadata": {
        "id": "adverse-permit"
      },
      "outputs": [],
      "source": [
        "# Affichage des courbes d'entraînement\n",
        "hauteur = 8\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(211)\n",
        "plt.title('Erreur entropie croisée - modele_de_base')\n",
        "plt.plot(traces_entrainement.history['loss'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_loss'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Erreur\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# tracer l'exactitude\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(212)\n",
        "plt.title('\\nExactitude de la classification - modele_de_base')\n",
        "plt.plot(traces_entrainement.history['accuracy'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_accuracy'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Exactitude\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Sauvegarde du graphique en format .png\n",
        "# nom_graphique = \"modele_de_base-courbes_entraînement.png\"\n",
        "# plt.savefig(nom_graphique)\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "employed-romantic",
      "metadata": {
        "id": "employed-romantic"
      },
      "source": [
        "# 2- Modèle 2 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suited-folks",
      "metadata": {
        "id": "suited-folks"
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "print(\"Création d'un modèle 2 fois plus profond...\")\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "batch_size = 32\n",
        "# ou nombre de classes\n",
        "nombre_classes_cibles = 10\n",
        "\n",
        "modele_2X_plus_profond = Sequential()\n",
        "# Apprentissage et extraction des attributs\n",
        "modele_2X_plus_profond.add(Conv2D(32, \n",
        "                         kernel_size=(3,3), \n",
        "                         activation='relu', \n",
        "                         kernel_initializer='glorot_uniform',\n",
        "                         padding='same',\n",
        "                         strides=(1,1),\n",
        "                         input_shape=input_shape))\n",
        "modele_2X_plus_profond.add(MaxPooling2D(pool_size=(2,2)))\n",
        "modele_2X_plus_profond.add(Conv2D(64,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='relu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_2X_plus_profond.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Classification des images\n",
        "modele_2X_plus_profond.add(Flatten())\n",
        "modele_2X_plus_profond.add(Dense(128, \n",
        "                         activation='relu', \n",
        "                         kernel_initializer='glorot_uniform'))\n",
        "modele_2X_plus_profond.add(Dense(nombre_classes_cibles, \n",
        "                         activation='softmax'))\n",
        "print()\n",
        "print(\"Description du modèle 2 fois plus profond:\")\n",
        "modele_2X_plus_profond.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "transsexual-draft",
      "metadata": {
        "id": "transsexual-draft"
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "\n",
        "print()\n",
        "print(\"Compilation du modèle 2 fois plus profond...\")\n",
        "\n",
        "modele_2X_plus_profond.compile(loss=\"categorical_crossentropy\", \n",
        "                       optimizer=\"adam\", \n",
        "                       metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "everyday-release",
      "metadata": {
        "id": "everyday-release"
      },
      "source": [
        "## Entraînement modèle 2 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "brilliant-infrared",
      "metadata": {
        "id": "brilliant-infrared"
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "\n",
        "print()\n",
        "print(\"Entraînement du modèle 2 fois plus profond...\")\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "traces_entrainement = modele_2X_plus_profond.fit(attributs_entrainement,\n",
        "                                                 classes_cibles_entrainement,\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 epochs=epochs,\n",
        "                                                 validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "canadian-remains",
      "metadata": {
        "id": "canadian-remains"
      },
      "source": [
        "## Évaluation modèle 2 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rising-candle",
      "metadata": {
        "id": "rising-candle"
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "\n",
        "print()\n",
        "print(\"Évaluation du modèle 2 fois plus profond...\")\n",
        "\n",
        "resultats = modele_2X_plus_profond.evaluate(attributs_test, classes_cibles_test, verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "forced-wheel",
      "metadata": {
        "id": "forced-wheel"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 2 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eleven-medication",
      "metadata": {
        "id": "eleven-medication"
      },
      "outputs": [],
      "source": [
        "# Affichage des courbes d'entraînement\n",
        "hauteur = 8\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(211)\n",
        "plt.title('Erreur entropie croisée - modele_2X_plus_profond')\n",
        "plt.plot(traces_entrainement.history['loss'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_loss'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Erreur\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# tracer l'exactitude\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(212)\n",
        "plt.title('\\nExactitude de la classification - modele_2X_plus_profond')\n",
        "plt.plot(traces_entrainement.history['accuracy'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_accuracy'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Exactitude\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Sauvegarde du graphique en format .png\n",
        "# nom_graphique = \"modele_2X_plus_profond-courbes_entraînement.png\"\n",
        "# plt.savefig(nom_graphique)\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "radical-wound",
      "metadata": {
        "id": "radical-wound"
      },
      "source": [
        "# 3- Modèle 3 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "checked-feeling",
      "metadata": {
        "id": "checked-feeling"
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "print(\"Création du modèle 3 fois plus profond...\")\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "batch_size = 32\n",
        "# ou nombre de classes\n",
        "nombre_classes_cibles = 10\n",
        "\n",
        "modele_3X_plus_profond = Sequential()\n",
        "# Apprentissage et extraction des attributs\n",
        "modele_3X_plus_profond.add(Conv2D(32, \n",
        "                         kernel_size=(3,3), \n",
        "                         activation='relu', \n",
        "                         kernel_initializer='glorot_uniform',\n",
        "                         padding='same',\n",
        "                         strides=(1,1),\n",
        "                         input_shape=input_shape))\n",
        "modele_3X_plus_profond.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "modele_3X_plus_profond.add(Conv2D(64,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='relu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_3X_plus_profond.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "modele_3X_plus_profond.add(Conv2D(128,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='relu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_3X_plus_profond.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Classification des images\n",
        "modele_3X_plus_profond.add(Flatten())\n",
        "modele_3X_plus_profond.add(Dense(128,\n",
        "                           activation='relu',\n",
        "                           kernel_initializer='glorot_uniform'))\n",
        "modele_3X_plus_profond.add(Dense(nombre_classes_cibles, \n",
        "                         activation='softmax'))\n",
        "print()\n",
        "print(\"Description du modèle 3 fois plus profond:\")\n",
        "modele_3X_plus_profond.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "electronic-saudi",
      "metadata": {
        "id": "electronic-saudi"
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "\n",
        "print()\n",
        "print(\"Compilation du modèle 3 fois plus profond...\")\n",
        "\n",
        "modele_3X_plus_profond.compile(loss=\"categorical_crossentropy\", \n",
        "                       optimizer=\"adam\", \n",
        "                       metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "communist-challenge",
      "metadata": {
        "id": "communist-challenge"
      },
      "source": [
        "## Entraînement modèle 3 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cardiovascular-parameter",
      "metadata": {
        "id": "cardiovascular-parameter"
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "\n",
        "print()\n",
        "print(\"Entraînement du modèle 3 fois plus profond...\")\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "traces_entrainement = modele_3X_plus_profond.fit(attributs_entrainement,\n",
        "                                                 classes_cibles_entrainement,\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 epochs=epochs,\n",
        "                                                 validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "disturbed-greece",
      "metadata": {
        "id": "disturbed-greece"
      },
      "source": [
        "## Évaluation modèle 3 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "strategic-clear",
      "metadata": {
        "id": "strategic-clear"
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "\n",
        "print()\n",
        "print(\"Évaluation du modèle 3 fois plus profond...\")\n",
        "\n",
        "resultats = modele_3X_plus_profond.evaluate(attributs_test, classes_cibles_test, verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mediterranean-ceramic",
      "metadata": {
        "id": "mediterranean-ceramic"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 3 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "selected-coalition",
      "metadata": {
        "id": "selected-coalition"
      },
      "outputs": [],
      "source": [
        "# Affichage des courbes d'entraînement\n",
        "hauteur = 8\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(211)\n",
        "plt.title('Erreur entropie croisée  - modele_3X_plus_profond')\n",
        "plt.plot(traces_entrainement.history['loss'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_loss'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Erreur\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# tracer l'exactitude\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(212)\n",
        "plt.title('\\nExactitude de la classification - modele_3X_plus_profond')\n",
        "plt.plot(traces_entrainement.history['accuracy'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_accuracy'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Exactitude\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Sauvegarde du graphique en format .png\n",
        "# nom_graphique = \"modele_3X_plus_profond-courbes_entraînement.png\"\n",
        "# plt.savefig(nom_graphique)\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "perceived-mainstream",
      "metadata": {
        "id": "perceived-mainstream"
      },
      "source": [
        "# 4- Modèle 4 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "connected-hebrew",
      "metadata": {
        "id": "connected-hebrew"
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "print(\"Création du modèle 4 fois plus profond...\")\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "batch_size = 32\n",
        "# ou nombre de classes\n",
        "nombre_classes_cibles = 10\n",
        "\n",
        "modele_4X_plus_profond = Sequential()\n",
        "# Apprentissage et extraction des attributs\n",
        "modele_4X_plus_profond.add(Conv2D(32, \n",
        "                         kernel_size=(3,3), \n",
        "                         activation='relu', \n",
        "                         kernel_initializer='glorot_uniform',\n",
        "                         padding='same',\n",
        "                         strides=(1,1),\n",
        "                         input_shape=input_shape))\n",
        "modele_4X_plus_profond.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "modele_4X_plus_profond.add(Conv2D(64,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='relu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_4X_plus_profond.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "modele_4X_plus_profond.add(Conv2D(128,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='relu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_4X_plus_profond.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "modele_4X_plus_profond.add(Conv2D(256,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='relu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_4X_plus_profond.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Classification des images\n",
        "modele_4X_plus_profond.add(Flatten())\n",
        "modele_4X_plus_profond.add(Dense(128, \n",
        "                         activation='relu', \n",
        "                         kernel_initializer='glorot_uniform'))\n",
        "modele_4X_plus_profond.add(Dense(nombre_classes_cibles, \n",
        "                         activation='softmax'))\n",
        "\n",
        "print()\n",
        "print(\"Description du modèle 4 fois plus profond:\")\n",
        "modele_4X_plus_profond.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "experienced-search",
      "metadata": {
        "id": "experienced-search"
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "\n",
        "print()\n",
        "print(\"Compilation du modèle 4 fois plus profond...\")\n",
        "\n",
        "modele_4X_plus_profond.compile(loss=\"categorical_crossentropy\", \n",
        "                       optimizer=\"adam\", \n",
        "                       metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "located-grammar",
      "metadata": {
        "id": "located-grammar"
      },
      "source": [
        "## Entraînement modèle 4 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statewide-imperial",
      "metadata": {
        "id": "statewide-imperial"
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "\n",
        "print()\n",
        "print(\"Entraînement du modèle 4 fois plus profond...\")\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "traces_entrainement = modele_4X_plus_profond.fit(attributs_entrainement,\n",
        "                                                 classes_cibles_entrainement,\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 epochs=epochs,\n",
        "                                                 validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "periodic-credit",
      "metadata": {
        "id": "periodic-credit"
      },
      "source": [
        "## Évaluation modèle 4 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "severe-actress",
      "metadata": {
        "id": "severe-actress"
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "\n",
        "print()\n",
        "print(\"Évaluation du modèle 4 fois plus profond...\")\n",
        "\n",
        "resultats = modele_4X_plus_profond.evaluate(attributs_test, classes_cibles_test, verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unlike-trader",
      "metadata": {
        "id": "unlike-trader"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 4 fois plus profond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "registered-tolerance",
      "metadata": {
        "id": "registered-tolerance"
      },
      "outputs": [],
      "source": [
        "# Affichage des courbes d'entraînement\n",
        "hauteur = 8\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(211)\n",
        "plt.title('Erreur entropie croisée - modele_4X_plus_profond')\n",
        "plt.plot(traces_entrainement.history['loss'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_loss'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Erreur\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# tracer l'exactitude\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(212)\n",
        "plt.title('\\nExactitude de la classification - modele_4X_plus_profond')\n",
        "plt.plot(traces_entrainement.history['accuracy'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_accuracy'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Exactitude\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Sauvegarde du graphique en format .png\n",
        "# nom_graphique = \"modele_4X_plus_profond-courbes_entraînement.png\"\n",
        "# plt.savefig(nom_graphique)\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "continent-grain",
      "metadata": {
        "id": "continent-grain"
      },
      "source": [
        "# 5- Modèle 3 fois plus profond régularisé par extinction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "diverse-drove",
      "metadata": {
        "id": "diverse-drove"
      },
      "outputs": [],
      "source": [
        "# Construction d'un modèle de base\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "print(\"Création du modèle 3 fois plus profond régularisé...\")\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "batch_size = 32\n",
        "# ou nombre de classes\n",
        "nombre_classes_cibles = 10\n",
        "\n",
        "modele_3X_plus_profond_regularise = Sequential()\n",
        "\n",
        "# Apprentissage et extraction des attributs\n",
        "modele_3X_plus_profond_regularise.add(Conv2D(32, \n",
        "                         kernel_size=(3,3), \n",
        "                         activation='relu', \n",
        "                         kernel_initializer='glorot_uniform',\n",
        "                         padding='same',\n",
        "                         strides=(1,1),\n",
        "                         input_shape=input_shape))\n",
        "modele_3X_plus_profond_regularise.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# Régularisation par extinction de neurones (dropout) \n",
        "modele_3X_plus_profond_regularise.add(Dropout(0.2))\n",
        "\n",
        "modele_3X_plus_profond_regularise.add(Conv2D(64,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='relu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_3X_plus_profond_regularise.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# Régularisation par extinction de neurones (dropout) \n",
        "modele_3X_plus_profond_regularise.add(Dropout(0.2))\n",
        "\n",
        "modele_3X_plus_profond_regularise.add(Conv2D(128,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='relu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_3X_plus_profond_regularise.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# Régularisation par extinction de neurones (dropout) \n",
        "modele_3X_plus_profond_regularise.add(Dropout(0.2))\n",
        "\n",
        "# Classification des images\n",
        "modele_3X_plus_profond_regularise.add(Flatten())\n",
        "modele_3X_plus_profond_regularise.add(Dense(128, \n",
        "                         activation='relu', \n",
        "                         kernel_initializer='glorot_uniform'))\n",
        "modele_3X_plus_profond_regularise.add(Dense(nombre_classes_cibles, \n",
        "                         activation='softmax'))\n",
        "\n",
        "print()\n",
        "print(\"Description du modèle 3 fois plus profond régularisé:\")\n",
        "modele_3X_plus_profond_regularise.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "consecutive-opening",
      "metadata": {
        "id": "consecutive-opening"
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "\n",
        "print()\n",
        "print(\"Compilation du modèle 4 fois plus profond...\")\n",
        "\n",
        "modele_3X_plus_profond_regularise.compile(loss=\"categorical_crossentropy\",\n",
        "                                          optimizer=\"adam\",\n",
        "                                          metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "several-philip",
      "metadata": {
        "id": "several-philip"
      },
      "source": [
        "## Entraînement modèle 3 fois plus profond régularisé par extinction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "communist-portugal",
      "metadata": {
        "id": "communist-portugal"
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "\n",
        "print()\n",
        "print(\"Entraînement du modèle 3 fois plus profond régularisé...\")\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "traces_entrainement = modele_3X_plus_profond_regularise.fit(attributs_entrainement,\n",
        "                                                            classes_cibles_entrainement,\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            epochs=epochs,\n",
        "                                                            validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "perfect-conviction",
      "metadata": {
        "id": "perfect-conviction"
      },
      "source": [
        "## Évaluation modèle 3 fois plus profond régularisé par extinction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "varied-quest",
      "metadata": {
        "id": "varied-quest"
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print()\n",
        "print(\"Évaluation du modèle 3 fois plus profond régularisé...\")\n",
        "\n",
        "resultats = modele_3X_plus_profond_regularise.evaluate(attributs_test, classes_cibles_test, verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broadband-sphere",
      "metadata": {
        "id": "broadband-sphere"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 3 fois plus profond régularisé par extinction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pointed-national",
      "metadata": {
        "id": "pointed-national"
      },
      "outputs": [],
      "source": [
        "# Affichage des courbes d'entraînement\n",
        "hauteur = 8\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(211)\n",
        "plt.title('Erreur entropie croisée - modele_3X_plus_profond_regularise')\n",
        "plt.plot(traces_entrainement.history['loss'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_loss'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Erreur\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# tracer l'exactitude\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(212)\n",
        "plt.title('\\nExactitude de la classification - modele_3X_plus_profond_regularise')\n",
        "plt.plot(traces_entrainement.history['accuracy'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_accuracy'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Exactitude\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Sauvegarde du graphique en format .png\n",
        "# nom_graphique = \"modele_3X_plus_profond_regularise-courbes_entraînement.png\"\n",
        "# plt.savefig(nom_graphique)\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "satellite-routine",
      "metadata": {
        "id": "satellite-routine"
      },
      "source": [
        "# 6- Modèle 3 fois plus profond régularisé (L2 + extinction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "subject-communist",
      "metadata": {
        "id": "subject-communist"
      },
      "outputs": [],
      "source": [
        "# Construction d'un modèle de base\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "print(\"Création du modèle 3 fois plus profond régularisé (L2 + extinction)...\")\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "batch_size = 32\n",
        "# ou nombre de classes\n",
        "nombre_classes_cibles = 10\n",
        "diminution_poids = 0.01\n",
        "\n",
        "modele_3Xplus_profond_regL2Xtn = Sequential()\n",
        "\n",
        "# Apprentissage et extraction des attributs\n",
        "modele_3Xplus_profond_regL2Xtn.add(Conv2D(32, \n",
        "                         kernel_size=(3,3), \n",
        "                         activation='elu', \n",
        "                         kernel_initializer='glorot_uniform',\n",
        "                         kernel_regularizer=regularizers.l2(diminution_poids),\n",
        "                         padding='same',\n",
        "                         strides=(1,1),\n",
        "                         input_shape=input_shape))\n",
        "modele_3Xplus_profond_regL2Xtn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# Régularisation par extinction de neurones (dropout) \n",
        "modele_3Xplus_profond_regL2Xtn.add(Dropout(0.2))\n",
        "\n",
        "modele_3Xplus_profond_regL2Xtn.add(Conv2D(64,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='elu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          kernel_regularizer=regularizers.l2(diminution_poids),\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_3Xplus_profond_regL2Xtn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# Régularisation par extinction de neurones (dropout) \n",
        "modele_3Xplus_profond_regL2Xtn.add(Dropout(0.2))\n",
        "\n",
        "modele_3Xplus_profond_regL2Xtn.add(Conv2D(128,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='elu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          kernel_regularizer=regularizers.l2(diminution_poids),\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_3Xplus_profond_regL2Xtn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# Régularisation par extinction de neurones (dropout) \n",
        "modele_3Xplus_profond_regL2Xtn.add(Dropout(0.2))\n",
        "\n",
        "# Classification des images\n",
        "modele_3Xplus_profond_regL2Xtn.add(Flatten())\n",
        "modele_3Xplus_profond_regL2Xtn.add(Dense(128, \n",
        "                         activation='elu', \n",
        "                         kernel_initializer='glorot_uniform'))\n",
        "modele_3Xplus_profond_regL2Xtn.add(Dense(nombre_classes_cibles, \n",
        "                         activation='softmax'))\n",
        "\n",
        "print()\n",
        "print(\"Description du modèle 3 fois plus profond régularisé (L2 + extinction):\")\n",
        "modele_3Xplus_profond_regL2Xtn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "coated-depression",
      "metadata": {
        "id": "coated-depression"
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "\n",
        "print()\n",
        "print(\"Compilation du modèle 3 fois plus profond régularisé (L2 + extinction)...\")\n",
        "\n",
        "modele_3Xplus_profond_regL2Xtn.compile(loss=\"categorical_crossentropy\", \n",
        "                       optimizer=\"adam\", \n",
        "                       metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "divided-presence",
      "metadata": {
        "id": "divided-presence"
      },
      "source": [
        "## Entraînement modèle 3 fois plus profond régularisé (L2 + extinction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "registered-stock",
      "metadata": {
        "id": "registered-stock"
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "\n",
        "print()\n",
        "print(\"Entraînement du modèle 3 fois plus profond régularisé (L2 + extinction)...\")\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "traces_entrainement = modele_3Xplus_profond_regL2Xtn.fit(attributs_entrainement,\n",
        "                                                         classes_cibles_entrainement,\n",
        "                                                         batch_size=batch_size,\n",
        "                                                         epochs=epochs,\n",
        "                                                         validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "accessory-brave",
      "metadata": {
        "id": "accessory-brave"
      },
      "source": [
        "## Évaluation modèle 3 fois plus profond régularisé (L2 + extinction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "noticed-pavilion",
      "metadata": {
        "id": "noticed-pavilion"
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print()\n",
        "print(\"Évaluation du modèle 3 fois plus profond régularisé (L2 + extinction)...\")\n",
        "\n",
        "resultats = modele_3Xplus_profond_regL2Xtn.evaluate(attributs_test, classes_cibles_test, verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "standard-knife",
      "metadata": {
        "id": "standard-knife"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 3 fois plus profond régularisé (L2 + extinction) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "enabling-chuck",
      "metadata": {
        "id": "enabling-chuck"
      },
      "outputs": [],
      "source": [
        "# Affichage des courbes d'entraînement\n",
        "hauteur = 8\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(211)\n",
        "plt.title('Erreur entropie croisée - modele_3Xplus_profond_regL2Xtn')\n",
        "plt.plot(traces_entrainement.history['loss'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_loss'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Erreur\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# tracer l'exactitude\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(212)\n",
        "plt.title('\\nExactitude de la classification - modele_3Xplus_profond_regL2Xtn')\n",
        "plt.plot(traces_entrainement.history['accuracy'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_accuracy'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Exactitude\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Sauvegarde du graphique en format .png\n",
        "# nom_graphique = \"modele_3Xplus_profond_regL2Xtn-courbes_entraînement.png\"\n",
        "# plt.savefig(nom_graphique)\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "likely-parallel",
      "metadata": {
        "id": "likely-parallel"
      },
      "source": [
        "# 7- Modèle 3 fois plus profond régularisé et normalisation des lots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "elder-silver",
      "metadata": {
        "id": "elder-silver"
      },
      "outputs": [],
      "source": [
        "# Construction d'un modèle de base\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "print(\"Création du modèle 3 fois plus profond régularisé et normalisation des lots...\")\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "batch_size = 32\n",
        "# ou nombre de classes\n",
        "nombre_classes_cibles = 10\n",
        "\n",
        "modele_3X_plus_profond_reg_norm = Sequential()\n",
        "\n",
        "# Apprentissage et extraction des attributs\n",
        "modele_3X_plus_profond_reg_norm.add(Conv2D(32, \n",
        "                         kernel_size=(3,3), \n",
        "                         activation='elu', \n",
        "                         kernel_initializer='glorot_uniform',\n",
        "                         padding='same',\n",
        "                         strides=(1,1),\n",
        "                         input_shape=input_shape))\n",
        "modele_3X_plus_profond_reg_norm.add(BatchNormalization())\n",
        "modele_3X_plus_profond_reg_norm.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# Régularisation par extinction de neurones (dropout) \n",
        "modele_3X_plus_profond_reg_norm.add(Dropout(0.2))\n",
        "\n",
        "modele_3X_plus_profond_reg_norm.add(Conv2D(64,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='elu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_3X_plus_profond_reg_norm.add(BatchNormalization())\n",
        "modele_3X_plus_profond_reg_norm.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# Régularisation par extinction de neurones (dropout) \n",
        "modele_3X_plus_profond_reg_norm.add(Dropout(0.2))\n",
        "\n",
        "modele_3X_plus_profond_reg_norm.add(Conv2D(128,\n",
        "                          kernel_size=(3,3), \n",
        "                          activation='elu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),))\n",
        "modele_3X_plus_profond_reg_norm.add(BatchNormalization())\n",
        "modele_3X_plus_profond_reg_norm.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# Régularisation par extinction de neurones (dropout) \n",
        "modele_3X_plus_profond_reg_norm.add(Dropout(0.2))\n",
        "\n",
        "# Classification des images\n",
        "modele_3X_plus_profond_reg_norm.add(Flatten())\n",
        "modele_3X_plus_profond_reg_norm.add(Dense(128, \n",
        "                         activation='elu', \n",
        "                         kernel_initializer='glorot_uniform'))\n",
        "modele_3X_plus_profond_reg_norm.add(Dense(nombre_classes_cibles, \n",
        "                         activation='softmax'))\n",
        "\n",
        "print()\n",
        "print(\"Description du modèle 3 fois plus profond régularisé et normalisation des lots :\")\n",
        "modele_3X_plus_profond_reg_norm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "through-quantity",
      "metadata": {
        "id": "through-quantity"
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "\n",
        "print()\n",
        "print(\"Compilation du modèle 3 fois plus profond régularisé et normalisation des lots...\")\n",
        "\n",
        "modele_3X_plus_profond_reg_norm.compile(loss=\"categorical_crossentropy\", \n",
        "                       optimizer=\"adam\", \n",
        "                       metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tough-career",
      "metadata": {
        "id": "tough-career"
      },
      "source": [
        "## Entraînement modèle 3 fois plus profond régularisé et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "veterinary-violin",
      "metadata": {
        "id": "veterinary-violin"
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "\n",
        "print()\n",
        "print(\"Entraînement du modèle 3 fois plus profond régularisé et normalisation des lots...\")\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "traces_entrainement = modele_3X_plus_profond_reg_norm.fit(attributs_entrainement,\n",
        "                                                          classes_cibles_entrainement,\n",
        "                                                          batch_size=batch_size,\n",
        "                                                          epochs=epochs,\n",
        "                                                          validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "personalized-compact",
      "metadata": {
        "id": "personalized-compact"
      },
      "source": [
        "## Évaluation modèle 3 fois plus profond régularisé et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "invisible-sample",
      "metadata": {
        "id": "invisible-sample"
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print()\n",
        "print(\"Évaluation du modèle 3 fois plus profond régularisé et normalisation des lots...\")\n",
        "\n",
        "resultats = modele_3X_plus_profond_reg_norm.evaluate(attributs_test, classes_cibles_test, verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lesser-vertical",
      "metadata": {
        "id": "lesser-vertical"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 3X profond régularisé & normalisation lots "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "every-north",
      "metadata": {
        "id": "every-north"
      },
      "outputs": [],
      "source": [
        "# Affichage des courbes d'entraînement\n",
        "hauteur = 8\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(211)\n",
        "plt.title('Erreur entropie croisée - modèle 3X profond régularisé & normalisation lots')\n",
        "plt.plot(traces_entrainement.history['loss'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_loss'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Erreur\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# tracer l'exactitude\n",
        "plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "plt.subplot(212)\n",
        "plt.title('\\nExactitude de la classification - modèle 3X profond régularisé & normalisation lots')\n",
        "plt.plot(traces_entrainement.history['accuracy'], color='blue', label='courbe entraînement')\n",
        "plt.plot(traces_entrainement.history['val_accuracy'], color='orange', label='courbe test')\n",
        "plt.ylabel(\"Exactitude\")\n",
        "plt.xlabel(\"Nombre d'époques\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Sauvegarde du graphique en format .png\n",
        "# nom_graphique = \"modele_3Xplus_profond_regularise_&_normalisation_lots-courbes_entraînement.png\"\n",
        "# plt.savefig(nom_graphique)\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "short-latitude",
      "metadata": {
        "id": "short-latitude"
      },
      "outputs": [],
      "source": [
        "print(\"Carnet IPython exécution terminée.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fresh-hampshire",
      "metadata": {
        "id": "fresh-hampshire"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Identification_Objets-ResConv-VariantesArchitectures-CIFAR_10.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}