{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "scheduled-sudan",
      "metadata": {
        "id": "scheduled-sudan"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-CIFAR_10/Identification_Objets-ResConv-VariantesArchitectures-CIFAR_10.ipynb\" style=\"float:left;\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "### Rappel - Fonctionnement d'un carnet web iPython\n",
        "\n",
        "* Pour exécuter le code contenu dans une cellule d'un carnet iPython, cliquez dans la cellule et faites (⇧↵, shift-enter) \n",
        "* Le code d'un carnet iPython s'exécute séquentiellement de haut en bas de la page. Souvent, l'importation d'une bibliothèque Python ou l'initialisation d'une variable est préalable à l'exécution d'une cellule située plus bas. Il est donc recommandé d'exécuter les cellules en séquence. Enfin, méfiez-vous des retours en arrière qui peuvent réinitialiser certaines variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daily-basic",
      "metadata": {
        "id": "daily-basic"
      },
      "source": [
        "# Identification d'objets à partir de photos - jeu de données CIFAR-10\n",
        "## Labo réseau convolutif - variantes d'architecture\n",
        "\n",
        "Inspirations: \n",
        "\n",
        "* TensorFlow Tutorial - Google: <a href=\"https://www.tensorflow.org/tutorials/images/cnn?hl=fr\" target='_blank'>Tutoriel TensorFlow - Réseau neuronal convolutif</a>\n",
        "* Machine Learning Mastery - Jason Brownlee: <a href=\"https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\" target='_blank'>How to Develop a CNN From Scratch for CIFAR-10 Photo Classification</a> "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9d9154a",
      "metadata": {
        "id": "e9d9154a"
      },
      "source": [
        "## Importation des bibliothèques utilisées pour le tutoriel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a040d1e5",
      "metadata": {
        "id": "a040d1e5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\",tf.__version__)\n",
        "import keras\n",
        "print(\"Keras version:\",keras.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "092d5e79",
      "metadata": {
        "id": "092d5e79"
      },
      "source": [
        "## Fixer le hasard pour la reproductibilité\n",
        "\n",
        "La mise au point de réseaux de neurones implique certains processus aléatoires. Afin de pouvoir reproduire et comparer vos résultats d'expérience, vous fixez temporairement l'état aléatoire grâce à un germe aléatoire unique.\n",
        "\n",
        "Pendant la mise au point, vous fixez temporairement l'état aléatoire pour la reproductibilité mais vous répétez l'expérience avec différents germes ou états aléatoires et prenez la moyenne des résultats.\n",
        "<br/><br>\n",
        "##### **Note**: Pour un système en production, vous ravivez simplement l'état  purement aléatoire avec l'instruction `GERME_ALEATOIRE = None`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dcaaf1f",
      "metadata": {
        "id": "4dcaaf1f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Définir un germe aléatoire\n",
        "GERME_ALEATOIRE = 21\n",
        "\n",
        "# Définir un état aléatoire pour Python\n",
        "os.environ['PYTHONHASHSEED'] = str(GERME_ALEATOIRE)\n",
        "\n",
        "import random\n",
        "random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour NumPy\n",
        "import numpy as np\n",
        "np.random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour TensorFlow\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(GERME_ALEATOIRE)\n",
        "\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "print(\"Germe aléatoire fixé\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "convertible-bishop",
      "metadata": {
        "id": "convertible-bishop"
      },
      "source": [
        "## Jeu de données - photos CIFAR-10\n",
        "L'ensemble de données CIFAR-10 (Canadian Institute For Advanced Research) comporte 60 000 photographies en couleur de 32×32 pixels d'objets de 10 classes différentes. Il est relativement simple d'atteindre une précision de 80 %. On peut obtenir des performances de 90 % avec ces données avec des réseaux neuronaux convolutifs. \n",
        "\n",
        "* 0 : avion\n",
        "* 1 : automobile\n",
        "* 2 : oiseau\n",
        "* 3 : chat\n",
        "* 4 : cerf\n",
        "* 5 : chien\n",
        "* 6 : grenouille\n",
        "* 7 : cheval\n",
        "* 8 : bateau\n",
        "* 9 : camion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bigger-netherlands",
      "metadata": {
        "id": "bigger-netherlands",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Importer le jeu de données CIFAR-10\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "dic_noms_classe = { \n",
        "    0 : \"avion\",\n",
        "    1 : \"automobile\",\n",
        "    2 : \"oiseau\",\n",
        "    3 : \"chat\",\n",
        "    4 : \"cerf\",\n",
        "    5 : \"chien\",\n",
        "    6 : \"grenouille\",\n",
        "    7 : \"cheval\",\n",
        "    8 : \"bateau\",\n",
        "    9 : \"camion\",\n",
        "}\n",
        "\n",
        "# Lire le jeu de données CIFAR-10 et le diviser entre\n",
        "# les données d'entrainement et les données de test\n",
        "(attributs_entrainement, classes_cibles_entrainement), (attributs_test, classes_cibles_test) = cifar10.load_data()\n",
        "\n",
        "# résumé des données \n",
        "print()\n",
        "print('Entraînement: attributs=%s, classes-cibles=%s' % (attributs_entrainement.shape, classes_cibles_entrainement.shape))\n",
        "print('Test: attributs=%s, classes-cibles=%s' % (attributs_test.shape, classes_cibles_test.shape))\n",
        "\n",
        "# Afficher les 24 premières images\n",
        "print()\n",
        "print(\"Quelques images avec leur étiquette de classe-cible...\")\n",
        "%matplotlib inline\n",
        "# définir lagrill d'affichage des images\n",
        "fig, axes = plt.subplots(nrows=4,ncols=6,figsize=(10,8))\n",
        "for i_rangee in range(0,4):\n",
        "    for i_colonne in range(0,6):\n",
        "        axes[i_rangee,i_colonne].set_title(dic_noms_classe[int(classes_cibles_entrainement[i_rangee*6+i_colonne])],\n",
        "                                           fontsize=10)\n",
        "        axes[i_rangee,i_colonne].imshow(attributs_entrainement[i_rangee*6+i_colonne])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cellular-theorem",
      "metadata": {
        "id": "cellular-theorem"
      },
      "source": [
        "## Prétraitement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "certified-location",
      "metadata": {
        "id": "certified-location",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Conversion des classes-cibles en vecteurs binaires à un bit discriminant\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "classes_cibles_entrainement = to_categorical(classes_cibles_entrainement)\n",
        "classes_cibles_test = to_categorical(classes_cibles_test)\n",
        "\n",
        "# Normalisation\n",
        "\n",
        "def normalisation(entrainement, test):\n",
        "    # convertir de nombres entiers à nombres décimaux\n",
        "    entrainement_normalise = entrainement.astype('float32')\n",
        "    test_normalise = test.astype('float32')\n",
        "    # normalisation à un nombre entre 0 et 1\n",
        "    entrainement_normalise = entrainement_normalise / 255.0\n",
        "    test_normalise = test_normalise / 255.0\n",
        "    return entrainement_normalise, test_normalise\n",
        "\n",
        "attributs_entrainement, attributs_test = normalisation(attributs_entrainement, attributs_test)\n",
        "\n",
        "print(\"Normalisation des données terminée!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conservative-brook",
      "metadata": {
        "id": "conservative-brook"
      },
      "source": [
        "# 1- Modèle de base à 1 couche convolutive"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e51b0823",
      "metadata": {
        "id": "e51b0823"
      },
      "source": [
        "## Construction du modèle de base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "canadian-application",
      "metadata": {
        "id": "canadian-application",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "print(\"Création d'un modèle de base...\")\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "batch_size = 32\n",
        "# ou nombre de classes\n",
        "nombre_classes_cibles = 10\n",
        "\n",
        "modele_de_base = Sequential()\n",
        "# Apprentissage et extraction des attributs\n",
        "modele_de_base.add(Conv2D(32, \n",
        "                          kernel_size=(3,3),\n",
        "                          activation='relu',\n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),\n",
        "                          input_shape=input_shape))\n",
        "modele_de_base.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Classification des images\n",
        "# Classificateur perceptron multicouche\n",
        "modele_de_base.add(Flatten())\n",
        "modele_de_base.add(Dense(128,\n",
        "                         activation='relu',\n",
        "                         kernel_initializer='glorot_uniform'))\n",
        "modele_de_base.add(Dense(nombre_classes_cibles, \n",
        "                         activation='softmax'))\n",
        "\n",
        "print()\n",
        "print(\"Description du modèle de base:\")\n",
        "modele_de_base.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ba65cc9",
      "metadata": {
        "id": "1ba65cc9"
      },
      "source": [
        "### Compilation du modèle de base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "twenty-football",
      "metadata": {
        "id": "twenty-football",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "print(\"\\nCompilation du modèle de base...\")\n",
        "modele_de_base.compile(loss=\"categorical_crossentropy\", \n",
        "                       optimizer=\"adam\", \n",
        "                       metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "animal-winning",
      "metadata": {
        "id": "animal-winning"
      },
      "source": [
        "## Entraînement du modèle de base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "optical-procurement",
      "metadata": {
        "id": "optical-procurement",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "print(\"\\Entraînement du modèle de base...\")\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "traces_entrainement = modele_de_base.fit(attributs_entrainement,\n",
        "                                         classes_cibles_entrainement,\n",
        "                                         batch_size=batch_size,\n",
        "                                         epochs=epochs,\n",
        "                                         validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "expired-drinking",
      "metadata": {
        "id": "expired-drinking"
      },
      "source": [
        "## Évaluation du modèle de base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "norman-fairy",
      "metadata": {
        "id": "norman-fairy",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print(\"\\nÉvaluation du modèle de base...\")\n",
        "resultats_1 = modele_de_base.evaluate(attributs_test,\n",
        "                                      classes_cibles_test,\n",
        "                                      verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats_1[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "demanding-disco",
      "metadata": {
        "id": "demanding-disco"
      },
      "source": [
        "## Affichage courbes d'entraînement du modèle de base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adverse-permit",
      "metadata": {
        "id": "adverse-permit",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Affichage des courbes d'entraînement\n",
        "def afficher_courbes_entraînement(nom_modele,traces_entrainement):\n",
        "    # Tracer l'erreur\n",
        "    hauteur = 8\n",
        "    plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "    plt.subplot(211)\n",
        "    plt.title(\"Erreur entropie croisée - \" + nom_modele)\n",
        "    plt.plot(traces_entrainement.history['loss'], color='blue', label='courbe entraînement')\n",
        "    plt.plot(traces_entrainement.history['val_loss'], color='orange', label='courbe test')\n",
        "    plt.ylabel(\"Erreur\")\n",
        "    plt.xlabel(\"Nombre d'époques\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    # Tracer l'exactitude\n",
        "    plt.subplots(figsize=(hauteur,1.618*hauteur))\n",
        "    plt.subplot(212)\n",
        "    plt.title(\"\\nExactitude de la classification - \" + nom_modele)\n",
        "    plt.plot(traces_entrainement.history['accuracy'], color='blue', label='courbe entraînement')\n",
        "    plt.plot(traces_entrainement.history['val_accuracy'], color='orange', label='courbe test')\n",
        "    plt.ylabel(\"Exactitude\")\n",
        "    plt.xlabel(\"Nombre d'époques\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd7e8677",
      "metadata": {
        "id": "cd7e8677",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "afficher_courbes_entraînement(\"Modèle de base\",traces_entrainement)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "employed-romantic",
      "metadata": {
        "id": "employed-romantic"
      },
      "source": [
        "# 2- Modèle à 2 couches convolutives "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f8ac974",
      "metadata": {
        "id": "6f8ac974"
      },
      "source": [
        "## Construction modèle 2 couches\n",
        "\n",
        "Ici, nous allons écrire une fonction `creer_reseau_convolutif` qui nous permettra de construire des réseaux à couches convolutives de différentes profondeur à partir de 4 paramètres:\n",
        "\n",
        "<ul>\n",
        "    <ol>\n",
        "        <li><b>nbre_couches</b>: un entier pour indiquer le nombre de couches désirées de 1 à 5;</li>\n",
        "        <li><b>reg_extinction</b>: un booléen (False, True) pour indiquer l'usage de la régularisation par extinction de neurones (<i>dropout</i>);</li>\n",
        "        <li><b>reg_L2</b>: un booléen (False, True) pour indiquer l'usage de la régularisation par la fonction L2;</li>\n",
        "        <li><b>normalisation</b>: un booléen (False, True) pour indiquer la normalisation des lots de données.</li>\n",
        "    </ol>\n",
        "</ul>\n",
        "\n",
        "Notez que c'est le genre de travail que la bibliothèque Keras fait, mais à partir d'une IPA (<i>API</i>) de haut niveau, pour construire un réseau avec des instructions TensorFlow de plus bas niveau.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suited-folks",
      "metadata": {
        "id": "suited-folks",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "    \n",
        "def creer_reseau_convolutif(nbre_couches=5,reg_extinction=False,reg_L2=False,normalisation=False):\n",
        "    # Créer le nom du modèle\n",
        "    nom_modele = creer_nom_modele(nbre_couches,reg_extinction,reg_L2,normalisation)\n",
        "\n",
        "    # Afficher le nom du modèle \n",
        "    print(\"Création d'un \" + nom_modele.replace('_',' ')) \n",
        "    # Définir l'entrée des données\n",
        "    dimensions_entree = (32, 32, 3)\n",
        "    # nombre de classes-cibles\n",
        "    nombre_classes_cibles = 10\n",
        "    # Utilisation de l'API Sequential de Keras\n",
        "    modele = Sequential()\n",
        "    # Ajout d'une fonction de régularisation ou régularisateur\n",
        "    diminution_poids = 0.01\n",
        "    if (reg_L2):\n",
        "        regularisateur = regularizers.l2(diminution_poids)\n",
        "    else:\n",
        "        regularisateur = None\n",
        "    # Apprentissage et extraction des attributs\n",
        "    # Boucler sur le nombre de couches desirées\n",
        "    nombre_filtres = 16\n",
        "    for index_couche in range(1,nbre_couches+1):\n",
        "        # Couche convolutive\n",
        "        # L'augmentation du nombre de filtres en fonction de la\n",
        "        # profondeur suit une règle simple. Elle double simplement. \n",
        "        nombre_filtres *= 2\n",
        "        modele.add(Conv2D(filters=nombre_filtres,\n",
        "                          kernel_size=(3,3),\n",
        "                          activation='relu',\n",
        "                          kernel_regularizer = regularisateur,\n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          padding='same',\n",
        "                          strides=(1,1),\n",
        "                          input_shape=dimensions_entree))\n",
        "        # Normalisation des mini-lots \n",
        "        if (normalisation):\n",
        "            modele.add(BatchNormalization())\n",
        "        # Couche de sous-échantillonnage\n",
        "        modele.add(MaxPooling2D(pool_size=(2,2)))\n",
        "        if (reg_extinction):\n",
        "            # Régularisation par extinction de neurones (dropout) \n",
        "            modele.add(Dropout(0.2))\n",
        "    # Classification\n",
        "    modele.add(Flatten())\n",
        "    modele.add(Dense(units=128,\n",
        "                     activation='relu',\n",
        "                     kernel_initializer='glorot_uniform'))\n",
        "    # Sortie fonction exponentielle normalisée ou Softmax\n",
        "    modele.add(Dense(nombre_classes_cibles,\n",
        "                     activation='softmax'))\n",
        "    return modele\n",
        "\n",
        "def creer_nom_modele(nbre_couches=1,reg_extinction=False,reg_L2=False,normalisation=False):\n",
        "    nom_modele = \"réseau_convolutif_\" + str(nbre_couches) + \"_couches\"\n",
        "    if (reg_extinction or reg_L2):\n",
        "        nom_modele += \"_régularisé\"\n",
        "    if (reg_extinction):\n",
        "        nom_modele += \"_extinction\"\n",
        "    if (reg_L2):\n",
        "        nom_modele += \"_L2\"\n",
        "    if \"(\" in nom_modele:\n",
        "        nom_modele += \")\"\n",
        "    if (normalisation):\n",
        "        nom_modele += \"_et_normalisation_des_lots\"    \n",
        "    return nom_modele"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "347b2b20",
      "metadata": {
        "id": "347b2b20",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "modele_2_couches = creer_reseau_convolutif(nbre_couches=2,\n",
        "                                           reg_extinction=False,\n",
        "                                           reg_L2=False,\n",
        "                                           normalisation=False)  \n",
        "nom_modele = creer_nom_modele(nbre_couches=2,\n",
        "                              reg_extinction=False,\n",
        "                              reg_L2=False,\n",
        "                              normalisation=False)\n",
        "print(\"\\nDescription du \" + nom_modele.replace('_',' '))\n",
        "modele_2_couches.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5539ba59",
      "metadata": {
        "id": "5539ba59"
      },
      "source": [
        "### Compilation modèle 2 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "transsexual-draft",
      "metadata": {
        "id": "transsexual-draft",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "print(\"\\nCompilation d'un \" + nom_modele.replace('_',' ')+\"...\")\n",
        "modele_2_couches.compile(loss=\"categorical_crossentropy\",\n",
        "                         optimizer=\"adam\",\n",
        "                         metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "everyday-release",
      "metadata": {
        "id": "everyday-release"
      },
      "source": [
        "## Entraînement modèle 2 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "brilliant-infrared",
      "metadata": {
        "id": "brilliant-infrared",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "print(\"\\Entraînement du \" + nom_modele.replace('_',' ')+\"...\")\n",
        "taille_lots = 128\n",
        "nbr_iterations = 15\n",
        "traces_entrainement_2_couches = modele_2_couches.fit(attributs_entrainement,\n",
        "                                                     classes_cibles_entrainement,\n",
        "                                                     batch_size=taille_lots,\n",
        "                                                     epochs=nbr_iterations,\n",
        "                                                     validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "canadian-remains",
      "metadata": {
        "id": "canadian-remains"
      },
      "source": [
        "## Évaluation modèle 2 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rising-candle",
      "metadata": {
        "id": "rising-candle",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print(\"\\nÉvaluation du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "resultats_2 = modele_2_couches.evaluate(attributs_test,\n",
        "                                        classes_cibles_test,\n",
        "                                        verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats_2[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "forced-wheel",
      "metadata": {
        "id": "forced-wheel"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 2 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eleven-medication",
      "metadata": {
        "id": "eleven-medication",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "afficher_courbes_entraînement(nom_modele.replace('_',' '),\n",
        "                              traces_entrainement_2_couches)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "radical-wound",
      "metadata": {
        "id": "radical-wound"
      },
      "source": [
        "# 3- Modèle à 3 couches convolutives"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f28dd01",
      "metadata": {
        "id": "3f28dd01"
      },
      "source": [
        "## Construction modèle 3 couches "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "checked-feeling",
      "metadata": {
        "id": "checked-feeling",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "modele_3_couches = creer_reseau_convolutif(nbre_couches=3,\n",
        "                                           reg_extinction=False,\n",
        "                                           reg_L2=False,\n",
        "                                           normalisation=False)  \n",
        "nom_modele = creer_nom_modele(nbre_couches=3,\n",
        "                              reg_extinction=False,\n",
        "                              reg_L2=False,\n",
        "                              normalisation=False)\n",
        "print(\"\\nDescription du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3953c31c",
      "metadata": {
        "id": "3953c31c"
      },
      "source": [
        "### Compilation modèle 3 couches "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "electronic-saudi",
      "metadata": {
        "id": "electronic-saudi",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "print(\"\\nCompilation d'un \" + nom_modele.replace('_',' ')+\"...\")\n",
        "modele_3_couches.compile(loss=\"categorical_crossentropy\",\n",
        "                         optimizer=\"adam\",\n",
        "                         metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "communist-challenge",
      "metadata": {
        "id": "communist-challenge"
      },
      "source": [
        "## Entraînement modèle 3 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cardiovascular-parameter",
      "metadata": {
        "id": "cardiovascular-parameter",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "print(\"\\nEntraînement du \" + nom_modele.replace('_',' ')+\"...\")\n",
        "taille_lots = 128\n",
        "nbr_iterations = 15\n",
        "traces_entrainement_3_couches = modele_3_couches.fit(attributs_entrainement,\n",
        "                                                     classes_cibles_entrainement,\n",
        "                                                     batch_size=taille_lots,\n",
        "                                                     epochs=nbr_iterations,\n",
        "                                                     validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "disturbed-greece",
      "metadata": {
        "id": "disturbed-greece"
      },
      "source": [
        "## Évaluation modèle 3 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "strategic-clear",
      "metadata": {
        "id": "strategic-clear",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print(\"\\nÉvaluation du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "resultats_3 = modele_3_couches.evaluate(attributs_test,\n",
        "                                        classes_cibles_test,\n",
        "                                        verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats_3[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mediterranean-ceramic",
      "metadata": {
        "id": "mediterranean-ceramic"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 3 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "selected-coalition",
      "metadata": {
        "id": "selected-coalition",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "afficher_courbes_entraînement(nom_modele.replace('_',' '),\n",
        "                              traces_entrainement_3_couches)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "perceived-mainstream",
      "metadata": {
        "id": "perceived-mainstream"
      },
      "source": [
        "# 4- Modèle à 4 couches convolutives"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99b71753",
      "metadata": {
        "id": "99b71753"
      },
      "source": [
        "## Construction modèle 4 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "894b3db6",
      "metadata": {
        "id": "894b3db6",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "modele_4_couches = creer_reseau_convolutif(nbre_couches=4,\n",
        "                                           reg_extinction=False,\n",
        "                                           reg_L2=False,\n",
        "                                           normalisation=False)  \n",
        "nom_modele = creer_nom_modele(nbre_couches=4,\n",
        "                              reg_extinction=False,\n",
        "                              reg_L2=False,\n",
        "                              normalisation=False)\n",
        "print(\"\\nDescription du \" + nom_modele.replace('_',' '))\n",
        "modele_4_couches.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03f4910b",
      "metadata": {
        "id": "03f4910b"
      },
      "source": [
        "### Compilation modèle 4 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "experienced-search",
      "metadata": {
        "id": "experienced-search",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "print(\"\\nCompilation d'un \" + nom_modele.replace('_',' ')+\"...\")\n",
        "modele_4_couches.compile(loss=\"categorical_crossentropy\",\n",
        "                         optimizer=\"adam\",\n",
        "                         metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "located-grammar",
      "metadata": {
        "id": "located-grammar"
      },
      "source": [
        "## Entraînement modèle 4 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statewide-imperial",
      "metadata": {
        "id": "statewide-imperial",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "print(\"\\nEntraînement du \" + nom_modele.replace('_',' ')+\"...\")\n",
        "taille_lots = 128\n",
        "nbr_iterations = 15\n",
        "traces_entrainement_4_couches = modele_4_couches.fit(attributs_entrainement,\n",
        "                                                     classes_cibles_entrainement,\n",
        "                                                     batch_size=taille_lots,\n",
        "                                                     epochs=nbr_iterations,\n",
        "                                                     validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "periodic-credit",
      "metadata": {
        "id": "periodic-credit"
      },
      "source": [
        "## Évaluation modèle 4 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "severe-actress",
      "metadata": {
        "id": "severe-actress",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print(\"\\nÉvaluation du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "resultats_4 = modele_4_couches.evaluate(attributs_test,\n",
        "                                        classes_cibles_test,\n",
        "                                        verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats_4[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unlike-trader",
      "metadata": {
        "id": "unlike-trader"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 4 couches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "registered-tolerance",
      "metadata": {
        "id": "registered-tolerance",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "afficher_courbes_entraînement(nom_modele.replace('_',' '),\n",
        "                              traces_entrainement_4_couches)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "continent-grain",
      "metadata": {
        "id": "continent-grain"
      },
      "source": [
        "# 5- Modèle 3 couches régularisé par extinction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf810974",
      "metadata": {
        "id": "bf810974"
      },
      "source": [
        "## Construction modèle 3 couches régularisé par extinction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "diverse-drove",
      "metadata": {
        "id": "diverse-drove",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "modele_3_couches_regularise_extinction = creer_reseau_convolutif(nbre_couches=3,\n",
        "                                                                 reg_extinction=True,\n",
        "                                                                 reg_L2=False,\n",
        "                                                                 normalisation=False)  \n",
        "nom_modele = creer_nom_modele(nbre_couches=3,\n",
        "                              reg_extinction=True,\n",
        "                              reg_L2=False,\n",
        "                              normalisation=False)\n",
        "print(\"\\nDescription du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches_regularise_extinction.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5665fe6",
      "metadata": {
        "id": "e5665fe6"
      },
      "source": [
        "### Compilation modèle 3 couches régularisé par extinction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "consecutive-opening",
      "metadata": {
        "id": "consecutive-opening",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "print(\"\\nCompilation du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches_regularise_extinction.compile(loss=\"categorical_crossentropy\",\n",
        "                                               optimizer=\"adam\",\n",
        "                                               metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "several-philip",
      "metadata": {
        "id": "several-philip"
      },
      "source": [
        "## Entraînement modèle 3 couches régularisé par extinction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "communist-portugal",
      "metadata": {
        "id": "communist-portugal",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "print(\"\\nEntraînement du \" + nom_modele.replace('_',' '))\n",
        "taille_lots = 128\n",
        "nbr_iterations = 15\n",
        "traces_entrainement_3_couches_regularise_extinction = modele_3_couches_regularise_extinction.fit(\n",
        "    attributs_entrainement,\n",
        "    classes_cibles_entrainement,\n",
        "    batch_size=taille_lots,\n",
        "    epochs=nbr_iterations,\n",
        "    validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "perfect-conviction",
      "metadata": {
        "id": "perfect-conviction"
      },
      "source": [
        "## Évaluation modèle 3 couches régularisé par extinction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "varied-quest",
      "metadata": {
        "id": "varied-quest",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print(\"\\nÉvaluation du \" + nom_modele.replace('_',' '))\n",
        "resultats_5 = modele_3_couches_regularise_extinction.evaluate(attributs_test,\n",
        "                                                              classes_cibles_test,\n",
        "                                                              verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats_5[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broadband-sphere",
      "metadata": {
        "id": "broadband-sphere"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 3 couches régularisé par extinction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pointed-national",
      "metadata": {
        "id": "pointed-national",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "afficher_courbes_entraînement(nom_modele.replace('_',' '),\n",
        "                              traces_entrainement_3_couches_regularise_extinction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f774f3",
      "metadata": {
        "id": "97f774f3"
      },
      "source": [
        "# 6- Modèle 3 couches régularisé L2 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea0d6063",
      "metadata": {
        "id": "ea0d6063"
      },
      "source": [
        "## Construction modèle 3 couches régularisé L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c29c1171",
      "metadata": {
        "id": "c29c1171",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "modele_3_couches_regularise_L2 = creer_reseau_convolutif(nbre_couches=3,\n",
        "                                                         reg_extinction=False,\n",
        "                                                         reg_L2=True,\n",
        "                                                         normalisation=False)  \n",
        "nom_modele = creer_nom_modele(nbre_couches=3,\n",
        "                              reg_extinction=False,\n",
        "                              reg_L2=True,\n",
        "                              normalisation=False)\n",
        "print(\"\\nDescription du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches_regularise_L2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c627ab9f",
      "metadata": {
        "id": "c627ab9f"
      },
      "source": [
        "### Compilation modèle 3 couches régularisé L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04b7e51b",
      "metadata": {
        "id": "04b7e51b",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "print(\"\\nCompilation du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches_regularise_L2.compile(loss=\"categorical_crossentropy\",\n",
        "                                       optimizer=\"adam\",\n",
        "                                       metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a06bd2e",
      "metadata": {
        "id": "1a06bd2e"
      },
      "source": [
        "## Entraînement modèle 3 couches régularisé L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45f1e6cd",
      "metadata": {
        "id": "45f1e6cd",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "print(\"\\nEntraînement du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "taille_lots = 128\n",
        "nbr_iterations = 15\n",
        "traces_entrainement_3_couches_regularise_L2 = modele_3_couches_regularise_L2.fit(\n",
        "    attributs_entrainement,\n",
        "    classes_cibles_entrainement,\n",
        "    batch_size=taille_lots,\n",
        "    epochs=nbr_iterations,\n",
        "    validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdf6465e",
      "metadata": {
        "id": "fdf6465e"
      },
      "source": [
        "## Évaluation modèle 3 couches régularisé L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066a1929",
      "metadata": {
        "id": "066a1929",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print(\"\\nÉvaluation du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "resultats_6 = modele_3_couches_regularise_L2.evaluate(attributs_test,\n",
        "                                                      classes_cibles_test,\n",
        "                                                      verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats_6[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ffec837",
      "metadata": {
        "id": "0ffec837"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 3 couches régularisé L2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd601665",
      "metadata": {
        "id": "cd601665",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "afficher_courbes_entraînement(nom_modele.replace('_',' '),\n",
        "                              traces_entrainement_3_couches_regularise_L2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "satellite-routine",
      "metadata": {
        "id": "satellite-routine"
      },
      "source": [
        "# 7- Modèle 3 couches régularisé (extinction + L2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "861b491b",
      "metadata": {
        "id": "861b491b"
      },
      "source": [
        "## Construction modèle 3 couches régularisé extinction + L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "subject-communist",
      "metadata": {
        "id": "subject-communist",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "modele_3_couches_regularise_extinction_L2 = creer_reseau_convolutif(nbre_couches=3,\n",
        "                                                                    reg_extinction=True,\n",
        "                                                                    reg_L2=True,\n",
        "                                                                    normalisation=False)  \n",
        "nom_modele = creer_nom_modele(nbre_couches=3,\n",
        "                              reg_extinction=True,\n",
        "                              reg_L2=True,\n",
        "                              normalisation=False)\n",
        "print(\"\\nDescription du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches_regularise_extinction_L2.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74fa0ccb",
      "metadata": {
        "id": "74fa0ccb"
      },
      "source": [
        "### Compilation modèle 3 couches régularisé (extinction + L2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "coated-depression",
      "metadata": {
        "id": "coated-depression",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "print(\"\\nCompilation du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches_regularise_extinction_L2.compile(loss=\"categorical_crossentropy\",\n",
        "                                                  optimizer=\"adam\",\n",
        "                                                  metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "divided-presence",
      "metadata": {
        "id": "divided-presence"
      },
      "source": [
        "## Entraînement modèle 3 couches régularisé (extinction + L2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "registered-stock",
      "metadata": {
        "id": "registered-stock",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "print(\"\\nEntraînement du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "taille_lots = 128\n",
        "nbr_iterations = 15\n",
        "traces_entrainement_3_couches_regularise_extinction_L2 = modele_3_couches_regularise_extinction_L2.fit(\n",
        "    attributs_entrainement,\n",
        "    classes_cibles_entrainement,\n",
        "    batch_size=taille_lots,\n",
        "    epochs=nbr_iterations,\n",
        "    validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "accessory-brave",
      "metadata": {
        "id": "accessory-brave"
      },
      "source": [
        "## Évaluation modèle 3 couches régularisé (extinction + L2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "noticed-pavilion",
      "metadata": {
        "id": "noticed-pavilion",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print(\"\\nÉvaluation du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "resultats_7 = modele_3_couches_regularise_extinction_L2.evaluate(attributs_test,\n",
        "                                                                 classes_cibles_test,\n",
        "                                                                 verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats_7[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "standard-knife",
      "metadata": {
        "id": "standard-knife"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 3 couches régularisé (extinction + L2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "enabling-chuck",
      "metadata": {
        "id": "enabling-chuck",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "afficher_courbes_entraînement(nom_modele.replace('_',' '),\n",
        "                              traces_entrainement_3_couches_regularise_extinction_L2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "likely-parallel",
      "metadata": {
        "id": "likely-parallel"
      },
      "source": [
        "# 8- Modèle 3 couches régularisé par extinction et normalisation des lots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bba075bb",
      "metadata": {
        "id": "bba075bb"
      },
      "source": [
        "## Construction modèle 3 couches régularisé par extinction et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "elder-silver",
      "metadata": {
        "id": "elder-silver",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "modele_3_couches_regularise_extinction_et_normalisation = creer_reseau_convolutif(nbre_couches=3,\n",
        "                                                                                  reg_extinction=True,\n",
        "                                                                                  reg_L2=False,\n",
        "                                                                                  normalisation=True)  \n",
        "nom_modele = creer_nom_modele(nbre_couches=3,\n",
        "                              reg_extinction=True,\n",
        "                              reg_L2=False,\n",
        "                              normalisation=True)\n",
        "print(\"\\nDescription du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches_regularise_extinction_et_normalisation.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e12c1dbf",
      "metadata": {
        "id": "e12c1dbf"
      },
      "source": [
        "### Compilation modèle 3 couches régularisé par extinction et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "through-quantity",
      "metadata": {
        "id": "through-quantity",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "print(\"\\nCompilation du \" + nom_modele.replace('_',' '))\n",
        "\n",
        "modele_3_couches_regularise_extinction_et_normalisation.compile(loss=\"categorical_crossentropy\", \n",
        "                                                                optimizer=\"adam\",\n",
        "                                                                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tough-career",
      "metadata": {
        "id": "tough-career"
      },
      "source": [
        "## Entraînement modèle 3 couches régularisé par extinction et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "veterinary-violin",
      "metadata": {
        "id": "veterinary-violin",
        "scrolled": false,
        "outputId": "d16f062c-fb14-4e30-bf87-3ee8839999da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352/352 [==============================] - ETA: 0s - loss: 0.6422 - accuracy: 0.7716"
          ]
        }
      ],
      "source": [
        "# Entraînement du modèle\n",
        "print(\"\\nEntraînement du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "taille_lots = 128\n",
        "nbr_iterations = 15\n",
        "traces_entrainement_3_couches_regularise_extinction_et_normalisation = modele_3_couches_regularise_extinction_et_normalisation.fit(\n",
        "    attributs_entrainement,\n",
        "    classes_cibles_entrainement,\n",
        "    batch_size=taille_lots,\n",
        "    epochs=nbr_iterations,\n",
        "    validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "personalized-compact",
      "metadata": {
        "id": "personalized-compact"
      },
      "source": [
        "## Évaluation modèle 3 couches régularisé par extinction et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "invisible-sample",
      "metadata": {
        "id": "invisible-sample",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print(\"\\nÉvaluation du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "resultats_8 = modele_3_couches_regularise_extinction_et_normalisation.evaluate(attributs_test,\n",
        "                                                                               classes_cibles_test,\n",
        "                                                                               verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats_8[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lesser-vertical",
      "metadata": {
        "id": "lesser-vertical"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 3 couches régularisé par extinction et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "every-north",
      "metadata": {
        "id": "every-north",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "afficher_courbes_entraînement(nom_modele.replace('_',' '),\n",
        "                              traces_entrainement_3_couches_regularise_extinction_et_normalisation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6e84969",
      "metadata": {
        "id": "d6e84969"
      },
      "source": [
        "# 9- Modèle 3 couches régularisé par L2 et normalisation des lots"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9972fb5",
      "metadata": {
        "id": "b9972fb5"
      },
      "source": [
        "## Construction modèle 3 couches régularisé par L2 et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68700b01",
      "metadata": {
        "id": "68700b01",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "modele_3_couches_regularise_L2_et_normalisation = creer_reseau_convolutif(nbre_couches=3,\n",
        "                                                                          reg_extinction=False,\n",
        "                                                                          reg_L2=True,\n",
        "                                                                          normalisation=True)  \n",
        "nom_modele = creer_nom_modele(nbre_couches=3,\n",
        "                              reg_extinction=False,\n",
        "                              reg_L2=True,\n",
        "                              normalisation=True)\n",
        "print(\"\\nDescription du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches_regularise_L2_et_normalisation.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9648ea30",
      "metadata": {
        "id": "9648ea30"
      },
      "source": [
        "### Compilation modèle 3 couches régularisé par L2 et normalisation des lots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11d90727",
      "metadata": {
        "id": "11d90727",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "print(\"\\nCompilation du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches_regularise_L2_et_normalisation.compile(loss=\"categorical_crossentropy\",\n",
        "                                                        optimizer=\"adam\",\n",
        "                                                        metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ebb7ea9",
      "metadata": {
        "id": "3ebb7ea9"
      },
      "source": [
        "## Entraînement modèle 3 couches régularisé par L2 et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8719c033",
      "metadata": {
        "id": "8719c033",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "print(\"\\nEntraînement du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "taille_lots = 128\n",
        "nbr_iterations = 15\n",
        "traces_entrainement_3_couches_regularise_L2_et_normalisation = modele_3_couches_regularise_L2_et_normalisation.fit(\n",
        "    attributs_entrainement,\n",
        "    classes_cibles_entrainement,\n",
        "    batch_size=taille_lots,\n",
        "    epochs=nbr_iterations,\n",
        "    validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9202d4f",
      "metadata": {
        "id": "f9202d4f"
      },
      "source": [
        "## Évaluation modèle 3 couches régularisé par L2 et normalisation des lots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c04ddded",
      "metadata": {
        "id": "c04ddded",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print(\"\\nÉvaluation du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "resultats_9 = modele_3_couches_regularise_L2_et_normalisation.evaluate(attributs_test,\n",
        "                                                                        classes_cibles_test,\n",
        "                                                                        verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats_9[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63d70cfd",
      "metadata": {
        "id": "63d70cfd"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 3 couches régularisé par L2 et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed41dd68",
      "metadata": {
        "id": "ed41dd68",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "afficher_courbes_entraînement(nom_modele.replace('_',' '),\n",
        "                              traces_entrainement_3_couches_regularise_L2_et_normalisation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a1deee7",
      "metadata": {
        "id": "3a1deee7"
      },
      "source": [
        "# 10- Modèle 3 couches régularisé (extinction + L2) et normalisation des lots"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94b7a05f",
      "metadata": {
        "id": "94b7a05f"
      },
      "source": [
        "## Construction modèle 3 couches régularisé (extinction + L2) et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a160d728",
      "metadata": {
        "id": "a160d728",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Construction du modèle\n",
        "modele_3_couches_regularise_extinction_L2_et_normalisation = creer_reseau_convolutif(nbre_couches=3,\n",
        "                                                                                     reg_extinction=True,\n",
        "                                                                                     reg_L2=True,\n",
        "                                                                                     normalisation=True)  \n",
        "nom_modele = creer_nom_modele(nbre_couches=3,\n",
        "                              reg_extinction=True,\n",
        "                              reg_L2=True,\n",
        "                              normalisation=True)\n",
        "print(\"\\nDescription du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches_regularise_extinction_L2_et_normalisation.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55cf0e4f",
      "metadata": {
        "id": "55cf0e4f"
      },
      "source": [
        "### Compilation modèle 3 couches régularisé (extinction + L2) et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d30322",
      "metadata": {
        "id": "93d30322",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle\n",
        "print(\"\\nCompilation du \" + nom_modele.replace('_',' '))\n",
        "modele_3_couches_regularise_extinction_L2_et_normalisation.compile(loss=\"categorical_crossentropy\",\n",
        "                                                                   optimizer=\"adam\",\n",
        "                                                                   metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f194a448",
      "metadata": {
        "id": "f194a448"
      },
      "source": [
        "## Entraînement modèle 3 couches régularisé (extinction + L2) et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f68741",
      "metadata": {
        "id": "d8f68741",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "print(\"\\nEntraînement du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "taille_lots = 128\n",
        "nbr_iterations = 15\n",
        "traces_entrainement_3_couches_regularise_extinction_L2_et_normalisation = modele_3_couches_regularise_extinction_L2_et_normalisation.fit(\n",
        "    attributs_entrainement,\n",
        "    classes_cibles_entrainement,\n",
        "    batch_size=taille_lots,\n",
        "    epochs=nbr_iterations,\n",
        "    validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1f3865d",
      "metadata": {
        "id": "b1f3865d"
      },
      "source": [
        "## Évaluation modèle 3 couches régularisé (extinction + L2) et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f00f0d7b",
      "metadata": {
        "id": "f00f0d7b",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "print(\"\\nÉvaluation du \" + nom_modele.replace('_',' ') + \"...\")\n",
        "resultats_10 = modele_3_couches_regularise_extinction_L2_et_normalisation.evaluate(attributs_test,\n",
        "                                                                                   classes_cibles_test,\n",
        "                                                                                   verbose=0)\n",
        "print(\"Exactitude test: {:.2f}%\".format(resultats_10[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efae0038",
      "metadata": {
        "id": "efae0038"
      },
      "source": [
        "## Affichage courbes d'entraînement, modèle 3 couches régularisé (extinction + L2) et normalisation des lots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64257df5",
      "metadata": {
        "id": "64257df5",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "afficher_courbes_entraînement(nom_modele.replace('_',' '),\n",
        "                              traces_entrainement_3_couches_regularise_extinction_L2_et_normalisation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "595c3813",
      "metadata": {
        "id": "595c3813"
      },
      "source": [
        "# -----------------------------------------------------------------------------------\n",
        "# Affichage des résultats comparés des différentes architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da9fed0f",
      "metadata": {
        "id": "da9fed0f"
      },
      "source": [
        "## Afficher le meilleur résultats et le nom du modèle correspondant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8f05776",
      "metadata": {
        "id": "b8f05776",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Préparation d'une liste regroupant tous les résultats\n",
        "resultats = [resultats_1[1],\n",
        "             resultats_2[1],\n",
        "             resultats_3[1],\n",
        "             resultats_4[1],\n",
        "             resultats_5[1],\n",
        "             resultats_6[1],\n",
        "             resultats_7[1],\n",
        "             resultats_8[1],\n",
        "             resultats_9[1],\n",
        "             resultats_10[1],\n",
        "            ]\n",
        "print(resultats)\n",
        "\n",
        "# Préparation d'une liste regroupant tous les noms de modèles\n",
        "noms_modeles = ['1 couche',\n",
        "                '2 couches', \n",
        "                '3 couches', \n",
        "                '4 couches',\n",
        "                '3 couches, regularisé extinction',\n",
        "                '3 couches, regularisé L2',\n",
        "                '3 couches, regularisé extinction + L2',\n",
        "                '3 couches, regularisé extinction, lots normalisés',\n",
        "                '3 couches, regularisé L2, lots normalisés',\n",
        "                '3 couches, regularisé extinction + L2, lots normalisés'\n",
        "               ]\n",
        "\n",
        "# Afficher le meilleur résultats et le nom du modèle correspondant\n",
        "import numpy as np\n",
        "index_meilleur_resultat = np.argmax(np.asarray(resultats))\n",
        "print(\"\\nMeilleur résultat: {:.2f}%\".format(resultats[index_meilleur_resultat]*100))\n",
        "print(\"Meilleur modèle: {}\".format(noms_modeles[index_meilleur_resultat]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb67205",
      "metadata": {
        "id": "4bb67205",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Affichage des résultats comparés des différentes architectures\n",
        "\n",
        "hauteur = 6\n",
        "plt.figure(figsize=(hauteur*1.62,hauteur))\n",
        "plt.title(\"Résultats comparés des différentes architectures\")\n",
        "plt.plot(noms_modeles, resultats, color='orange')\n",
        "plt.ylabel(\"Exactitude\")\n",
        "plt.xlabel(\"Noms des modèles\")\n",
        "plt.axvline(x=index_meilleur_resultat, color='g', ls=':')\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "short-latitude",
      "metadata": {
        "id": "short-latitude",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "print(\"Carnet IPython exécution terminée!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c09adc5d",
      "metadata": {
        "id": "c09adc5d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Identification_Objets-ResConv-VariantesArchitectures-CIFAR_10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}